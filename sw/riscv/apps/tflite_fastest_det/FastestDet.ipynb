{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 20:46:54.426877: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-11 20:46:54.486307: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 20:46:54.900496: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 20:46:55.926954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnx2keras\n",
    "import onnx2tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch_pruning as tp\n",
    "import ultralytics\n",
    "from keras_cv import bounding_box, visualization\n",
    "from matplotlib import pyplot as plt\n",
    "from onnx2keras import onnx_to_keras\n",
    "from rich.pretty import pprint\n",
    "from tensorflow import keras\n",
    "from tqdm.auto import tqdm\n",
    "from ultralytics import YOLO, __version__\n",
    "\n",
    "# from ultralytics.engine.model import TASK_MAP\n",
    "from ultralytics.engine.trainer import BaseTrainer\n",
    "from ultralytics.nn.modules import Bottleneck, C2f, Conv, Detect\n",
    "from ultralytics.nn.tasks import attempt_load_one_weight\n",
    "from ultralytics.utils import (\n",
    "    DEFAULT_CFG_DICT,\n",
    "    DEFAULT_CFG_KEYS,\n",
    "    LOGGER,\n",
    "    RANK,\n",
    "    yaml_load,\n",
    ")\n",
    "from ultralytics.utils.checks import check_yaml\n",
    "from ultralytics.utils.torch_utils import de_parallel, initialize_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't know why tensorflow doesn't recognize the GPU while ultralytics (torch) has no problems with it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 20:46:59.884315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-11 20:46:59.891471: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.12 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "Setup complete ✅ (12 CPUs, 23.4 GB RAM, 142.2/250.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size\n",
    "\n",
    "\n",
    "def sparsity(model):\n",
    "    # Return global model sparsity\n",
    "    a, b = 0, 0\n",
    "    for p in model.parameters():\n",
    "        a += p.numel()\n",
    "        b += (p == 0).sum()\n",
    "    return b / a\n",
    "\n",
    "\n",
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return print(\"File size: \" + str(round(size / 1024, 3)) + \" Kilobytes\")\n",
    "    elif unit == \"MB\":\n",
    "        return print(\"File size: \" + str(round(size / (1024 * 1024), 3)) + \" Megabytes\")\n",
    "    else:\n",
    "        return print(\"File size: \" + str(size) + \" bytes\")\n",
    "\n",
    "\n",
    "def c_style_hexdump(input, ouput, name):\n",
    "    with open(input, \"rb\") as f:\n",
    "        file = f.read()\n",
    "\n",
    "    file = bytearray(file)\n",
    "    _bytes = [f\"0x{x:02x}\" for x in file]\n",
    "    file = \",\".join(_bytes)\n",
    "\n",
    "    with open(ouput, \"w\") as f:\n",
    "        f.write(\"#pragma once\\n\")\n",
    "        f.write(\"#include <stdalign.h>\\n\")\n",
    "        f.write(f\"alignas(16) const unsigned char {name}[] = {{{file}}};\")\n",
    "\n",
    "    return len(_bytes)\n",
    "\n",
    "\n",
    "def build_header(output, names_with_sizes):\n",
    "    with open(output, \"w\") as f:\n",
    "        f.write('#pragma once\\n#ifdef __cplusplus\\nextern \"C\"\\n{\\n#endif\\n')\n",
    "        f.write(\"#include <stdalign.h>\\n\\n\")\n",
    "        for name, size in names_with_sizes:\n",
    "            f.write(f\"alignas(16) extern const unsigned char {name}[{size}];\\n\")\n",
    "        f.write(\"\\n#ifdef __cplusplus\\n}\\n#endif\\n\")\n",
    "\n",
    "\n",
    "def evaluate_model(interpreter, x_test, y_test):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(x_test):\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == y_test).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to quantize the model directly using `model.export(format=\"tflite\", imgsz=640, int8=True, data=\"coco.yaml\")`, see issue https://github.com/ultralytics/ultralytics/issues/11722\n",
    "\n",
    "What I do is export into `.onnx` format first and then convert to `.tflite` using `onnx2tf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add         │ 1              │ 1                │\n",
      "│ AveragePool │ 1              │ 1                │\n",
      "│ Concat      │ 19             │ 19               │\n",
      "│ Constant    │ 150            │ 150              │\n",
      "│ Conv        │ 70             │ 70               │\n",
      "│ Gather      │ 26             │ 26               │\n",
      "│ MaxPool     │ 1              │ 1                │\n",
      "│ Relu        │ 48             │ 48               │\n",
      "│ Reshape     │ 26             │ 26               │\n",
      "│ Resize      │ 1              │ 1                │\n",
      "│ Sigmoid     │ 1              │ 1                │\n",
      "│ Softmax     │ 1              │ 1                │\n",
      "│ Transpose   │ 15             │ 15               │\n",
      "│ Model Size  │ 972.6KiB       │ 972.6KiB         │\n",
      "└─────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add         │ 1              │ 1                │\n",
      "│ AveragePool │ 1              │ 1                │\n",
      "│ Concat      │ 19             │ 19               │\n",
      "│ Constant    │ 150            │ 150              │\n",
      "│ Conv        │ 70             │ 70               │\n",
      "│ Gather      │ 26             │ 26               │\n",
      "│ MaxPool     │ 1              │ 1                │\n",
      "│ Relu        │ 48             │ 48               │\n",
      "│ Reshape     │ 26             │ 26               │\n",
      "│ Resize      │ 1              │ 1                │\n",
      "│ Sigmoid     │ 1              │ 1                │\n",
      "│ Softmax     │ 1              │ 1                │\n",
      "│ Transpose   │ 15             │ 15               │\n",
      "│ Model Size  │ 972.6KiB       │ 972.6KiB         │\n",
      "└─────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add         │ 1              │ 1                │\n",
      "│ AveragePool │ 1              │ 1                │\n",
      "│ Concat      │ 19             │ 19               │\n",
      "│ Constant    │ 150            │ 150              │\n",
      "│ Conv        │ 70             │ 70               │\n",
      "│ Gather      │ 26             │ 26               │\n",
      "│ MaxPool     │ 1              │ 1                │\n",
      "│ Relu        │ 48             │ 48               │\n",
      "│ Reshape     │ 26             │ 26               │\n",
      "│ Resize      │ 1              │ 1                │\n",
      "│ Sigmoid     │ 1              │ 1                │\n",
      "│ Softmax     │ 1              │ 1                │\n",
      "│ Transpose   │ 15             │ 15               │\n",
      "│ Model Size  │ 972.6KiB       │ 972.6KiB         │\n",
      "└─────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "\u001b[32mModel optimizing complete!\u001b[0m\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input.1 \u001b[32mshape\u001b[0m: [1, 3, 352, 352] \u001b[32mdtype\u001b[0m: float32\n",
      "\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n",
      "\u001b[33mWARNING:\u001b[0m module 'onnx' has no attribute '_serialize'\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_0\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.1 \u001b[36mshape\u001b[0m: [1, 3, 352, 352] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_760 \u001b[36mshape\u001b[0m: [24, 3, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_761 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.4 \u001b[36mshape\u001b[0m: [1, 24, 176, 176] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_16/Pad:0 \u001b[34mshape\u001b[0m: (1, 354, 354, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_144/Add:0 \u001b[34mshape\u001b[0m: (1, 176, 176, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.4 \u001b[36mshape\u001b[0m: [1, 24, 176, 176] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____MaxPool_423 \u001b[36mshape\u001b[0m: [1, 24, 176, 176] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_144/Add:0 \u001b[34mshape\u001b[0m: (1, 176, 176, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (1, 176, 176, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: MaxPool_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____MaxPool_423 \u001b[36mshape\u001b[0m: [1, 24, 176, 176] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.8 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[33mWARNING:\u001b[0m Tensorflow incompatible padding detected. Extra pad layer is inserted automatically. \n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (1, 176, 176, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [3, 3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [[0, 0], [1, 1], [1, 1], [0, 0]] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_1/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 88, 88, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_3\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.8 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_763 \u001b[36mshape\u001b[0m: [24, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_764 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.16 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_18/Pad:0 \u001b[34mshape\u001b[0m: (1, 90, 90, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 24, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 24 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_145/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.8 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_769 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_770 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.32 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_1/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 88, 88, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_146/Add:0 \u001b[34mshape\u001b[0m: (1, 88, 88, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_4\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.16 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_766 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_767 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.24 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_145/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_147/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_7\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.32 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_432 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_146/Add:0 \u001b[34mshape\u001b[0m: (1, 88, 88, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (1, 88, 88, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_5\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.24 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_429 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_147/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_8\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_432 \u001b[36mshape\u001b[0m: [1, 24, 88, 88] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_772 \u001b[36mshape\u001b[0m: [24, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_773 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.40 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_19/Pad:0 \u001b[34mshape\u001b[0m: (1, 90, 90, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 24, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 24 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_148/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_9\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.40 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_775 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_776 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.48 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_148/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_149/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_10\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.48 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_437 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_149/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_11\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_429 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_437 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_615/concat:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_13\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_439 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_440 \u001b[36mshape\u001b[0m: [24, 2, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1232/transpose:0 \u001b[34mshape\u001b[0m: (1, 48, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [24, 2, 1936] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_31/Reshape:0 \u001b[34mshape\u001b[0m: (24, 2, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_14\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_440 \u001b[36mshape\u001b[0m: [24, 2, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_441 \u001b[36mshape\u001b[0m: [2, 24, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_31/Reshape:0 \u001b[34mshape\u001b[0m: (24, 2, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1233/transpose:0 \u001b[34mshape\u001b[0m: (2, 24, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_16\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_441 \u001b[36mshape\u001b[0m: [2, 24, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_442 \u001b[36mshape\u001b[0m: [5] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_443 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1234/transpose:0 \u001b[34mshape\u001b[0m: (2, 24, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 24, 44, 44] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_32/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_18\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_443 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_445 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_32/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_26/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_26/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_20\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_443 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.52 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_32/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_27/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_27/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_21\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.52 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_778 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_779 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.60 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1235/transpose:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_150/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_22\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.60 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_450 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_150/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_52/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_23\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_450 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_781 \u001b[36mshape\u001b[0m: [24, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_782 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.68 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_52/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 24, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 24 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_151/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_24\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.68 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_784 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_785 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.76 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_151/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_152/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_25\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.76 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_455 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_152/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_53/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_26\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_445 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_455 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.3 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1236/transpose:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_53/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_616/concat:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_28\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.3 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_439 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_458 \u001b[36mshape\u001b[0m: [24, 2, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1237/transpose:0 \u001b[34mshape\u001b[0m: (1, 48, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [24, 2, 1936] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_33/Reshape:0 \u001b[34mshape\u001b[0m: (24, 2, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_29\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_458 \u001b[36mshape\u001b[0m: [24, 2, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_459 \u001b[36mshape\u001b[0m: [2, 24, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_33/Reshape:0 \u001b[34mshape\u001b[0m: (24, 2, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1238/transpose:0 \u001b[34mshape\u001b[0m: (2, 24, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m27 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_31\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_459 \u001b[36mshape\u001b[0m: [2, 24, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_442 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_461 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1239/transpose:0 \u001b[34mshape\u001b[0m: (2, 24, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 24, 44, 44] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_34/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m28 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_33\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_461 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_463 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_34/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_28/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_28/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m29 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_35\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_461 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.80 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_34/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_29/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_29/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m30 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_36\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.80 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_787 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_788 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.88 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1240/transpose:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_153/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m31 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_37\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.88 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_468 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_153/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_54/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m32 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_38\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_468 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_790 \u001b[36mshape\u001b[0m: [24, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_791 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.96 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_54/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 24, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 24 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_154/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m33 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_39\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.96 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_793 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_794 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.104 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_154/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_155/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m34 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_40\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.104 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_473 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_155/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_55/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m35 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_41\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_463 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_473 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.7 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1241/transpose:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_55/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_617/concat:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m36 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_43\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.7 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_439 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_476 \u001b[36mshape\u001b[0m: [24, 2, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1242/transpose:0 \u001b[34mshape\u001b[0m: (1, 48, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [24, 2, 1936] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_35/Reshape:0 \u001b[34mshape\u001b[0m: (24, 2, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m37 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_44\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_476 \u001b[36mshape\u001b[0m: [24, 2, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_477 \u001b[36mshape\u001b[0m: [2, 24, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_35/Reshape:0 \u001b[34mshape\u001b[0m: (24, 2, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1243/transpose:0 \u001b[34mshape\u001b[0m: (2, 24, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m38 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_46\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_477 \u001b[36mshape\u001b[0m: [2, 24, 1936] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_442 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_479 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1244/transpose:0 \u001b[34mshape\u001b[0m: (2, 24, 1936) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 24, 44, 44] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_36/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m39 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_48\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_479 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_481 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_36/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_30/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_30/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m40 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_50\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_479 \u001b[36mshape\u001b[0m: [2, 1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.108 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_36/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_31/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_31/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 24, 44, 44) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m41 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_51\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.108 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_796 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_797 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.116 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1245/transpose:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_156/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m42 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_52\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.116 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_486 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_156/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_56/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m43 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_53\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_486 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_799 \u001b[36mshape\u001b[0m: [24, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_800 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.124 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_56/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 24, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 24 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_157/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m44 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_54\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.124 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_802 \u001b[36mshape\u001b[0m: [24, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_803 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.132 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_157/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_158/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m45 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_55\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.132 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_491 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_158/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_57/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m46 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_56\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_481 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_491 \u001b[36mshape\u001b[0m: [1, 24, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.136 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1246/transpose:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_57/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_618/concat:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m47 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_57\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.136 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_805 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_806 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.144 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_20/Pad:0 \u001b[34mshape\u001b[0m: (1, 46, 46, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_159/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m48 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_60\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.136 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_811 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_812 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.160 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_618/concat:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_160/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m49 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: AveragePool\u001b[35m onnx_op_name\u001b[0m: AveragePool_229\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.136 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_708 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[33mWARNING:\u001b[0m Tensorflow incompatible padding detected. Extra pad layer is inserted automatically. \n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: AveragePooling2D\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_618/concat:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.pool_size\u001b[0m: \u001b[34mval\u001b[0m: [3, 3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.padding\u001b[0m: \u001b[34mval\u001b[0m: [[0, 0], [1, 1], [1, 1], [0, 0]] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.avg_pool_1/AvgPool:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m50 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_58\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.144 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_808 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_809 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.152 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_159/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_161/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m51 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_61\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.160 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_500 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_160/Add:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_58/Relu:0 \u001b[34mshape\u001b[0m: (1, 44, 44, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m52 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_59\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.152 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_497 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_161/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_59/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m53 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_62\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_500 \u001b[36mshape\u001b[0m: [1, 48, 44, 44] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_814 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_815 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.168 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_22/Pad:0 \u001b[34mshape\u001b[0m: (1, 46, 46, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_162/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m54 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_63\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.168 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_817 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_818 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.176 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_162/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_163/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m55 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.176 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_505 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_163/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_60/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m56 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_65\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_497 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_505 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.11 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_59/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_60/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_619/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m57 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_67\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.11 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_508 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1247/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_37/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m58 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_68\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_508 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_509 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_37/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1248/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m59 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_70\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_509 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: [5] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_511 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1249/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_38/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m60 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_72\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_511 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_513 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_38/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_32/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_32/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m61 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_74\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_511 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.180 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_38/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_33/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_33/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m62 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_75\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.180 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_820 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_821 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.188 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1250/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_164/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m63 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_76\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.188 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_518 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_164/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_61/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m64 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_77\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_518 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_823 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_824 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.196 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_61/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_165/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m65 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_78\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.196 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_826 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_827 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.204 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_165/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_166/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m66 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_79\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.204 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_523 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_166/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_62/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m67 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_80\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_513 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_523 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.15 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1251/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_62/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_620/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m68 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_82\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.15 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_526 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1252/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_39/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m69 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_83\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_526 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_527 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_39/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1253/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m70 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_85\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_527 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_529 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1254/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_40/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m71 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_87\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_529 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_531 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_40/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_34/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_34/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m72 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_89\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_529 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.208 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_40/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_35/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_35/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m73 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_90\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.208 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_829 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_830 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.216 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1255/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_167/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m74 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_91\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.216 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_536 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_167/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_63/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m75 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_92\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_536 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_832 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_833 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.224 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_63/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_168/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m76 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_93\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.224 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_835 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_836 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.232 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_168/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_169/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m77 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_94\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.232 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_541 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_169/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_64/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m78 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_95\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_531 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_541 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.19 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1256/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_64/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_621/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m79 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_97\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.19 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_544 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1257/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_41/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m80 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_98\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_544 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_545 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_41/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1258/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m81 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_100\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_545 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_547 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1259/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_42/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m82 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_102\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_547 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_549 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_42/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_36/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_36/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m83 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_104\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_547 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.236 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_42/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_37/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_37/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m84 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_105\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.236 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_838 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_839 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.244 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1260/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_170/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m85 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_106\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.244 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_554 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_170/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_65/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m86 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_107\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_554 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_841 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_842 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.252 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_65/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_171/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m87 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_108\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.252 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_844 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_845 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.260 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_171/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_172/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m88 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_109\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.260 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_559 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_172/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_66/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m89 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_110\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_549 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_559 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.23 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1261/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_66/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_622/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m90 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_112\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.23 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_562 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1262/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_43/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m91 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_113\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_562 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_563 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_43/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1263/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m92 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_115\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_563 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_565 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1264/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_44/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m93 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_117\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_565 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_567 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_44/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_38/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_38/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m94 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_119\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_565 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.264 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_44/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_39/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_39/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m95 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_120\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.264 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_847 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_848 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.272 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1265/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_173/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m96 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_121\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.272 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_572 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_173/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_67/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m97 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_122\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_572 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_850 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_851 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.280 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_67/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_174/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m98 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_123\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.280 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_853 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_854 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.288 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_174/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_175/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m99 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_124\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.288 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_577 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_175/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_68/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m100 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_125\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_567 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_577 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.27 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1266/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_68/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_623/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m101 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_127\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.27 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_580 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1267/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_45/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m102 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_128\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_580 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_581 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_45/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1268/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m103 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_130\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_581 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_583 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1269/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_46/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m104 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_132\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_583 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_585 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_46/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_40/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_40/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m105 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_134\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_583 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.292 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_46/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_41/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_41/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m106 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_135\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.292 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_856 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_857 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.300 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1270/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_176/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m107 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_136\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.300 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_590 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_176/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_69/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m108 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_137\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_590 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_859 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_860 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.308 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_69/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_177/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m109 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_138\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.308 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_862 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_863 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.316 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_177/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_178/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m110 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_139\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.316 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_595 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_178/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_70/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m111 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_140\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_585 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_595 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.31 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1271/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_70/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_624/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m112 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_142\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.31 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_598 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1272/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_47/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m113 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_143\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_598 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_599 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_47/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1273/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m114 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_145\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_599 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_601 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1274/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_48/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m115 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_147\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_601 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_603 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_48/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_42/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_42/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m116 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_149\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_601 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.320 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_48/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_43/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_43/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m117 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_150\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.320 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_865 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_866 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.328 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1275/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_179/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m118 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_151\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.328 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_608 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_179/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_71/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m119 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_152\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_608 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_868 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_869 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.336 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_71/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_180/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m120 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_153\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.336 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_871 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_872 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.344 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_180/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_181/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m121 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_154\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.344 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_613 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_181/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_72/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m122 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_155\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_603 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_613 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.35 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1276/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_72/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_625/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m123 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_157\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.35 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_507 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_616 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1277/transpose:0 \u001b[34mshape\u001b[0m: (1, 96, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [48, 2, 484] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_49/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m124 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_158\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_616 \u001b[36mshape\u001b[0m: [48, 2, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_617 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_49/Reshape:0 \u001b[34mshape\u001b[0m: (48, 2, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1278/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m125 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_160\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_617 \u001b[36mshape\u001b[0m: [2, 48, 484] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_510 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_619 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1279/transpose:0 \u001b[34mshape\u001b[0m: (2, 48, 484) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 48, 22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_50/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m126 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_162\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_619 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_621 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_50/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_44/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_44/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m127 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_164\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_619 \u001b[36mshape\u001b[0m: [2, 1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.348 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_50/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_45/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_45/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 48, 22, 22) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m128 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_165\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.348 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_874 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_875 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.356 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1280/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_182/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m129 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_166\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.356 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_626 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_182/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_73/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m130 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_167\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_626 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_877 \u001b[36mshape\u001b[0m: [48, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_878 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.364 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_73/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 48 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_183/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m131 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_168\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.364 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_880 \u001b[36mshape\u001b[0m: [48, 48, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_881 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.372 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_183/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_184/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m132 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_169\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.372 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_631 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_184/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_74/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m133 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_170\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_621 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_631 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.376 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1281/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_74/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_626/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m134 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_171\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.376 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_883 \u001b[36mshape\u001b[0m: [96, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_884 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.384 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_23/Pad:0 \u001b[34mshape\u001b[0m: (1, 24, 24, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_185/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m135 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_174\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.376 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_889 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_890 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.400 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_626/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_186/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m136 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_172\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.384 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_886 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_887 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.392 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_185/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_187/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m137 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_175\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.400 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_640 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_186/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_75/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m138 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_173\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.392 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_637 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_187/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_76/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m139 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_176\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_640 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_892 \u001b[36mshape\u001b[0m: [96, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_893 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.408 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_24/Pad:0 \u001b[34mshape\u001b[0m: (1, 24, 24, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_188/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m140 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_177\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.408 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_895 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_896 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.416 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_188/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_189/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m141 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_178\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.416 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_645 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_189/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_77/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m142 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_179\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_637 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_645 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.39 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_76/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_77/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_627/concat:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m143 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_181\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.39 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_647 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_648 \u001b[36mshape\u001b[0m: [96, 2, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1282/transpose:0 \u001b[34mshape\u001b[0m: (1, 192, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [96, 2, 121] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_51/Reshape:0 \u001b[34mshape\u001b[0m: (96, 2, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m144 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_182\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_648 \u001b[36mshape\u001b[0m: [96, 2, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_649 \u001b[36mshape\u001b[0m: [2, 96, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_51/Reshape:0 \u001b[34mshape\u001b[0m: (96, 2, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1283/transpose:0 \u001b[34mshape\u001b[0m: (2, 96, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m145 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_184\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_649 \u001b[36mshape\u001b[0m: [2, 96, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_650 \u001b[36mshape\u001b[0m: [5] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_651 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1284/transpose:0 \u001b[34mshape\u001b[0m: (2, 96, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 96, 11, 11] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_52/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m146 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_186\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_651 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_653 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_52/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_46/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_46/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m147 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_188\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_651 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.420 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_52/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_47/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_47/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m148 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_189\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.420 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_898 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_899 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.428 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1285/transpose:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_190/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m149 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_190\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.428 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_658 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_190/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_78/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m150 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_191\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_658 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_901 \u001b[36mshape\u001b[0m: [96, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_902 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.436 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_78/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_191/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m151 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_192\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.436 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_904 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_905 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.444 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_191/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_192/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m152 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_193\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.444 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_663 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_192/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_79/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m153 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_194\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_653 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_663 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.43 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1286/transpose:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_79/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_628/concat:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m154 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_196\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.43 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_647 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_666 \u001b[36mshape\u001b[0m: [96, 2, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1287/transpose:0 \u001b[34mshape\u001b[0m: (1, 192, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [96, 2, 121] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_53/Reshape:0 \u001b[34mshape\u001b[0m: (96, 2, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m155 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_197\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_666 \u001b[36mshape\u001b[0m: [96, 2, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_667 \u001b[36mshape\u001b[0m: [2, 96, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_53/Reshape:0 \u001b[34mshape\u001b[0m: (96, 2, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1288/transpose:0 \u001b[34mshape\u001b[0m: (2, 96, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m156 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_199\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_667 \u001b[36mshape\u001b[0m: [2, 96, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_650 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_669 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1289/transpose:0 \u001b[34mshape\u001b[0m: (2, 96, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 96, 11, 11] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_54/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m157 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_201\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_669 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_671 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_54/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_48/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_48/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m158 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_203\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_669 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.448 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_54/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_49/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_49/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m159 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_204\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.448 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_907 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_908 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.456 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1290/transpose:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_193/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m160 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_205\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.456 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_676 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_193/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_80/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m161 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_206\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_676 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_910 \u001b[36mshape\u001b[0m: [96, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_911 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.464 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_80/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_194/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m162 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_207\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.464 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_913 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_914 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.472 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_194/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_195/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m163 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_208\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.472 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_681 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_195/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_81/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m164 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_209\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_671 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_681 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: old_x.47 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1291/transpose:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_81/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_629/concat:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m165 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_211\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: old_x.47 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_647 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_684 \u001b[36mshape\u001b[0m: [96, 2, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1292/transpose:0 \u001b[34mshape\u001b[0m: (1, 192, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [96, 2, 121] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_55/Reshape:0 \u001b[34mshape\u001b[0m: (96, 2, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m166 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_212\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_684 \u001b[36mshape\u001b[0m: [96, 2, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Reshape_685 \u001b[36mshape\u001b[0m: [2, 96, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_55/Reshape:0 \u001b[34mshape\u001b[0m: (96, 2, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1293/transpose:0 \u001b[34mshape\u001b[0m: (2, 96, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m167 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: Reshape_214\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Reshape_685 \u001b[36mshape\u001b[0m: [2, 96, 121] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Reshape_650 \u001b[36mshape\u001b[0m: (5,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Gather_687 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1294/transpose:0 \u001b[34mshape\u001b[0m: (2, 96, 121) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [2, -1, 96, 11, 11] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_56/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m168 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_216\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_687 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_444 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_689 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_56/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_50/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_50/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m169 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: Gather_218\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Gather_687 \u001b[36mshape\u001b[0m: [2, 1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Gather_446 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.476 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: gather_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_56/Reshape:0 \u001b[34mshape\u001b[0m: (2, 1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_51/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_51/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 96, 11, 11) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m170 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_219\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.476 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_916 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_917 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.484 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1295/transpose:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_196/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m171 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_220\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.484 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_694 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_196/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_82/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m172 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_221\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_694 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_919 \u001b[36mshape\u001b[0m: [96, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_920 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.492 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_82/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_197/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m173 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_222\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.492 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_922 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_923 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.500 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_197/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_198/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m174 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_223\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.500 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_699 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_198/Add:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_83/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m175 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_224\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_689 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_699 \u001b[36mshape\u001b[0m: [1, 96, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.504 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1296/transpose:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_83/Relu:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_630/concat:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m176 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: Resize_226\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.504 \u001b[36mshape\u001b[0m: [1, 192, 11, 11] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Resize_704 \u001b[36mshape\u001b[0m: [0] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Resize_969 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_705 \u001b[36mshape\u001b[0m: [1, 192, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_nearest\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_630/concat:0 \u001b[34mshape\u001b[0m: (1, 11, 11, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mval\u001b[0m: [22, 22] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: nearest \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: lambda_3/Resize_226:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m177 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_230\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_708 \u001b[36mshape\u001b[0m: [1, 48, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: input.376 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx____Concat_705 \u001b[36mshape\u001b[0m: [1, 192, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.508 \u001b[36mshape\u001b[0m: [1, 336, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.avg_pool_1/AvgPool:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_626/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: lambda_3/Resize_226:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_631/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 336) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m178 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_231\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.508 \u001b[36mshape\u001b[0m: [1, 336, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_925 \u001b[36mshape\u001b[0m: [96, 336, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_926 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.516 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_631/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 336) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 336, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_199/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m179 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_232\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.516 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_712 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_199/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m180 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_233\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_712 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_928 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_929 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.524 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_200/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m181 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_235\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_712 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_931 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_932 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.532 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_201/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m182 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_239\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_712 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_937 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_938 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.548 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_202/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m183 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_234\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.524 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_715 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_200/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_85/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m184 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_236\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.532 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_718 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_201/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_86/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m185 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_240\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.548 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_724 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_202/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_87/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m186 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_237\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_718 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_934 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_935 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.540 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_86/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_203/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m187 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_241\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_724 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_940 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_941 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.556 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_87/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_204/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m188 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_238\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.540 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_721 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_203/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_88/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m189 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_242\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.556 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_727 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_204/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_89/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m190 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_243\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_727 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_943 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_944 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.564 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_89/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_205/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m191 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_244\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.564 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_730 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_205/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_90/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m192 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_245\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_715 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_721 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx____Concat_730 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.568 \u001b[36mshape\u001b[0m: [1, 288, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_85/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_88/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_90/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_632/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 288) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m193 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_246\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.568 \u001b[36mshape\u001b[0m: [1, 288, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_946 \u001b[36mshape\u001b[0m: [96, 288, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_947 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Add_945 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_632/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 288) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 288, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_206/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m194 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: Add_247\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_712 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Add_945 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.576 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_206/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_207/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m195 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_248\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.576 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_735 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_207/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_91/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m196 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_249\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_735 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_949 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_950 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.584 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_91/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_208/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m197 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_250\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.584 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_738 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_208/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_92/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m198 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_251\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_738 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_952 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_953 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.592 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_92/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_209/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m199 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_255\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_738 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_958 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_959 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.604 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_92/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_210/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m200 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_258\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_738 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_964 \u001b[36mshape\u001b[0m: [96, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_965 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.616 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_92/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 96 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_211/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m201 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_252\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.592 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_741 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_209/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_93/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m202 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_256\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.604 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_747 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_210/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_94/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m203 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: Relu_259\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.616 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Conv_752 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_211/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_95/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m204 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_253\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_741 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_955 \u001b[36mshape\u001b[0m: [1, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_956 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Sigmoid_954 \u001b[36mshape\u001b[0m: [1, 1, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_93/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_212/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m205 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_257\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_747 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_961 \u001b[36mshape\u001b[0m: [4, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_962 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_960 \u001b[36mshape\u001b[0m: [1, 4, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_94/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (4,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_213/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m206 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: Conv_260\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Conv_752 \u001b[36mshape\u001b[0m: [1, 96, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_967 \u001b[36mshape\u001b[0m: [80, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_968 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: input.624 \u001b[36mshape\u001b[0m: [1, 80, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_95/Relu:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_214/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m207 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: Sigmoid_254\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Sigmoid_954 \u001b[36mshape\u001b[0m: [1, 1, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_744 \u001b[36mshape\u001b[0m: [1, 1, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_212/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_59/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m208 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_261\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.624 \u001b[36mshape\u001b[0m: [1, 80, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Softmax_755 \u001b[36mshape\u001b[0m: [1, 22, 22, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_214/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 1, 2, 3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1297/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m209 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Softmax\u001b[35m onnx_op_name\u001b[0m: Softmax_262\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Softmax_755 \u001b[36mshape\u001b[0m: [1, 22, 22, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Transpose_756 \u001b[36mshape\u001b[0m: [1, 22, 22, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: softmax_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.logits\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1297/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax_2/Softmax_262:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m210 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: Transpose_263\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Transpose_756 \u001b[36mshape\u001b[0m: [1, 22, 22, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: onnx____Concat_757 \u001b[36mshape\u001b[0m: [1, 80, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax_2/Softmax_262:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 1, 2, 3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1298/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m211 / 211\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: Concat_264\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Concat_744 \u001b[36mshape\u001b[0m: [1, 1, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx____Concat_960 \u001b[36mshape\u001b[0m: [1, 4, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx____Concat_757 \u001b[36mshape\u001b[0m: [1, 80, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: 758 \u001b[36mshape\u001b[0m: [1, 85, 22, 22] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_59/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_213/Add:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1298/transpose:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_633/concat:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 85) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07mh5 output started\u001b[0m ===================================================================\n",
      "\u001b[32mjson output start...\u001b[0m\n",
      "\u001b[32mjson output finish\u001b[0m\n",
      "\u001b[32mweights.h5 output start...\u001b[0m\n",
      "\u001b[32mweights.h5 output finish\u001b[0m\n",
      "\u001b[32mweights.keras output start...\u001b[0m\n",
      "\u001b[32mweights.keras output finish\u001b[0m\n",
      "\u001b[32mweights.tf output start...\u001b[0m\n",
      "\u001b[32mweights.tf output finish\u001b[0m\n",
      "\u001b[32mkeras output start...\u001b[0m\n",
      "\u001b[32mkeras output finish\u001b[0m\n",
      "\u001b[32mh5 output start...\u001b[0m\n",
      "\u001b[32mh5 output complete!\u001b[0m\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:44.985352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-11 22:14:44.985413: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-11 22:14:44.985525: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-11 22:14:44.985883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-11 22:14:44.985900: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-11 22:14:45.484709: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:45.484796: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:45.558937: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n",
      "2024-05-11 22:14:45.732445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-11 22:14:45.732506: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-11 22:14:45.732642: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-05-11 22:14:45.732917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-11 22:14:45.732931: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:46.156393: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:46.156449: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:46.238954: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n",
      "\u001b[34mInput signature information for quantization\u001b[0m\n",
      "\u001b[34msignature_name\u001b[0m: serving_default\n",
      "\u001b[34minput_name.0\u001b[0m: input_1 \u001b[34mshape\u001b[0m: (1, 352, 352, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:47.964535: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:47.964593: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:47.964747: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:47.967468: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 22:14:47.967482: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:47.974766: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 22:14:48.005701: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:48.038239: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 73491 microseconds.\n",
      "2024-05-11 22:14:48.188172: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDynamic Range Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:48.411462: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:48.411517: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:48.411703: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:48.415515: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 22:14:48.415542: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:48.422915: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 22:14:48.467812: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:48.498756: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 87051 microseconds.\n",
      "2024-05-11 22:14:48.650326: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2024-05-11 22:14:50.612760: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINT8 Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:50.897538: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:50.897604: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:50.897788: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:50.902594: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 22:14:50.902647: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:50.912120: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 22:14:50.948501: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:50.987392: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 89605 microseconds.\n",
      "2024-05-11 22:14:51.114962: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "2024-05-11 22:14:53.089953: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFull INT8 Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:53.369011: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:53.369074: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:53.369244: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:53.372493: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 22:14:53.372521: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:53.379722: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 22:14:53.417877: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:53.446453: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 77209 microseconds.\n",
      "2024-05-11 22:14:53.561926: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINT8 Quantization with int16 activations tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:14:57.572973: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 22:14:57.573022: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 22:14:57.573172: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:57.576166: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 22:14:57.576197: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:57.583602: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 22:14:57.610895: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqakc845g\n",
      "2024-05-11 22:14:57.637044: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 63870 microseconds.\n",
      "2024-05-11 22:14:57.749711: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFull INT8 Quantization with int16 activations tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7ff74b7aa200>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_fastest_det = tempfile.mkdtemp()\n",
    "\n",
    "onnx2tf.convert(\n",
    "    \"FastestDet.onnx\",\n",
    "    output_integer_quantized_tflite=True,\n",
    "    output_h5=True,\n",
    "    output_folder_path=saved_model_fastest_det,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpqakc845g\n"
     ]
    }
   ],
   "source": [
    "print(saved_model_fastest_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 23:15:28.413722: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 23:15:28.413777: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 23:15:28.413936: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqakc845g\n",
      "2024-05-11 23:15:28.416982: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 23:15:28.417023: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqakc845g\n",
      "2024-05-11 23:15:28.658135: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 23:15:28.860968: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqakc845g\n",
      "2024-05-11 23:15:28.890203: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 476267 microseconds.\n",
      "2024-05-11 23:15:29.163609: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n",
      "2024-05-11 23:15:38.824285: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 250.424 M  ops, equivalently 125.212 M  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 0.402 Megabytes\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 352, 352, 3)\n",
    "        yield [data.astype(np.float32)]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_fastest_det)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "\n",
    "file = converter.convert()\n",
    "\n",
    "_, fastest_det_quant_file = tempfile.mkstemp(\".tflite\")\n",
    "\n",
    "with open(fastest_det_quant_file, \"wb\") as f:\n",
    "    f.write(file)\n",
    "\n",
    "convert_bytes(get_file_size(fastest_det_quant_file), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpqibri787.tflite\n"
     ]
    }
   ],
   "source": [
    "print(fastest_det_quant_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /tmp/tmpqibri787.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the QUANTIZE op takes\n",
      "tensor #0 as input and produces tensor #154 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#364]\n",
      "  Op#0 QUANTIZE(T#0) -> [T#154]\n",
      "  Op#1 PAD(T#154, T#1[0, 0, 1, 1, 1, ...]) -> [T#155]\n",
      "  Op#2 CONV_2D(T#155, T#153, T#152[96096, 32069, 39896, 44835, 4403, ...]) -> [T#156]\n",
      "  Op#3 PAD(T#156, T#1[0, 0, 1, 1, 1, ...]) -> [T#157]\n",
      "  Op#4 MAX_POOL_2D(T#157) -> [T#158]\n",
      "  Op#5 PAD(T#158, T#1[0, 0, 1, 1, 1, ...]) -> [T#159]\n",
      "  Op#6 DEPTHWISE_CONV_2D(T#159, T#151, T#150[3620, -14626, -4446, -6719, 2775, ...]) -> [T#160]\n",
      "  Op#7 CONV_2D(T#158, T#149, T#148[-20606, -9339, 8208, -5232, 18590, ...]) -> [T#161]\n",
      "  Op#8 PAD(T#161, T#1[0, 0, 1, 1, 1, ...]) -> [T#162]\n",
      "  Op#9 DEPTHWISE_CONV_2D(T#162, T#147, T#146[217, 9713, -5683, -4704, 366, ...]) -> [T#163]\n",
      "  Op#10 CONV_2D(T#160, T#145, T#144[3635, -574, 1858, 3546, 877, ...]) -> [T#164]\n",
      "  Op#11 CONV_2D(T#163, T#143, T#142[17702, 1890, 3351, -1676, 12323, ...]) -> [T#165]\n",
      "  Op#12 CONCATENATION(T#164, T#165) -> [T#166]\n",
      "  Op#13 TRANSPOSE(T#166, T#2[0, 3, 1, 2]) -> [T#167]\n",
      "  Op#14 RESHAPE(T#167, T#3[24, 2, 1936]) -> [T#168]\n",
      "  Op#15 TRANSPOSE(T#168, T#4[1, 0, 2]) -> [T#169]\n",
      "  Op#16 RESHAPE(T#169, T#5[2, 1, 24, 44, 44]) -> [T#170]\n",
      "  Op#17 GATHER(T#170, T#6[0]) -> [T#171]\n",
      "  Op#18 TRANSPOSE(T#171, T#7[0, 2, 3, 1]) -> [T#172]\n",
      "  Op#19 GATHER(T#170, T#8[1]) -> [T#173]\n",
      "  Op#20 TRANSPOSE(T#173, T#7[0, 2, 3, 1]) -> [T#174]\n",
      "  Op#21 CONV_2D(T#174, T#141, T#140[24439, 9724, 5712, 48839, 13942, ...]) -> [T#175]\n",
      "  Op#22 DEPTHWISE_CONV_2D(T#175, T#139, T#138[6241, 852, -1314, 2054, 757, ...]) -> [T#176]\n",
      "  Op#23 CONV_2D(T#176, T#137, T#136[1491, 264, 3939, 1035, 800, ...]) -> [T#177]\n",
      "  Op#24 CONCATENATION(T#172, T#177) -> [T#178]\n",
      "  Op#25 TRANSPOSE(T#178, T#2[0, 3, 1, 2]) -> [T#179]\n",
      "  Op#26 RESHAPE(T#179, T#3[24, 2, 1936]) -> [T#180]\n",
      "  Op#27 TRANSPOSE(T#180, T#4[1, 0, 2]) -> [T#181]\n",
      "  Op#28 RESHAPE(T#181, T#5[2, 1, 24, 44, 44]) -> [T#182]\n",
      "  Op#29 GATHER(T#182, T#6[0]) -> [T#183]\n",
      "  Op#30 TRANSPOSE(T#183, T#7[0, 2, 3, 1]) -> [T#184]\n",
      "  Op#31 GATHER(T#182, T#8[1]) -> [T#185]\n",
      "  Op#32 TRANSPOSE(T#185, T#7[0, 2, 3, 1]) -> [T#186]\n",
      "  Op#33 CONV_2D(T#186, T#135, T#134[-10065, 21693, 5077, 45674, 26759, ...]) -> [T#187]\n",
      "  Op#34 DEPTHWISE_CONV_2D(T#187, T#133, T#132[5595, 3102, -5522, -457, 1295, ...]) -> [T#188]\n",
      "  Op#35 CONV_2D(T#188, T#131, T#130[77, -107, 74, -427, 3715, ...]) -> [T#189]\n",
      "  Op#36 CONCATENATION(T#184, T#189) -> [T#190]\n",
      "  Op#37 TRANSPOSE(T#190, T#2[0, 3, 1, 2]) -> [T#191]\n",
      "  Op#38 RESHAPE(T#191, T#3[24, 2, 1936]) -> [T#192]\n",
      "  Op#39 TRANSPOSE(T#192, T#4[1, 0, 2]) -> [T#193]\n",
      "  Op#40 RESHAPE(T#193, T#5[2, 1, 24, 44, 44]) -> [T#194]\n",
      "  Op#41 GATHER(T#194, T#6[0]) -> [T#195]\n",
      "  Op#42 TRANSPOSE(T#195, T#7[0, 2, 3, 1]) -> [T#196]\n",
      "  Op#43 GATHER(T#194, T#8[1]) -> [T#197]\n",
      "  Op#44 TRANSPOSE(T#197, T#7[0, 2, 3, 1]) -> [T#198]\n",
      "  Op#45 CONV_2D(T#198, T#129, T#128[37739, 8220, -700, 31554, -3491, ...]) -> [T#199]\n",
      "  Op#46 DEPTHWISE_CONV_2D(T#199, T#127, T#126[-1833, -530, 27, -2318, -1294, ...]) -> [T#200]\n",
      "  Op#47 CONV_2D(T#200, T#125, T#124[150, 29, 402, -262, 1099, ...]) -> [T#201]\n",
      "  Op#48 CONCATENATION(T#196, T#201) -> [T#202]\n",
      "  Op#49 PAD(T#202, T#1[0, 0, 1, 1, 1, ...]) -> [T#203]\n",
      "  Op#50 DEPTHWISE_CONV_2D(T#203, T#123, T#122[21912, -7343, -40557, 55630, 6939, ...]) -> [T#204]\n",
      "  Op#51 AVERAGE_POOL_2D(T#203) -> [T#205]\n",
      "  Op#52 CONV_2D(T#202, T#121, T#120[-10134, 21600, 1134, -9801, 23955, ...]) -> [T#206]\n",
      "  Op#53 PAD(T#206, T#1[0, 0, 1, 1, 1, ...]) -> [T#207]\n",
      "  Op#54 DEPTHWISE_CONV_2D(T#207, T#119, T#118[2621, 6168, -5457, 1139, 5203, ...]) -> [T#208]\n",
      "  Op#55 CONV_2D(T#204, T#117, T#116[8468, -53, 1224, 9776, 4737, ...]) -> [T#209]\n",
      "  Op#56 CONV_2D(T#208, T#115, T#114[7625, 67, 5778, 3673, 12870, ...]) -> [T#210]\n",
      "  Op#57 CONCATENATION(T#209, T#210) -> [T#211]\n",
      "  Op#58 TRANSPOSE(T#211, T#2[0, 3, 1, 2]) -> [T#212]\n",
      "  Op#59 RESHAPE(T#212, T#9[48, 2, 484]) -> [T#213]\n",
      "  Op#60 TRANSPOSE(T#213, T#4[1, 0, 2]) -> [T#214]\n",
      "  Op#61 RESHAPE(T#214, T#10[2, 1, 48, 22, 22]) -> [T#215]\n",
      "  Op#62 GATHER(T#215, T#6[0]) -> [T#216]\n",
      "  Op#63 TRANSPOSE(T#216, T#7[0, 2, 3, 1]) -> [T#217]\n",
      "  Op#64 GATHER(T#215, T#8[1]) -> [T#218]\n",
      "  Op#65 TRANSPOSE(T#218, T#7[0, 2, 3, 1]) -> [T#219]\n",
      "  Op#66 CONV_2D(T#219, T#113, T#112[6010, 39097, 8633, -6556, -8011, ...]) -> [T#220]\n",
      "  Op#67 DEPTHWISE_CONV_2D(T#220, T#111, T#110[-720, 3134, -313, -6440, 15, ...]) -> [T#221]\n",
      "  Op#68 CONV_2D(T#221, T#109, T#108[380, -343, -762, -2669, 15289, ...]) -> [T#222]\n",
      "  Op#69 CONCATENATION(T#217, T#222) -> [T#223]\n",
      "  Op#70 TRANSPOSE(T#223, T#2[0, 3, 1, 2]) -> [T#224]\n",
      "  Op#71 RESHAPE(T#224, T#9[48, 2, 484]) -> [T#225]\n",
      "  Op#72 TRANSPOSE(T#225, T#4[1, 0, 2]) -> [T#226]\n",
      "  Op#73 RESHAPE(T#226, T#10[2, 1, 48, 22, 22]) -> [T#227]\n",
      "  Op#74 GATHER(T#227, T#6[0]) -> [T#228]\n",
      "  Op#75 TRANSPOSE(T#228, T#7[0, 2, 3, 1]) -> [T#229]\n",
      "  Op#76 GATHER(T#227, T#8[1]) -> [T#230]\n",
      "  Op#77 TRANSPOSE(T#230, T#7[0, 2, 3, 1]) -> [T#231]\n",
      "  Op#78 CONV_2D(T#231, T#107, T#106[22333, 33802, -4994, 8945, 10056, ...]) -> [T#232]\n",
      "  Op#79 DEPTHWISE_CONV_2D(T#232, T#105, T#104[5625, -1187, -5420, -137, 495, ...]) -> [T#233]\n",
      "  Op#80 CONV_2D(T#233, T#103, T#102[7164, 145, 3388, 129, 13181, ...]) -> [T#234]\n",
      "  Op#81 CONCATENATION(T#229, T#234) -> [T#235]\n",
      "  Op#82 TRANSPOSE(T#235, T#2[0, 3, 1, 2]) -> [T#236]\n",
      "  Op#83 RESHAPE(T#236, T#9[48, 2, 484]) -> [T#237]\n",
      "  Op#84 TRANSPOSE(T#237, T#4[1, 0, 2]) -> [T#238]\n",
      "  Op#85 RESHAPE(T#238, T#10[2, 1, 48, 22, 22]) -> [T#239]\n",
      "  Op#86 GATHER(T#239, T#6[0]) -> [T#240]\n",
      "  Op#87 TRANSPOSE(T#240, T#7[0, 2, 3, 1]) -> [T#241]\n",
      "  Op#88 GATHER(T#239, T#8[1]) -> [T#242]\n",
      "  Op#89 TRANSPOSE(T#242, T#7[0, 2, 3, 1]) -> [T#243]\n",
      "  Op#90 CONV_2D(T#243, T#101, T#100[13493, 7332, 33461, 37, -11608, ...]) -> [T#244]\n",
      "  Op#91 DEPTHWISE_CONV_2D(T#244, T#99, T#98[11464, -6183, 34609, 6495, 11674, ...]) -> [T#245]\n",
      "  Op#92 CONV_2D(T#245, T#97, T#96[19672, -1440, 321, 15830, 13908, ...]) -> [T#246]\n",
      "  Op#93 CONCATENATION(T#241, T#246) -> [T#247]\n",
      "  Op#94 TRANSPOSE(T#247, T#2[0, 3, 1, 2]) -> [T#248]\n",
      "  Op#95 RESHAPE(T#248, T#9[48, 2, 484]) -> [T#249]\n",
      "  Op#96 TRANSPOSE(T#249, T#4[1, 0, 2]) -> [T#250]\n",
      "  Op#97 RESHAPE(T#250, T#10[2, 1, 48, 22, 22]) -> [T#251]\n",
      "  Op#98 GATHER(T#251, T#6[0]) -> [T#252]\n",
      "  Op#99 TRANSPOSE(T#252, T#7[0, 2, 3, 1]) -> [T#253]\n",
      "  Op#100 GATHER(T#251, T#8[1]) -> [T#254]\n",
      "  Op#101 TRANSPOSE(T#254, T#7[0, 2, 3, 1]) -> [T#255]\n",
      "  Op#102 CONV_2D(T#255, T#95, T#94[7925, -12253, 10376, 14230, 14162, ...]) -> [T#256]\n",
      "  Op#103 DEPTHWISE_CONV_2D(T#256, T#93, T#92[-1373, -4742, -19772, -1982, 1766, ...]) -> [T#257]\n",
      "  Op#104 CONV_2D(T#257, T#91, T#90[10438, -325, -4831, -1815, 9648, ...]) -> [T#258]\n",
      "  Op#105 CONCATENATION(T#253, T#258) -> [T#259]\n",
      "  Op#106 TRANSPOSE(T#259, T#2[0, 3, 1, 2]) -> [T#260]\n",
      "  Op#107 RESHAPE(T#260, T#9[48, 2, 484]) -> [T#261]\n",
      "  Op#108 TRANSPOSE(T#261, T#4[1, 0, 2]) -> [T#262]\n",
      "  Op#109 RESHAPE(T#262, T#10[2, 1, 48, 22, 22]) -> [T#263]\n",
      "  Op#110 GATHER(T#263, T#6[0]) -> [T#264]\n",
      "  Op#111 TRANSPOSE(T#264, T#7[0, 2, 3, 1]) -> [T#265]\n",
      "  Op#112 GATHER(T#263, T#8[1]) -> [T#266]\n",
      "  Op#113 TRANSPOSE(T#266, T#7[0, 2, 3, 1]) -> [T#267]\n",
      "  Op#114 CONV_2D(T#267, T#89, T#88[-25423, -13003, -8121, 49389, 3582, ...]) -> [T#268]\n",
      "  Op#115 DEPTHWISE_CONV_2D(T#268, T#87, T#86[1105, -3274, 1487, -5145, 22444, ...]) -> [T#269]\n",
      "  Op#116 CONV_2D(T#269, T#85, T#84[13138, -2813, 19062, -3393, 11849, ...]) -> [T#270]\n",
      "  Op#117 CONCATENATION(T#265, T#270) -> [T#271]\n",
      "  Op#118 TRANSPOSE(T#271, T#2[0, 3, 1, 2]) -> [T#272]\n",
      "  Op#119 RESHAPE(T#272, T#9[48, 2, 484]) -> [T#273]\n",
      "  Op#120 TRANSPOSE(T#273, T#4[1, 0, 2]) -> [T#274]\n",
      "  Op#121 RESHAPE(T#274, T#10[2, 1, 48, 22, 22]) -> [T#275]\n",
      "  Op#122 GATHER(T#275, T#6[0]) -> [T#276]\n",
      "  Op#123 TRANSPOSE(T#276, T#7[0, 2, 3, 1]) -> [T#277]\n",
      "  Op#124 GATHER(T#275, T#8[1]) -> [T#278]\n",
      "  Op#125 TRANSPOSE(T#278, T#7[0, 2, 3, 1]) -> [T#279]\n",
      "  Op#126 CONV_2D(T#279, T#83, T#82[30865, 28693, -391, -52244, -14517, ...]) -> [T#280]\n",
      "  Op#127 DEPTHWISE_CONV_2D(T#280, T#81, T#80[-9760, -4182, 26286, -10723, -1626, ...]) -> [T#281]\n",
      "  Op#128 CONV_2D(T#281, T#79, T#78[25810, 11650, 8345, 5147, 6514, ...]) -> [T#282]\n",
      "  Op#129 CONCATENATION(T#277, T#282) -> [T#283]\n",
      "  Op#130 TRANSPOSE(T#283, T#2[0, 3, 1, 2]) -> [T#284]\n",
      "  Op#131 RESHAPE(T#284, T#9[48, 2, 484]) -> [T#285]\n",
      "  Op#132 TRANSPOSE(T#285, T#4[1, 0, 2]) -> [T#286]\n",
      "  Op#133 RESHAPE(T#286, T#10[2, 1, 48, 22, 22]) -> [T#287]\n",
      "  Op#134 GATHER(T#287, T#6[0]) -> [T#288]\n",
      "  Op#135 TRANSPOSE(T#288, T#7[0, 2, 3, 1]) -> [T#289]\n",
      "  Op#136 GATHER(T#287, T#8[1]) -> [T#290]\n",
      "  Op#137 TRANSPOSE(T#290, T#7[0, 2, 3, 1]) -> [T#291]\n",
      "  Op#138 CONV_2D(T#291, T#77, T#76[13911, 18952, 15144, 14900, -19989, ...]) -> [T#292]\n",
      "  Op#139 DEPTHWISE_CONV_2D(T#292, T#75, T#74[8958, 8354, 245, -11113, -13829, ...]) -> [T#293]\n",
      "  Op#140 CONV_2D(T#293, T#73, T#72[10920, -4089, 11203, -4882, 12051, ...]) -> [T#294]\n",
      "  Op#141 CONCATENATION(T#289, T#294) -> [T#295]\n",
      "  Op#142 PAD(T#295, T#1[0, 0, 1, 1, 1, ...]) -> [T#296]\n",
      "  Op#143 DEPTHWISE_CONV_2D(T#296, T#71, T#70[-30239, 55104, -19536, 43689, -77229, ...]) -> [T#297]\n",
      "  Op#144 CONV_2D(T#295, T#69, T#68[20245, -981, 3588, -640751, -16157, ...]) -> [T#298]\n",
      "  Op#145 PAD(T#298, T#1[0, 0, 1, 1, 1, ...]) -> [T#299]\n",
      "  Op#146 DEPTHWISE_CONV_2D(T#299, T#67, T#66[7142, 3575, -8626, 0, -5898, ...]) -> [T#300]\n",
      "  Op#147 CONV_2D(T#297, T#65, T#64[16321, 19434, 26201, 23953, 10407, ...]) -> [T#301]\n",
      "  Op#148 CONV_2D(T#300, T#63, T#62[3679, -7674, -1866, -2735, 7043, ...]) -> [T#302]\n",
      "  Op#149 CONCATENATION(T#301, T#302) -> [T#303]\n",
      "  Op#150 TRANSPOSE(T#303, T#2[0, 3, 1, 2]) -> [T#304]\n",
      "  Op#151 RESHAPE(T#304, T#11[96, 2, 121]) -> [T#305]\n",
      "  Op#152 TRANSPOSE(T#305, T#4[1, 0, 2]) -> [T#306]\n",
      "  Op#153 RESHAPE(T#306, T#12[2, 1, 96, 11, 11]) -> [T#307]\n",
      "  Op#154 GATHER(T#307, T#6[0]) -> [T#308]\n",
      "  Op#155 TRANSPOSE(T#308, T#7[0, 2, 3, 1]) -> [T#309]\n",
      "  Op#156 GATHER(T#307, T#8[1]) -> [T#310]\n",
      "  Op#157 TRANSPOSE(T#310, T#7[0, 2, 3, 1]) -> [T#311]\n",
      "  Op#158 CONV_2D(T#311, T#61, T#60[17780, 6849, 6345, 4129, 5135, ...]) -> [T#312]\n",
      "  Op#159 DEPTHWISE_CONV_2D(T#312, T#59, T#58[-12701, 7215, 1250, -17831, 5341, ...]) -> [T#313]\n",
      "  Op#160 CONV_2D(T#313, T#57, T#56[28828, 21791, -4864, 17446, 10433, ...]) -> [T#314]\n",
      "  Op#161 CONCATENATION(T#309, T#314) -> [T#315]\n",
      "  Op#162 TRANSPOSE(T#315, T#2[0, 3, 1, 2]) -> [T#316]\n",
      "  Op#163 RESHAPE(T#316, T#11[96, 2, 121]) -> [T#317]\n",
      "  Op#164 TRANSPOSE(T#317, T#4[1, 0, 2]) -> [T#318]\n",
      "  Op#165 RESHAPE(T#318, T#12[2, 1, 96, 11, 11]) -> [T#319]\n",
      "  Op#166 GATHER(T#319, T#6[0]) -> [T#320]\n",
      "  Op#167 TRANSPOSE(T#320, T#7[0, 2, 3, 1]) -> [T#321]\n",
      "  Op#168 GATHER(T#319, T#8[1]) -> [T#322]\n",
      "  Op#169 TRANSPOSE(T#322, T#7[0, 2, 3, 1]) -> [T#323]\n",
      "  Op#170 CONV_2D(T#323, T#55, T#54[-7313, -17711, -5780, 7097, 12474, ...]) -> [T#324]\n",
      "  Op#171 DEPTHWISE_CONV_2D(T#324, T#53, T#52[-26515, -6427, 6095, -1436, 7733, ...]) -> [T#325]\n",
      "  Op#172 CONV_2D(T#325, T#51, T#50[11347, -4237, 4727, 6739, -12705, ...]) -> [T#326]\n",
      "  Op#173 CONCATENATION(T#321, T#326) -> [T#327]\n",
      "  Op#174 TRANSPOSE(T#327, T#2[0, 3, 1, 2]) -> [T#328]\n",
      "  Op#175 RESHAPE(T#328, T#11[96, 2, 121]) -> [T#329]\n",
      "  Op#176 TRANSPOSE(T#329, T#4[1, 0, 2]) -> [T#330]\n",
      "  Op#177 RESHAPE(T#330, T#12[2, 1, 96, 11, 11]) -> [T#331]\n",
      "  Op#178 GATHER(T#331, T#6[0]) -> [T#332]\n",
      "  Op#179 TRANSPOSE(T#332, T#7[0, 2, 3, 1]) -> [T#333]\n",
      "  Op#180 GATHER(T#331, T#8[1]) -> [T#334]\n",
      "  Op#181 TRANSPOSE(T#334, T#7[0, 2, 3, 1]) -> [T#335]\n",
      "  Op#182 CONV_2D(T#335, T#49, T#48[11571, 2751, -3885, 31476, -850, ...]) -> [T#336]\n",
      "  Op#183 DEPTHWISE_CONV_2D(T#336, T#47, T#46[-2936, 9522, -16965, 18023, 2721, ...]) -> [T#337]\n",
      "  Op#184 CONV_2D(T#337, T#45, T#44[-5824, 424, -6486, -4706, -10507, ...]) -> [T#338]\n",
      "  Op#185 CONCATENATION(T#333, T#338) -> [T#339]\n",
      "  Op#186 RESIZE_NEAREST_NEIGHBOR(T#339, T#13[22, 22]) -> [T#340]\n",
      "  Op#187 CONCATENATION(T#205, T#295, T#340) -> [T#341]\n",
      "  Op#188 CONV_2D(T#341, T#43, T#42[43042, 13210, -822, 36957, 18087, ...]) -> [T#342]\n",
      "  Op#189 DEPTHWISE_CONV_2D(T#342, T#41, T#40[27646, 54820, -4851, 24348, -41217, ...]) -> [T#343]\n",
      "  Op#190 DEPTHWISE_CONV_2D(T#342, T#39, T#38[-6288, 51084, -4885, -6684, 36015, ...]) -> [T#344]\n",
      "  Op#191 DEPTHWISE_CONV_2D(T#344, T#37, T#36[-8475, -3449, -6925, -4598, -19260, ...]) -> [T#345]\n",
      "  Op#192 DEPTHWISE_CONV_2D(T#342, T#35, T#34[-15955, -7340, 4380, -13406, 15739, ...]) -> [T#346]\n",
      "  Op#193 DEPTHWISE_CONV_2D(T#346, T#33, T#32[-4144, 33530, -5613, -19653, -42067, ...]) -> [T#347]\n",
      "  Op#194 DEPTHWISE_CONV_2D(T#347, T#31, T#30[-3299, -9476, -4905, 26188, -33654, ...]) -> [T#348]\n",
      "  Op#195 CONCATENATION(T#343, T#345, T#348) -> [T#349]\n",
      "  Op#196 CONV_2D(T#349, T#29, T#28[11335, 25744, -375, 806, 28942, ...]) -> [T#350]\n",
      "  Op#197 ADD(T#342, T#350) -> [T#351]\n",
      "  Op#198 CONV_2D(T#351, T#27, T#26[27291, -9502, -7144, 829, -6161, ...]) -> [T#352]\n",
      "  Op#199 DEPTHWISE_CONV_2D(T#352, T#25, T#24[49547, 340, 7240, -562, -29729, ...]) -> [T#353]\n",
      "  Op#200 DEPTHWISE_CONV_2D(T#352, T#23, T#22[19879, 10487, -89, 1040, -189, ...]) -> [T#354]\n",
      "  Op#201 DEPTHWISE_CONV_2D(T#352, T#21, T#20[90243, 44101, -1404, -59065, -12107, ...]) -> [T#355]\n",
      "  Op#202 CONV_2D(T#353, T#19, T#18[-16366]) -> [T#356]\n",
      "  Op#203 LOGISTIC(T#356) -> [T#357]\n",
      "  Op#204 QUANTIZE(T#357) -> [T#358]\n",
      "  Op#205 CONV_2D(T#354, T#17, T#16[-2999, 5057, -5857, -6481]) -> [T#359]\n",
      "  Op#206 CONV_2D(T#355, T#15, T#14[-383, 3148, 4811, -5079, -25443, ...]) -> [T#360]\n",
      "  Op#207 SOFTMAX(T#360) -> [T#361]\n",
      "  Op#208 QUANTIZE(T#361) -> [T#362]\n",
      "  Op#209 CONCATENATION(T#358, T#359, T#362) -> [T#363]\n",
      "  Op#210 QUANTIZE(T#363) -> [T#364]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_input.1:0) shape:[1, 352, 352, 3], type:UINT8\n",
      "  T#1(Const_110) shape:[4, 2], type:INT32 RO 32 bytes, buffer: 2, data:[0, 0, 1, 1, 1, ...]\n",
      "  T#2(model_5/tf.compat.v1.transpose_1232/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 3, data:[0, 3, 1, 2]\n",
      "  T#3(model_5/tf.reshape_31/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 4, data:[24, 2, 1936]\n",
      "  T#4(model_5/tf.compat.v1.transpose_1233/transpose/perm) shape:[3], type:INT32 RO 12 bytes, buffer: 5, data:[1, 0, 2]\n",
      "  T#5(model_5/tf.reshape_32/Reshape/shape) shape:[5], type:INT32 RO 20 bytes, buffer: 6, data:[2, 1, 24, 44, 44]\n",
      "  T#6(model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[], type:INT32 RO 4 bytes, buffer: 7, data:[0]\n",
      "  T#7(model_5/tf.compat.v1.transpose_1235/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 8, data:[0, 2, 3, 1]\n",
      "  T#8(model_5/tf.compat.v1.gather_27/GatherV2/indices) shape:[], type:INT32 RO 4 bytes, buffer: 9, data:[1]\n",
      "  T#9(model_5/tf.reshape_37/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 10, data:[48, 2, 484]\n",
      "  T#10(model_5/tf.reshape_38/Reshape/shape) shape:[5], type:INT32 RO 20 bytes, buffer: 11, data:[2, 1, 48, 22, 22]\n",
      "  T#11(model_5/tf.reshape_51/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 12, data:[96, 2, 121]\n",
      "  T#12(model_5/tf.reshape_52/Reshape/shape) shape:[5], type:INT32 RO 20 bytes, buffer: 13, data:[2, 1, 96, 11, 11]\n",
      "  T#13(model_5/lambda_3/Resize_226/size) shape:[2], type:INT32 RO 8 bytes, buffer: 14, data:[22, 22]\n",
      "  T#14(Const_5) shape:[80], type:INT32 RO 320 bytes, buffer: 15, data:[-383, 3148, 4811, -5079, -25443, ...]\n",
      "  T#15(model_5/tf.nn.convolution_149/convolution) shape:[80, 1, 1, 96], type:INT8 RO 7680 bytes, buffer: 16, data:[., ., ., ., ., ...]\n",
      "  T#16(Const) shape:[4], type:INT32 RO 16 bytes, buffer: 17, data:[-2999, 5057, -5857, -6481]\n",
      "  T#17(model_5/tf.nn.convolution_148/convolution) shape:[4, 1, 1, 96], type:INT8 RO 384 bytes, buffer: 18, data:[., ., ., ., ., ...]\n",
      "  T#18(Const_1) shape:[1], type:INT32 RO 4 bytes, buffer: 19, data:[-16366]\n",
      "  T#19(model_5/tf.nn.convolution_147/convolution) shape:[1, 1, 1, 96], type:INT8 RO 96 bytes, buffer: 20, data:[., !, ., ., ., ...]\n",
      "  T#20(Const_10) shape:[96], type:INT32 RO 384 bytes, buffer: 21, data:[90243, 44101, -1404, -59065, -12107, ...]\n",
      "  T#21(model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 22, data:[., ., ., ., ., ...]\n",
      "  T#22(Const_4) shape:[96], type:INT32 RO 384 bytes, buffer: 23, data:[19879, 10487, -89, 1040, -189, ...]\n",
      "  T#23(model_5/tf.compat.v1.nn.depthwise_conv2d_54/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 24, data:[., ., .,  , ., ...]\n",
      "  T#24(Const_6) shape:[96], type:INT32 RO 384 bytes, buffer: 25, data:[49547, 340, 7240, -562, -29729, ...]\n",
      "  T#25(model_5/tf.compat.v1.nn.depthwise_conv2d_53/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 26, data:[., ., ., ., I, ...]\n",
      "  T#26(Const_12) shape:[96], type:INT32 RO 384 bytes, buffer: 27, data:[27291, -9502, -7144, 829, -6161, ...]\n",
      "  T#27(model_5/tf.nn.convolution_146/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 28, data:[., ., ., ., ., ...]\n",
      "  T#28(Const_14) shape:[96], type:INT32 RO 384 bytes, buffer: 29, data:[11335, 25744, -375, 806, 28942, ...]\n",
      "  T#29(model_5/tf.nn.convolution_145/convolution) shape:[96, 1, 1, 288], type:INT8 RO 27648 bytes, buffer: 30, data:[., ., ., ., ., ...]\n",
      "  T#30(Const_18) shape:[96], type:INT32 RO 384 bytes, buffer: 31, data:[-3299, -9476, -4905, 26188, -33654, ...]\n",
      "  T#31(model_5/tf.compat.v1.nn.depthwise_conv2d_52/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 32, data:[., ., H, ., :, ...]\n",
      "  T#32(Const_23) shape:[96], type:INT32 RO 384 bytes, buffer: 33, data:[-4144, 33530, -5613, -19653, -42067, ...]\n",
      "  T#33(model_5/tf.compat.v1.nn.depthwise_conv2d_51/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 34, data:[-, ., ., ., a, ...]\n",
      "  T#34(Const_26) shape:[96], type:INT32 RO 384 bytes, buffer: 35, data:[-15955, -7340, 4380, -13406, 15739, ...]\n",
      "  T#35(model_5/tf.compat.v1.nn.depthwise_conv2d_49/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 36, data:[., w, ., b, ., ...]\n",
      "  T#36(Const_17) shape:[96], type:INT32 RO 384 bytes, buffer: 37, data:[-8475, -3449, -6925, -4598, -19260, ...]\n",
      "  T#37(model_5/tf.compat.v1.nn.depthwise_conv2d_50/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 38, data:[., ., ., ., O, ...]\n",
      "  T#38(Const_22) shape:[96], type:INT32 RO 384 bytes, buffer: 39, data:[-6288, 51084, -4885, -6684, 36015, ...]\n",
      "  T#39(model_5/tf.compat.v1.nn.depthwise_conv2d_48/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 40, data:[., ., ., ., ., ...]\n",
      "  T#40(Const_16) shape:[96], type:INT32 RO 384 bytes, buffer: 41, data:[27646, 54820, -4851, 24348, -41217, ...]\n",
      "  T#41(model_5/tf.compat.v1.nn.depthwise_conv2d_47/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 42, data:[., ., 3, ., >, ...]\n",
      "  T#42(Const_28) shape:[96], type:INT32 RO 384 bytes, buffer: 43, data:[43042, 13210, -822, 36957, 18087, ...]\n",
      "  T#43(model_5/tf.nn.convolution_144/convolution) shape:[96, 1, 1, 336], type:INT8 RO 32256 bytes, buffer: 44, data:[., ., ., ., ., ...]\n",
      "  T#44(Const_30) shape:[96], type:INT32 RO 384 bytes, buffer: 45, data:[-5824, 424, -6486, -4706, -10507, ...]\n",
      "  T#45(model_5/tf.nn.convolution_143/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 46, data:[., v, ., ., !, ...]\n",
      "  T#46(Const_32) shape:[96], type:INT32 RO 384 bytes, buffer: 47, data:[-2936, 9522, -16965, 18023, 2721, ...]\n",
      "  T#47(model_5/tf.compat.v1.nn.depthwise_conv2d_46/depthwise) shape:[1, 3, 3, 96], type:INT8 RO 864 bytes, buffer: 48, data:[., ., k, ., ., ...]\n",
      "  T#48(Const_34) shape:[96], type:INT32 RO 384 bytes, buffer: 49, data:[11571, 2751, -3885, 31476, -850, ...]\n",
      "  T#49(model_5/tf.nn.convolution_142/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 50, data:[., ., ., ., ., ...]\n",
      "  T#50(Const_36) shape:[96], type:INT32 RO 384 bytes, buffer: 51, data:[11347, -4237, 4727, 6739, -12705, ...]\n",
      "  T#51(model_5/tf.nn.convolution_141/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 52, data:[4, ., ., ., ., ...]\n",
      "  T#52(Const_38) shape:[96], type:INT32 RO 384 bytes, buffer: 53, data:[-26515, -6427, 6095, -1436, 7733, ...]\n",
      "  T#53(model_5/tf.compat.v1.nn.depthwise_conv2d_45/depthwise) shape:[1, 3, 3, 96], type:INT8 RO 864 bytes, buffer: 54, data:[d, ., ., ], ., ...]\n",
      "  T#54(Const_40) shape:[96], type:INT32 RO 384 bytes, buffer: 55, data:[-7313, -17711, -5780, 7097, 12474, ...]\n",
      "  T#55(model_5/tf.nn.convolution_140/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 56, data:[., >, i, ., ., ...]\n",
      "  T#56(Const_42) shape:[96], type:INT32 RO 384 bytes, buffer: 57, data:[28828, 21791, -4864, 17446, 10433, ...]\n",
      "  T#57(model_5/tf.nn.convolution_139/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 58, data:[., ., ., ., ., ...]\n",
      "  T#58(Const_44) shape:[96], type:INT32 RO 384 bytes, buffer: 59, data:[-12701, 7215, 1250, -17831, 5341, ...]\n",
      "  T#59(model_5/tf.compat.v1.nn.depthwise_conv2d_44/depthwise) shape:[1, 3, 3, 96], type:INT8 RO 864 bytes, buffer: 60, data:[s, ., ., \\, ., ...]\n",
      "  T#60(Const_46) shape:[96], type:INT32 RO 384 bytes, buffer: 61, data:[17780, 6849, 6345, 4129, 5135, ...]\n",
      "  T#61(model_5/tf.nn.convolution_138/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 62, data:[,, ., ., ., ., ...]\n",
      "  T#62(Const_49) shape:[96], type:INT32 RO 384 bytes, buffer: 63, data:[3679, -7674, -1866, -2735, 7043, ...]\n",
      "  T#63(model_5/tf.nn.convolution_137/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 64, data:[., ., ,, ., ., ...]\n",
      "  T#64(Const_48) shape:[96], type:INT32 RO 384 bytes, buffer: 65, data:[16321, 19434, 26201, 23953, 10407, ...]\n",
      "  T#65(model_5/tf.nn.convolution_136/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 66, data:[., E, ., ., ., ...]\n",
      "  T#66(Const_53) shape:[96], type:INT32 RO 384 bytes, buffer: 67, data:[7142, 3575, -8626, 0, -5898, ...]\n",
      "  T#67(model_5/tf.compat.v1.nn.depthwise_conv2d_43/depthwise) shape:[1, 3, 3, 96], type:INT8 RO 864 bytes, buffer: 68, data:[., ., ., ., ), ...]\n",
      "  T#68(Const_58) shape:[96], type:INT32 RO 384 bytes, buffer: 69, data:[20245, -981, 3588, -640751, -16157, ...]\n",
      "  T#69(model_5/tf.nn.convolution_135/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 70, data:[., ., ., ., ., ...]\n",
      "  T#70(Const_52) shape:[96], type:INT32 RO 384 bytes, buffer: 71, data:[-30239, 55104, -19536, 43689, -77229, ...]\n",
      "  T#71(model_5/tf.compat.v1.nn.depthwise_conv2d_42/depthwise) shape:[1, 3, 3, 96], type:INT8 RO 864 bytes, buffer: 72, data:[R, ., ., ., @, ...]\n",
      "  T#72(Const_60) shape:[48], type:INT32 RO 192 bytes, buffer: 73, data:[10920, -4089, 11203, -4882, 12051, ...]\n",
      "  T#73(model_5/tf.nn.convolution_134/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 74, data:[., ., U, ., ., ...]\n",
      "  T#74(Const_62) shape:[48], type:INT32 RO 192 bytes, buffer: 75, data:[8958, 8354, 245, -11113, -13829, ...]\n",
      "  T#75(model_5/tf.compat.v1.nn.depthwise_conv2d_41/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 76, data:[., ., ., ., ,, ...]\n",
      "  T#76(Const_64) shape:[48], type:INT32 RO 192 bytes, buffer: 77, data:[13911, 18952, 15144, 14900, -19989, ...]\n",
      "  T#77(model_5/tf.nn.convolution_133/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 78, data:[., ., ., ., ., ...]\n",
      "  T#78(Const_66) shape:[48], type:INT32 RO 192 bytes, buffer: 79, data:[25810, 11650, 8345, 5147, 6514, ...]\n",
      "  T#79(model_5/tf.nn.convolution_132/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 80, data:[!, ., ,, ., ., ...]\n",
      "  T#80(Const_68) shape:[48], type:INT32 RO 192 bytes, buffer: 81, data:[-9760, -4182, 26286, -10723, -1626, ...]\n",
      "  T#81(model_5/tf.compat.v1.nn.depthwise_conv2d_40/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 82, data:[$, ., ., #, ., ...]\n",
      "  T#82(Const_70) shape:[48], type:INT32 RO 192 bytes, buffer: 83, data:[30865, 28693, -391, -52244, -14517, ...]\n",
      "  T#83(model_5/tf.nn.convolution_131/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 84, data:[., ., ., ., ., ...]\n",
      "  T#84(Const_72) shape:[48], type:INT32 RO 192 bytes, buffer: 85, data:[13138, -2813, 19062, -3393, 11849, ...]\n",
      "  T#85(model_5/tf.nn.convolution_130/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 86, data:[., ., ., ., !, ...]\n",
      "  T#86(Const_74) shape:[48], type:INT32 RO 192 bytes, buffer: 87, data:[1105, -3274, 1487, -5145, 22444, ...]\n",
      "  T#87(model_5/tf.compat.v1.nn.depthwise_conv2d_39/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 88, data:[., ., ., ., ., ...]\n",
      "  T#88(Const_76) shape:[48], type:INT32 RO 192 bytes, buffer: 89, data:[-25423, -13003, -8121, 49389, 3582, ...]\n",
      "  T#89(model_5/tf.nn.convolution_129/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 90, data:[., M, ., ., ., ...]\n",
      "  T#90(Const_78) shape:[48], type:INT32 RO 192 bytes, buffer: 91, data:[10438, -325, -4831, -1815, 9648, ...]\n",
      "  T#91(model_5/tf.nn.convolution_128/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 92, data:[., ., ., ., ., ...]\n",
      "  T#92(Const_80) shape:[48], type:INT32 RO 192 bytes, buffer: 93, data:[-1373, -4742, -19772, -1982, 1766, ...]\n",
      "  T#93(model_5/tf.compat.v1.nn.depthwise_conv2d_38/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 94, data:[., ., 4, ., ., ...]\n",
      "  T#94(Const_82) shape:[48], type:INT32 RO 192 bytes, buffer: 95, data:[7925, -12253, 10376, 14230, 14162, ...]\n",
      "  T#95(model_5/tf.nn.convolution_127/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 96, data:[., >, ., ., ., ...]\n",
      "  T#96(Const_84) shape:[48], type:INT32 RO 192 bytes, buffer: 97, data:[19672, -1440, 321, 15830, 13908, ...]\n",
      "  T#97(model_5/tf.nn.convolution_126/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 98, data:[&, ., .,  , ., ...]\n",
      "  T#98(Const_86) shape:[48], type:INT32 RO 192 bytes, buffer: 99, data:[11464, -6183, 34609, 6495, 11674, ...]\n",
      "  T#99(model_5/tf.compat.v1.nn.depthwise_conv2d_37/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 100, data:[., ., ., ., ., ...]\n",
      "  T#100(Const_88) shape:[48], type:INT32 RO 192 bytes, buffer: 101, data:[13493, 7332, 33461, 37, -11608, ...]\n",
      "  T#101(model_5/tf.nn.convolution_125/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 102, data:[., ., ., ., ., ...]\n",
      "  T#102(Const_90) shape:[48], type:INT32 RO 192 bytes, buffer: 103, data:[7164, 145, 3388, 129, 13181, ...]\n",
      "  T#103(model_5/tf.nn.convolution_124/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 104, data:[., ., ., ., ., ...]\n",
      "  T#104(Const_92) shape:[48], type:INT32 RO 192 bytes, buffer: 105, data:[5625, -1187, -5420, -137, 495, ...]\n",
      "  T#105(model_5/tf.compat.v1.nn.depthwise_conv2d_36/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 106, data:[., ., ., ., \", ...]\n",
      "  T#106(Const_94) shape:[48], type:INT32 RO 192 bytes, buffer: 107, data:[22333, 33802, -4994, 8945, 10056, ...]\n",
      "  T#107(model_5/tf.nn.convolution_123/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 108, data:[2, 7, ., ., ., ...]\n",
      "  T#108(Const_96) shape:[48], type:INT32 RO 192 bytes, buffer: 109, data:[380, -343, -762, -2669, 15289, ...]\n",
      "  T#109(model_5/tf.nn.convolution_122/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 110, data:[., ., ., $, ., ...]\n",
      "  T#110(Const_98) shape:[48], type:INT32 RO 192 bytes, buffer: 111, data:[-720, 3134, -313, -6440, 15, ...]\n",
      "  T#111(model_5/tf.compat.v1.nn.depthwise_conv2d_35/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 112, data:[., ., ., ., ., ...]\n",
      "  T#112(Const_100) shape:[48], type:INT32 RO 192 bytes, buffer: 113, data:[6010, 39097, 8633, -6556, -8011, ...]\n",
      "  T#113(model_5/tf.nn.convolution_121/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 114, data:[., ., +, *, I, ...]\n",
      "  T#114(Const_103) shape:[48], type:INT32 RO 192 bytes, buffer: 115, data:[7625, 67, 5778, 3673, 12870, ...]\n",
      "  T#115(model_5/tf.nn.convolution_120/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 116, data:[.,  , ., ., ., ...]\n",
      "  T#116(Const_102) shape:[48], type:INT32 RO 192 bytes, buffer: 117, data:[8468, -53, 1224, 9776, 4737, ...]\n",
      "  T#117(model_5/tf.nn.convolution_119/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 118, data:[., ., ., T, $, ...]\n",
      "  T#118(Const_107) shape:[48], type:INT32 RO 192 bytes, buffer: 119, data:[2621, 6168, -5457, 1139, 5203, ...]\n",
      "  T#119(model_5/tf.compat.v1.nn.depthwise_conv2d_34/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 120, data:[., ., ', ., ., ...]\n",
      "  T#120(Const_112) shape:[48], type:INT32 RO 192 bytes, buffer: 121, data:[-10134, 21600, 1134, -9801, 23955, ...]\n",
      "  T#121(model_5/tf.nn.convolution_118/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 122, data:[., ., ., ., ., ...]\n",
      "  T#122(Const_106) shape:[48], type:INT32 RO 192 bytes, buffer: 123, data:[21912, -7343, -40557, 55630, 6939, ...]\n",
      "  T#123(model_5/tf.compat.v1.nn.depthwise_conv2d_33/depthwise) shape:[1, 3, 3, 48], type:INT8 RO 432 bytes, buffer: 124, data:[., ., ., ., ., ...]\n",
      "  T#124(Const_114) shape:[24], type:INT32 RO 96 bytes, buffer: 125, data:[150, 29, 402, -262, 1099, ...]\n",
      "  T#125(model_5/tf.nn.convolution_117/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 126, data:[., ., ., ., ., ...]\n",
      "  T#126(Const_116) shape:[24], type:INT32 RO 96 bytes, buffer: 127, data:[-1833, -530, 27, -2318, -1294, ...]\n",
      "  T#127(model_5/tf.compat.v1.nn.depthwise_conv2d_32/depthwise) shape:[1, 3, 3, 24], type:INT8 RO 216 bytes, buffer: 128, data:[., ., ., ., ., ...]\n",
      "  T#128(Const_118) shape:[24], type:INT32 RO 96 bytes, buffer: 129, data:[37739, 8220, -700, 31554, -3491, ...]\n",
      "  T#129(model_5/tf.nn.convolution_116/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 130, data:[., ., ., ., ., ...]\n",
      "  T#130(Const_120) shape:[24], type:INT32 RO 96 bytes, buffer: 131, data:[77, -107, 74, -427, 3715, ...]\n",
      "  T#131(model_5/tf.nn.convolution_115/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 132, data:[\n",
      ", ., ., ., ., ...]\n",
      "  T#132(Const_122) shape:[24], type:INT32 RO 96 bytes, buffer: 133, data:[5595, 3102, -5522, -457, 1295, ...]\n",
      "  T#133(model_5/tf.compat.v1.nn.depthwise_conv2d_31/depthwise) shape:[1, 3, 3, 24], type:INT8 RO 216 bytes, buffer: 134, data:[., ., ., ., ., ...]\n",
      "  T#134(Const_124) shape:[24], type:INT32 RO 96 bytes, buffer: 135, data:[-10065, 21693, 5077, 45674, 26759, ...]\n",
      "  T#135(model_5/tf.nn.convolution_114/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 136, data:[., E, ., N, ., ...]\n",
      "  T#136(Const_126) shape:[24], type:INT32 RO 96 bytes, buffer: 137, data:[1491, 264, 3939, 1035, 800, ...]\n",
      "  T#137(model_5/tf.nn.convolution_113/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 138, data:[:, ., ., ., *, ...]\n",
      "  T#138(Const_128) shape:[24], type:INT32 RO 96 bytes, buffer: 139, data:[6241, 852, -1314, 2054, 757, ...]\n",
      "  T#139(model_5/tf.compat.v1.nn.depthwise_conv2d_30/depthwise) shape:[1, 3, 3, 24], type:INT8 RO 216 bytes, buffer: 140, data:[., ., ., ., ., ...]\n",
      "  T#140(Const_130) shape:[24], type:INT32 RO 96 bytes, buffer: 141, data:[24439, 9724, 5712, 48839, 13942, ...]\n",
      "  T#141(model_5/tf.nn.convolution_112/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 142, data:[., 7, ., ., ., ...]\n",
      "  T#142(Const_133) shape:[24], type:INT32 RO 96 bytes, buffer: 143, data:[17702, 1890, 3351, -1676, 12323, ...]\n",
      "  T#143(model_5/tf.nn.convolution_111/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 144, data:[., ., ., ., ., ...]\n",
      "  T#144(Const_132) shape:[24], type:INT32 RO 96 bytes, buffer: 145, data:[3635, -574, 1858, 3546, 877, ...]\n",
      "  T#145(model_5/tf.nn.convolution_110/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 146, data:[., &, ., ., ., ...]\n",
      "  T#146(Const_137) shape:[24], type:INT32 RO 96 bytes, buffer: 147, data:[217, 9713, -5683, -4704, 366, ...]\n",
      "  T#147(model_5/tf.compat.v1.nn.depthwise_conv2d_29/depthwise) shape:[1, 3, 3, 24], type:INT8 RO 216 bytes, buffer: 148, data:[., ., ., ., ., ...]\n",
      "  T#148(Const_142) shape:[24], type:INT32 RO 96 bytes, buffer: 149, data:[-20606, -9339, 8208, -5232, 18590, ...]\n",
      "  T#149(model_5/tf.nn.convolution_109/convolution) shape:[24, 1, 1, 24], type:INT8 RO 576 bytes, buffer: 150, data:[Y, ., `, c, ., ...]\n",
      "  T#150(Const_136) shape:[24], type:INT32 RO 96 bytes, buffer: 151, data:[3620, -14626, -4446, -6719, 2775, ...]\n",
      "  T#151(model_5/tf.compat.v1.nn.depthwise_conv2d_28/depthwise) shape:[1, 3, 3, 24], type:INT8 RO 216 bytes, buffer: 152, data:[., 1, ., ., ., ...]\n",
      "  T#152(Const_144) shape:[24], type:INT32 RO 96 bytes, buffer: 153, data:[96096, 32069, 39896, 44835, 4403, ...]\n",
      "  T#153(model_5/tf.nn.convolution_108/convolution) shape:[24, 3, 3, 3], type:INT8 RO 648 bytes, buffer: 154, data:[., ., v, ., ., ...]\n",
      "  T#154(tfl.quantize) shape:[1, 352, 352, 3], type:INT8\n",
      "  T#155(model_5/tf.compat.v1.pad_16/Pad) shape:[1, 354, 354, 3], type:INT8\n",
      "  T#156(model_5/tf.nn.relu_48/Relu;model_5/tf.math.add_144/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_108/convolution;Const_144) shape:[1, 176, 176, 24], type:INT8\n",
      "  T#157(model_5/tf.compat.v1.pad_17/Pad) shape:[1, 178, 178, 24], type:INT8\n",
      "  T#158(model_5/tf.nn.max_pool2d_1/MaxPool2d) shape:[1, 88, 88, 24], type:INT8\n",
      "  T#159(model_5/tf.compat.v1.pad_18/Pad) shape:[1, 90, 90, 24], type:INT8\n",
      "  T#160(model_5/tf.math.add_145/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_28/depthwise;Const_136) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#161(model_5/tf.nn.relu_49/Relu;model_5/tf.math.add_146/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_109/convolution;Const_142) shape:[1, 88, 88, 24], type:INT8\n",
      "  T#162(model_5/tf.compat.v1.pad_19/Pad) shape:[1, 90, 90, 24], type:INT8\n",
      "  T#163(model_5/tf.math.add_148/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_29/depthwise;Const_137) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#164(model_5/tf.nn.relu_50/Relu;model_5/tf.math.add_147/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_110/convolution;Const_132) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#165(model_5/tf.nn.relu_51/Relu;model_5/tf.math.add_149/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_111/convolution;Const_133) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#166(model_5/tf.concat_615/concat) shape:[1, 44, 44, 48], type:INT8\n",
      "  T#167(model_5/tf.compat.v1.transpose_1232/transpose) shape:[1, 48, 44, 44], type:INT8\n",
      "  T#168(model_5/tf.reshape_31/Reshape) shape:[24, 2, 1936], type:INT8\n",
      "  T#169(model_5/tf.compat.v1.transpose_1233/transpose) shape:[2, 24, 1936], type:INT8\n",
      "  T#170(model_5/tf.reshape_32/Reshape) shape:[2, 1, 24, 44, 44], type:INT8\n",
      "  T#171(model_5/tf.compat.v1.gather_26/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:INT8\n",
      "  T#172(model_5/tf.compat.v1.transpose_1236/transpose) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#173(model_5/tf.compat.v1.gather_27/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:INT8\n",
      "  T#174(model_5/tf.compat.v1.transpose_1235/transpose) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#175(model_5/tf.nn.relu_52/Relu;model_5/tf.math.add_150/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_112/convolution;Const_130) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#176(model_5/tf.math.add_151/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_30/depthwise;Const_128) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#177(model_5/tf.nn.relu_53/Relu;model_5/tf.math.add_152/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_113/convolution;Const_126) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#178(model_5/tf.concat_616/concat) shape:[1, 44, 44, 48], type:INT8\n",
      "  T#179(model_5/tf.compat.v1.transpose_1237/transpose) shape:[1, 48, 44, 44], type:INT8\n",
      "  T#180(model_5/tf.reshape_33/Reshape) shape:[24, 2, 1936], type:INT8\n",
      "  T#181(model_5/tf.compat.v1.transpose_1238/transpose) shape:[2, 24, 1936], type:INT8\n",
      "  T#182(model_5/tf.reshape_34/Reshape) shape:[2, 1, 24, 44, 44], type:INT8\n",
      "  T#183(model_5/tf.compat.v1.gather_28/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:INT8\n",
      "  T#184(model_5/tf.compat.v1.transpose_1241/transpose) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#185(model_5/tf.compat.v1.gather_29/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:INT8\n",
      "  T#186(model_5/tf.compat.v1.transpose_1240/transpose) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#187(model_5/tf.nn.relu_54/Relu;model_5/tf.math.add_153/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_114/convolution;Const_124) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#188(model_5/tf.math.add_154/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_31/depthwise;Const_122) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#189(model_5/tf.nn.relu_55/Relu;model_5/tf.math.add_155/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_115/convolution;Const_120) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#190(model_5/tf.concat_617/concat) shape:[1, 44, 44, 48], type:INT8\n",
      "  T#191(model_5/tf.compat.v1.transpose_1242/transpose) shape:[1, 48, 44, 44], type:INT8\n",
      "  T#192(model_5/tf.reshape_35/Reshape) shape:[24, 2, 1936], type:INT8\n",
      "  T#193(model_5/tf.compat.v1.transpose_1243/transpose) shape:[2, 24, 1936], type:INT8\n",
      "  T#194(model_5/tf.reshape_36/Reshape) shape:[2, 1, 24, 44, 44], type:INT8\n",
      "  T#195(model_5/tf.compat.v1.gather_30/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:INT8\n",
      "  T#196(model_5/tf.compat.v1.transpose_1246/transpose) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#197(model_5/tf.compat.v1.gather_31/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:INT8\n",
      "  T#198(model_5/tf.compat.v1.transpose_1245/transpose) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#199(model_5/tf.nn.relu_56/Relu;model_5/tf.math.add_156/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_116/convolution;Const_118) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#200(model_5/tf.math.add_157/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_32/depthwise;Const_116) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#201(model_5/tf.nn.relu_57/Relu;model_5/tf.math.add_158/Add;model_5/tf.nn.convolution_117/convolution;Const_114) shape:[1, 44, 44, 24], type:INT8\n",
      "  T#202(model_5/tf.concat_618/concat) shape:[1, 44, 44, 48], type:INT8\n",
      "  T#203(model_5/tf.compat.v1.pad_20/Pad) shape:[1, 46, 46, 48], type:INT8\n",
      "  T#204(model_5/tf.math.add_159/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_33/depthwise;Const_106) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#205(model_5/tf.compat.v1.nn.avg_pool_1/AvgPool) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#206(model_5/tf.nn.relu_58/Relu;model_5/tf.math.add_160/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_118/convolution;Const_112) shape:[1, 44, 44, 48], type:INT8\n",
      "  T#207(model_5/tf.compat.v1.pad_22/Pad) shape:[1, 46, 46, 48], type:INT8\n",
      "  T#208(model_5/tf.math.add_162/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_34/depthwise;Const_107) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#209(model_5/tf.nn.relu_59/Relu;model_5/tf.math.add_161/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_119/convolution;Const_102) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#210(model_5/tf.nn.relu_60/Relu;model_5/tf.math.add_163/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_120/convolution;Const_103) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#211(model_5/tf.concat_619/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#212(model_5/tf.compat.v1.transpose_1247/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#213(model_5/tf.reshape_37/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#214(model_5/tf.compat.v1.transpose_1248/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#215(model_5/tf.reshape_38/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#216(model_5/tf.compat.v1.gather_32/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#217(model_5/tf.compat.v1.transpose_1251/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#218(model_5/tf.compat.v1.gather_33/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#219(model_5/tf.compat.v1.transpose_1250/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#220(model_5/tf.nn.relu_61/Relu;model_5/tf.math.add_164/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_121/convolution;Const_100) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#221(model_5/tf.math.add_165/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_35/depthwise;Const_98) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#222(model_5/tf.nn.relu_62/Relu;model_5/tf.math.add_166/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_122/convolution;Const_96) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#223(model_5/tf.concat_620/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#224(model_5/tf.compat.v1.transpose_1252/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#225(model_5/tf.reshape_39/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#226(model_5/tf.compat.v1.transpose_1253/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#227(model_5/tf.reshape_40/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#228(model_5/tf.compat.v1.gather_34/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#229(model_5/tf.compat.v1.transpose_1256/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#230(model_5/tf.compat.v1.gather_35/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#231(model_5/tf.compat.v1.transpose_1255/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#232(model_5/tf.nn.relu_63/Relu;model_5/tf.math.add_167/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_123/convolution;Const_94) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#233(model_5/tf.math.add_168/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_36/depthwise;Const_92) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#234(model_5/tf.nn.relu_64/Relu;model_5/tf.math.add_169/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_124/convolution;Const_90) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#235(model_5/tf.concat_621/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#236(model_5/tf.compat.v1.transpose_1257/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#237(model_5/tf.reshape_41/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#238(model_5/tf.compat.v1.transpose_1258/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#239(model_5/tf.reshape_42/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#240(model_5/tf.compat.v1.gather_36/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#241(model_5/tf.compat.v1.transpose_1261/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#242(model_5/tf.compat.v1.gather_37/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#243(model_5/tf.compat.v1.transpose_1260/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#244(model_5/tf.nn.relu_65/Relu;model_5/tf.math.add_170/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_125/convolution;Const_88) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#245(model_5/tf.math.add_171/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_37/depthwise;Const_86) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#246(model_5/tf.nn.relu_66/Relu;model_5/tf.math.add_172/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_126/convolution;Const_84) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#247(model_5/tf.concat_622/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#248(model_5/tf.compat.v1.transpose_1262/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#249(model_5/tf.reshape_43/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#250(model_5/tf.compat.v1.transpose_1263/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#251(model_5/tf.reshape_44/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#252(model_5/tf.compat.v1.gather_38/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#253(model_5/tf.compat.v1.transpose_1266/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#254(model_5/tf.compat.v1.gather_39/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#255(model_5/tf.compat.v1.transpose_1265/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#256(model_5/tf.nn.relu_67/Relu;model_5/tf.math.add_173/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_127/convolution;Const_82) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#257(model_5/tf.math.add_174/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_38/depthwise;Const_80) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#258(model_5/tf.nn.relu_68/Relu;model_5/tf.math.add_175/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_128/convolution;Const_78) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#259(model_5/tf.concat_623/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#260(model_5/tf.compat.v1.transpose_1267/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#261(model_5/tf.reshape_45/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#262(model_5/tf.compat.v1.transpose_1268/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#263(model_5/tf.reshape_46/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#264(model_5/tf.compat.v1.gather_40/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#265(model_5/tf.compat.v1.transpose_1271/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#266(model_5/tf.compat.v1.gather_41/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#267(model_5/tf.compat.v1.transpose_1270/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#268(model_5/tf.nn.relu_69/Relu;model_5/tf.math.add_176/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_129/convolution;Const_76) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#269(model_5/tf.math.add_177/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_39/depthwise;Const_74) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#270(model_5/tf.nn.relu_70/Relu;model_5/tf.math.add_178/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_130/convolution;Const_72) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#271(model_5/tf.concat_624/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#272(model_5/tf.compat.v1.transpose_1272/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#273(model_5/tf.reshape_47/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#274(model_5/tf.compat.v1.transpose_1273/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#275(model_5/tf.reshape_48/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#276(model_5/tf.compat.v1.gather_42/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#277(model_5/tf.compat.v1.transpose_1276/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#278(model_5/tf.compat.v1.gather_43/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#279(model_5/tf.compat.v1.transpose_1275/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#280(model_5/tf.nn.relu_71/Relu;model_5/tf.math.add_179/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_131/convolution;Const_70) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#281(model_5/tf.math.add_180/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_40/depthwise;Const_68) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#282(model_5/tf.nn.relu_72/Relu;model_5/tf.math.add_181/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_132/convolution;Const_66) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#283(model_5/tf.concat_625/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#284(model_5/tf.compat.v1.transpose_1277/transpose) shape:[1, 96, 22, 22], type:INT8\n",
      "  T#285(model_5/tf.reshape_49/Reshape) shape:[48, 2, 484], type:INT8\n",
      "  T#286(model_5/tf.compat.v1.transpose_1278/transpose) shape:[2, 48, 484], type:INT8\n",
      "  T#287(model_5/tf.reshape_50/Reshape) shape:[2, 1, 48, 22, 22], type:INT8\n",
      "  T#288(model_5/tf.compat.v1.gather_44/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#289(model_5/tf.compat.v1.transpose_1281/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#290(model_5/tf.compat.v1.gather_45/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:INT8\n",
      "  T#291(model_5/tf.compat.v1.transpose_1280/transpose) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#292(model_5/tf.nn.relu_73/Relu;model_5/tf.math.add_182/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_133/convolution;Const_64) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#293(model_5/tf.math.add_183/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_41/depthwise;Const_62) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#294(model_5/tf.nn.relu_74/Relu;model_5/tf.math.add_184/Add;model_5/tf.nn.convolution_134/convolution;Const_60) shape:[1, 22, 22, 48], type:INT8\n",
      "  T#295(model_5/tf.concat_626/concat) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#296(model_5/tf.compat.v1.pad_23/Pad) shape:[1, 24, 24, 96], type:INT8\n",
      "  T#297(model_5/tf.math.add_185/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_42/depthwise;Const_52) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#298(model_5/tf.nn.relu_75/Relu;model_5/tf.math.add_186/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_135/convolution;Const_58) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#299(model_5/tf.compat.v1.pad_24/Pad) shape:[1, 24, 24, 96], type:INT8\n",
      "  T#300(model_5/tf.math.add_188/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_43/depthwise;Const_53) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#301(model_5/tf.nn.relu_76/Relu;model_5/tf.math.add_187/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_136/convolution;Const_48) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#302(model_5/tf.nn.relu_77/Relu;model_5/tf.math.add_189/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_137/convolution;Const_49) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#303(model_5/tf.concat_627/concat) shape:[1, 11, 11, 192], type:INT8\n",
      "  T#304(model_5/tf.compat.v1.transpose_1282/transpose) shape:[1, 192, 11, 11], type:INT8\n",
      "  T#305(model_5/tf.reshape_51/Reshape) shape:[96, 2, 121], type:INT8\n",
      "  T#306(model_5/tf.compat.v1.transpose_1283/transpose) shape:[2, 96, 121], type:INT8\n",
      "  T#307(model_5/tf.reshape_52/Reshape) shape:[2, 1, 96, 11, 11], type:INT8\n",
      "  T#308(model_5/tf.compat.v1.gather_46/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:INT8\n",
      "  T#309(model_5/tf.compat.v1.transpose_1286/transpose) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#310(model_5/tf.compat.v1.gather_47/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:INT8\n",
      "  T#311(model_5/tf.compat.v1.transpose_1285/transpose) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#312(model_5/tf.nn.relu_78/Relu;model_5/tf.math.add_190/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_138/convolution;Const_46) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#313(model_5/tf.math.add_191/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_44/depthwise;Const_44) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#314(model_5/tf.nn.relu_79/Relu;model_5/tf.math.add_192/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_139/convolution;Const_42) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#315(model_5/tf.concat_628/concat) shape:[1, 11, 11, 192], type:INT8\n",
      "  T#316(model_5/tf.compat.v1.transpose_1287/transpose) shape:[1, 192, 11, 11], type:INT8\n",
      "  T#317(model_5/tf.reshape_53/Reshape) shape:[96, 2, 121], type:INT8\n",
      "  T#318(model_5/tf.compat.v1.transpose_1288/transpose) shape:[2, 96, 121], type:INT8\n",
      "  T#319(model_5/tf.reshape_54/Reshape) shape:[2, 1, 96, 11, 11], type:INT8\n",
      "  T#320(model_5/tf.compat.v1.gather_48/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:INT8\n",
      "  T#321(model_5/tf.compat.v1.transpose_1291/transpose) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#322(model_5/tf.compat.v1.gather_49/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:INT8\n",
      "  T#323(model_5/tf.compat.v1.transpose_1290/transpose) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#324(model_5/tf.nn.relu_80/Relu;model_5/tf.math.add_193/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_140/convolution;Const_40) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#325(model_5/tf.math.add_194/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_45/depthwise;Const_38) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#326(model_5/tf.nn.relu_81/Relu;model_5/tf.math.add_195/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_141/convolution;Const_36) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#327(model_5/tf.concat_629/concat) shape:[1, 11, 11, 192], type:INT8\n",
      "  T#328(model_5/tf.compat.v1.transpose_1292/transpose) shape:[1, 192, 11, 11], type:INT8\n",
      "  T#329(model_5/tf.reshape_55/Reshape) shape:[96, 2, 121], type:INT8\n",
      "  T#330(model_5/tf.compat.v1.transpose_1293/transpose) shape:[2, 96, 121], type:INT8\n",
      "  T#331(model_5/tf.reshape_56/Reshape) shape:[2, 1, 96, 11, 11], type:INT8\n",
      "  T#332(model_5/tf.compat.v1.gather_50/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:INT8\n",
      "  T#333(model_5/tf.compat.v1.transpose_1296/transpose) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#334(model_5/tf.compat.v1.gather_51/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:INT8\n",
      "  T#335(model_5/tf.compat.v1.transpose_1295/transpose) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#336(model_5/tf.nn.relu_82/Relu;model_5/tf.math.add_196/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_142/convolution;Const_34) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#337(model_5/tf.math.add_197/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_46/depthwise;Const_32) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#338(model_5/tf.nn.relu_83/Relu;model_5/tf.math.add_198/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_143/convolution;Const_30) shape:[1, 11, 11, 96], type:INT8\n",
      "  T#339(model_5/tf.concat_630/concat) shape:[1, 11, 11, 192], type:INT8\n",
      "  T#340(model_5/lambda_3/Resize_226) shape:[1, 22, 22, 192], type:INT8\n",
      "  T#341(model_5/tf.concat_631/concat) shape:[1, 22, 22, 336], type:INT8\n",
      "  T#342(model_5/tf.nn.relu_84/Relu;model_5/tf.math.add_199/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_144/convolution;Const_28) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#343(model_5/tf.nn.relu_85/Relu;model_5/tf.math.add_200/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_47/depthwise;Const_16) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#344(model_5/tf.nn.relu_86/Relu;model_5/tf.math.add_201/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_48/depthwise;Const_22) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#345(model_5/tf.nn.relu_88/Relu;model_5/tf.math.add_203/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_50/depthwise;Const_17) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#346(model_5/tf.nn.relu_87/Relu;model_5/tf.math.add_202/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_49/depthwise;Const_26) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#347(model_5/tf.nn.relu_89/Relu;model_5/tf.math.add_204/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_51/depthwise;Const_23) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#348(model_5/tf.nn.relu_90/Relu;model_5/tf.math.add_205/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_52/depthwise;Const_18) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#349(model_5/tf.concat_632/concat) shape:[1, 22, 22, 288], type:INT8\n",
      "  T#350(model_5/tf.math.add_206/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_145/convolution;Const_14) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#351(model_5/tf.nn.relu_91/Relu;model_5/tf.math.add_207/Add) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#352(model_5/tf.nn.relu_92/Relu;model_5/tf.math.add_208/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_146/convolution;Const_12) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#353(model_5/tf.nn.relu_93/Relu;model_5/tf.math.add_209/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_53/depthwise;Const_6) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#354(model_5/tf.nn.relu_94/Relu;model_5/tf.math.add_210/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_54/depthwise;Const_4) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#355(model_5/tf.nn.relu_95/Relu;model_5/tf.math.add_211/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;Const_10) shape:[1, 22, 22, 96], type:INT8\n",
      "  T#356(model_5/tf.math.add_212/Add;model_5/tf.nn.convolution_147/convolution;Const_1) shape:[1, 22, 22, 1], type:INT8\n",
      "  T#357(model_5/tf.math.sigmoid_59/Sigmoid) shape:[1, 22, 22, 1], type:INT8\n",
      "  T#358(model_5/tf.math.sigmoid_59/Sigmoid1) shape:[1, 22, 22, 1], type:INT8\n",
      "  T#359(model_5/tf.math.add_213/Add;model_5/tf.nn.convolution_148/convolution;Const) shape:[1, 22, 22, 4], type:INT8\n",
      "  T#360(model_5/tf.math.add_214/Add;model_5/tf.nn.convolution_149/convolution;Const_5) shape:[1, 22, 22, 80], type:INT8\n",
      "  T#361(model_5/tf.nn.softmax_2/Softmax_262) shape:[1, 22, 22, 80], type:INT8\n",
      "  T#362(model_5/tf.nn.softmax_2/Softmax_2621) shape:[1, 22, 22, 80], type:INT8\n",
      "  T#363(PartitionedCall:01) shape:[1, 22, 22, 85], type:INT8\n",
      "  T#364(PartitionedCall:0) shape:[1, 22, 22, 85], type:UINT8\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'input.1' : T#0\n",
      "- Outputs: \n",
      "    '758' : T#364\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:     421784 bytes\n",
      "    Non-data buffer size:     168624 bytes (39.98 %)\n",
      "  Total data buffer size:     253160 bytes (60.02 %)\n",
      "    (Zero value buffers):          4 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(fastest_det_quant_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /tmp/tmpqakc845g/FastestDet_dynamic_range_quant.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the PAD op takes\n",
      "tensor #0 and tensor #13 as input and produces tensor #154 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#360]\n",
      "  Op#0 PAD(T#0, T#13[0, 0, 1, 1, 1, ...]) -> [T#154]\n",
      "  Op#1 CONV_2D(T#154, T#99, T#29) -> [T#155]\n",
      "  Op#2 PAD(T#155, T#13[0, 0, 1, 1, 1, ...]) -> [T#156]\n",
      "  Op#3 MAX_POOL_2D(T#156) -> [T#157]\n",
      "  Op#4 PAD(T#157, T#13[0, 0, 1, 1, 1, ...]) -> [T#158]\n",
      "  Op#5 DEPTHWISE_CONV_2D(T#158, T#100, T#76) -> [T#159]\n",
      "  Op#6 CONV_2D(T#157, T#101, T#30) -> [T#160]\n",
      "  Op#7 PAD(T#160, T#13[0, 0, 1, 1, 1, ...]) -> [T#161]\n",
      "  Op#8 DEPTHWISE_CONV_2D(T#161, T#102, T#77) -> [T#162]\n",
      "  Op#9 CONV_2D(T#159, T#103, T#31) -> [T#163]\n",
      "  Op#10 CONV_2D(T#162, T#104, T#32) -> [T#164]\n",
      "  Op#11 CONCATENATION(T#163, T#164) -> [T#165]\n",
      "  Op#12 TRANSPOSE(T#165, T#9[0, 3, 1, 2]) -> [T#166]\n",
      "  Op#13 RESHAPE(T#166, T#6[24, 2, 1936]) -> [T#167]\n",
      "  Op#14 TRANSPOSE(T#167, T#8[1, 0, 2]) -> [T#168]\n",
      "  Op#15 RESHAPE(T#168, T#5[2, 1, 24, 44, 44]) -> [T#169]\n",
      "  Op#16 GATHER(T#169, T#11[0]) -> [T#170]\n",
      "  Op#17 TRANSPOSE(T#170, T#7[0, 2, 3, 1]) -> [T#171]\n",
      "  Op#18 GATHER(T#169, T#10[1]) -> [T#172]\n",
      "  Op#19 TRANSPOSE(T#172, T#7[0, 2, 3, 1]) -> [T#173]\n",
      "  Op#20 CONV_2D(T#173, T#105, T#33) -> [T#174]\n",
      "  Op#21 DEPTHWISE_CONV_2D(T#174, T#106, T#78) -> [T#175]\n",
      "  Op#22 CONV_2D(T#175, T#107, T#34) -> [T#176]\n",
      "  Op#23 CONCATENATION(T#171, T#176) -> [T#177]\n",
      "  Op#24 TRANSPOSE(T#177, T#9[0, 3, 1, 2]) -> [T#178]\n",
      "  Op#25 RESHAPE(T#178, T#6[24, 2, 1936]) -> [T#179]\n",
      "  Op#26 TRANSPOSE(T#179, T#8[1, 0, 2]) -> [T#180]\n",
      "  Op#27 RESHAPE(T#180, T#5[2, 1, 24, 44, 44]) -> [T#181]\n",
      "  Op#28 GATHER(T#181, T#11[0]) -> [T#182]\n",
      "  Op#29 TRANSPOSE(T#182, T#7[0, 2, 3, 1]) -> [T#183]\n",
      "  Op#30 GATHER(T#181, T#10[1]) -> [T#184]\n",
      "  Op#31 TRANSPOSE(T#184, T#7[0, 2, 3, 1]) -> [T#185]\n",
      "  Op#32 CONV_2D(T#185, T#108, T#35) -> [T#186]\n",
      "  Op#33 DEPTHWISE_CONV_2D(T#186, T#109, T#79) -> [T#187]\n",
      "  Op#34 CONV_2D(T#187, T#110, T#36) -> [T#188]\n",
      "  Op#35 CONCATENATION(T#183, T#188) -> [T#189]\n",
      "  Op#36 TRANSPOSE(T#189, T#9[0, 3, 1, 2]) -> [T#190]\n",
      "  Op#37 RESHAPE(T#190, T#6[24, 2, 1936]) -> [T#191]\n",
      "  Op#38 TRANSPOSE(T#191, T#8[1, 0, 2]) -> [T#192]\n",
      "  Op#39 RESHAPE(T#192, T#5[2, 1, 24, 44, 44]) -> [T#193]\n",
      "  Op#40 GATHER(T#193, T#11[0]) -> [T#194]\n",
      "  Op#41 TRANSPOSE(T#194, T#7[0, 2, 3, 1]) -> [T#195]\n",
      "  Op#42 GATHER(T#193, T#10[1]) -> [T#196]\n",
      "  Op#43 TRANSPOSE(T#196, T#7[0, 2, 3, 1]) -> [T#197]\n",
      "  Op#44 CONV_2D(T#197, T#111, T#37) -> [T#198]\n",
      "  Op#45 DEPTHWISE_CONV_2D(T#198, T#112, T#80) -> [T#199]\n",
      "  Op#46 CONV_2D(T#199, T#113, T#38) -> [T#200]\n",
      "  Op#47 CONCATENATION(T#195, T#200) -> [T#201]\n",
      "  Op#48 PAD(T#201, T#13[0, 0, 1, 1, 1, ...]) -> [T#202]\n",
      "  Op#49 DEPTHWISE_CONV_2D(T#202, T#114, T#81) -> [T#203]\n",
      "  Op#50 AVERAGE_POOL_2D(T#202) -> [T#204]\n",
      "  Op#51 CONV_2D(T#201, T#115, T#39) -> [T#205]\n",
      "  Op#52 PAD(T#205, T#13[0, 0, 1, 1, 1, ...]) -> [T#206]\n",
      "  Op#53 DEPTHWISE_CONV_2D(T#206, T#28, T#82) -> [T#207]\n",
      "  Op#54 CONV_2D(T#203, T#116, T#40) -> [T#208]\n",
      "  Op#55 CONV_2D(T#207, T#117, T#41) -> [T#209]\n",
      "  Op#56 CONCATENATION(T#208, T#209) -> [T#210]\n",
      "  Op#57 TRANSPOSE(T#210, T#9[0, 3, 1, 2]) -> [T#211]\n",
      "  Op#58 RESHAPE(T#211, T#4[48, 2, 484]) -> [T#212]\n",
      "  Op#59 TRANSPOSE(T#212, T#8[1, 0, 2]) -> [T#213]\n",
      "  Op#60 RESHAPE(T#213, T#3[2, 1, 48, 22, 22]) -> [T#214]\n",
      "  Op#61 GATHER(T#214, T#11[0]) -> [T#215]\n",
      "  Op#62 TRANSPOSE(T#215, T#7[0, 2, 3, 1]) -> [T#216]\n",
      "  Op#63 GATHER(T#214, T#10[1]) -> [T#217]\n",
      "  Op#64 TRANSPOSE(T#217, T#7[0, 2, 3, 1]) -> [T#218]\n",
      "  Op#65 CONV_2D(T#218, T#118, T#42) -> [T#219]\n",
      "  Op#66 DEPTHWISE_CONV_2D(T#219, T#27, T#83) -> [T#220]\n",
      "  Op#67 CONV_2D(T#220, T#119, T#43) -> [T#221]\n",
      "  Op#68 CONCATENATION(T#216, T#221) -> [T#222]\n",
      "  Op#69 TRANSPOSE(T#222, T#9[0, 3, 1, 2]) -> [T#223]\n",
      "  Op#70 RESHAPE(T#223, T#4[48, 2, 484]) -> [T#224]\n",
      "  Op#71 TRANSPOSE(T#224, T#8[1, 0, 2]) -> [T#225]\n",
      "  Op#72 RESHAPE(T#225, T#3[2, 1, 48, 22, 22]) -> [T#226]\n",
      "  Op#73 GATHER(T#226, T#11[0]) -> [T#227]\n",
      "  Op#74 TRANSPOSE(T#227, T#7[0, 2, 3, 1]) -> [T#228]\n",
      "  Op#75 GATHER(T#226, T#10[1]) -> [T#229]\n",
      "  Op#76 TRANSPOSE(T#229, T#7[0, 2, 3, 1]) -> [T#230]\n",
      "  Op#77 CONV_2D(T#230, T#120, T#44) -> [T#231]\n",
      "  Op#78 DEPTHWISE_CONV_2D(T#231, T#26, T#84) -> [T#232]\n",
      "  Op#79 CONV_2D(T#232, T#121, T#45) -> [T#233]\n",
      "  Op#80 CONCATENATION(T#228, T#233) -> [T#234]\n",
      "  Op#81 TRANSPOSE(T#234, T#9[0, 3, 1, 2]) -> [T#235]\n",
      "  Op#82 RESHAPE(T#235, T#4[48, 2, 484]) -> [T#236]\n",
      "  Op#83 TRANSPOSE(T#236, T#8[1, 0, 2]) -> [T#237]\n",
      "  Op#84 RESHAPE(T#237, T#3[2, 1, 48, 22, 22]) -> [T#238]\n",
      "  Op#85 GATHER(T#238, T#11[0]) -> [T#239]\n",
      "  Op#86 TRANSPOSE(T#239, T#7[0, 2, 3, 1]) -> [T#240]\n",
      "  Op#87 GATHER(T#238, T#10[1]) -> [T#241]\n",
      "  Op#88 TRANSPOSE(T#241, T#7[0, 2, 3, 1]) -> [T#242]\n",
      "  Op#89 CONV_2D(T#242, T#122, T#46) -> [T#243]\n",
      "  Op#90 DEPTHWISE_CONV_2D(T#243, T#25, T#85) -> [T#244]\n",
      "  Op#91 CONV_2D(T#244, T#123, T#47) -> [T#245]\n",
      "  Op#92 CONCATENATION(T#240, T#245) -> [T#246]\n",
      "  Op#93 TRANSPOSE(T#246, T#9[0, 3, 1, 2]) -> [T#247]\n",
      "  Op#94 RESHAPE(T#247, T#4[48, 2, 484]) -> [T#248]\n",
      "  Op#95 TRANSPOSE(T#248, T#8[1, 0, 2]) -> [T#249]\n",
      "  Op#96 RESHAPE(T#249, T#3[2, 1, 48, 22, 22]) -> [T#250]\n",
      "  Op#97 GATHER(T#250, T#11[0]) -> [T#251]\n",
      "  Op#98 TRANSPOSE(T#251, T#7[0, 2, 3, 1]) -> [T#252]\n",
      "  Op#99 GATHER(T#250, T#10[1]) -> [T#253]\n",
      "  Op#100 TRANSPOSE(T#253, T#7[0, 2, 3, 1]) -> [T#254]\n",
      "  Op#101 CONV_2D(T#254, T#124, T#48) -> [T#255]\n",
      "  Op#102 DEPTHWISE_CONV_2D(T#255, T#24, T#86) -> [T#256]\n",
      "  Op#103 CONV_2D(T#256, T#125, T#49) -> [T#257]\n",
      "  Op#104 CONCATENATION(T#252, T#257) -> [T#258]\n",
      "  Op#105 TRANSPOSE(T#258, T#9[0, 3, 1, 2]) -> [T#259]\n",
      "  Op#106 RESHAPE(T#259, T#4[48, 2, 484]) -> [T#260]\n",
      "  Op#107 TRANSPOSE(T#260, T#8[1, 0, 2]) -> [T#261]\n",
      "  Op#108 RESHAPE(T#261, T#3[2, 1, 48, 22, 22]) -> [T#262]\n",
      "  Op#109 GATHER(T#262, T#11[0]) -> [T#263]\n",
      "  Op#110 TRANSPOSE(T#263, T#7[0, 2, 3, 1]) -> [T#264]\n",
      "  Op#111 GATHER(T#262, T#10[1]) -> [T#265]\n",
      "  Op#112 TRANSPOSE(T#265, T#7[0, 2, 3, 1]) -> [T#266]\n",
      "  Op#113 CONV_2D(T#266, T#126, T#50) -> [T#267]\n",
      "  Op#114 DEPTHWISE_CONV_2D(T#267, T#23, T#87) -> [T#268]\n",
      "  Op#115 CONV_2D(T#268, T#127, T#51) -> [T#269]\n",
      "  Op#116 CONCATENATION(T#264, T#269) -> [T#270]\n",
      "  Op#117 TRANSPOSE(T#270, T#9[0, 3, 1, 2]) -> [T#271]\n",
      "  Op#118 RESHAPE(T#271, T#4[48, 2, 484]) -> [T#272]\n",
      "  Op#119 TRANSPOSE(T#272, T#8[1, 0, 2]) -> [T#273]\n",
      "  Op#120 RESHAPE(T#273, T#3[2, 1, 48, 22, 22]) -> [T#274]\n",
      "  Op#121 GATHER(T#274, T#11[0]) -> [T#275]\n",
      "  Op#122 TRANSPOSE(T#275, T#7[0, 2, 3, 1]) -> [T#276]\n",
      "  Op#123 GATHER(T#274, T#10[1]) -> [T#277]\n",
      "  Op#124 TRANSPOSE(T#277, T#7[0, 2, 3, 1]) -> [T#278]\n",
      "  Op#125 CONV_2D(T#278, T#128, T#52) -> [T#279]\n",
      "  Op#126 DEPTHWISE_CONV_2D(T#279, T#22, T#88) -> [T#280]\n",
      "  Op#127 CONV_2D(T#280, T#129, T#53) -> [T#281]\n",
      "  Op#128 CONCATENATION(T#276, T#281) -> [T#282]\n",
      "  Op#129 TRANSPOSE(T#282, T#9[0, 3, 1, 2]) -> [T#283]\n",
      "  Op#130 RESHAPE(T#283, T#4[48, 2, 484]) -> [T#284]\n",
      "  Op#131 TRANSPOSE(T#284, T#8[1, 0, 2]) -> [T#285]\n",
      "  Op#132 RESHAPE(T#285, T#3[2, 1, 48, 22, 22]) -> [T#286]\n",
      "  Op#133 GATHER(T#286, T#11[0]) -> [T#287]\n",
      "  Op#134 TRANSPOSE(T#287, T#7[0, 2, 3, 1]) -> [T#288]\n",
      "  Op#135 GATHER(T#286, T#10[1]) -> [T#289]\n",
      "  Op#136 TRANSPOSE(T#289, T#7[0, 2, 3, 1]) -> [T#290]\n",
      "  Op#137 CONV_2D(T#290, T#130, T#54) -> [T#291]\n",
      "  Op#138 DEPTHWISE_CONV_2D(T#291, T#21, T#89) -> [T#292]\n",
      "  Op#139 CONV_2D(T#292, T#131, T#55) -> [T#293]\n",
      "  Op#140 CONCATENATION(T#288, T#293) -> [T#294]\n",
      "  Op#141 PAD(T#294, T#13[0, 0, 1, 1, 1, ...]) -> [T#295]\n",
      "  Op#142 DEPTHWISE_CONV_2D(T#295, T#20, T#90) -> [T#296]\n",
      "  Op#143 CONV_2D(T#294, T#132, T#56) -> [T#297]\n",
      "  Op#144 PAD(T#297, T#13[0, 0, 1, 1, 1, ...]) -> [T#298]\n",
      "  Op#145 DEPTHWISE_CONV_2D(T#298, T#19, T#91) -> [T#299]\n",
      "  Op#146 CONV_2D(T#296, T#133, T#57) -> [T#300]\n",
      "  Op#147 CONV_2D(T#299, T#134, T#58) -> [T#301]\n",
      "  Op#148 CONCATENATION(T#300, T#301) -> [T#302]\n",
      "  Op#149 TRANSPOSE(T#302, T#9[0, 3, 1, 2]) -> [T#303]\n",
      "  Op#150 RESHAPE(T#303, T#2[96, 2, 121]) -> [T#304]\n",
      "  Op#151 TRANSPOSE(T#304, T#8[1, 0, 2]) -> [T#305]\n",
      "  Op#152 RESHAPE(T#305, T#1[2, 1, 96, 11, 11]) -> [T#306]\n",
      "  Op#153 GATHER(T#306, T#11[0]) -> [T#307]\n",
      "  Op#154 TRANSPOSE(T#307, T#7[0, 2, 3, 1]) -> [T#308]\n",
      "  Op#155 GATHER(T#306, T#10[1]) -> [T#309]\n",
      "  Op#156 TRANSPOSE(T#309, T#7[0, 2, 3, 1]) -> [T#310]\n",
      "  Op#157 CONV_2D(T#310, T#135, T#59) -> [T#311]\n",
      "  Op#158 DEPTHWISE_CONV_2D(T#311, T#18, T#92) -> [T#312]\n",
      "  Op#159 CONV_2D(T#312, T#136, T#60) -> [T#313]\n",
      "  Op#160 CONCATENATION(T#308, T#313) -> [T#314]\n",
      "  Op#161 TRANSPOSE(T#314, T#9[0, 3, 1, 2]) -> [T#315]\n",
      "  Op#162 RESHAPE(T#315, T#2[96, 2, 121]) -> [T#316]\n",
      "  Op#163 TRANSPOSE(T#316, T#8[1, 0, 2]) -> [T#317]\n",
      "  Op#164 RESHAPE(T#317, T#1[2, 1, 96, 11, 11]) -> [T#318]\n",
      "  Op#165 GATHER(T#318, T#11[0]) -> [T#319]\n",
      "  Op#166 TRANSPOSE(T#319, T#7[0, 2, 3, 1]) -> [T#320]\n",
      "  Op#167 GATHER(T#318, T#10[1]) -> [T#321]\n",
      "  Op#168 TRANSPOSE(T#321, T#7[0, 2, 3, 1]) -> [T#322]\n",
      "  Op#169 CONV_2D(T#322, T#137, T#61) -> [T#323]\n",
      "  Op#170 DEPTHWISE_CONV_2D(T#323, T#17, T#93) -> [T#324]\n",
      "  Op#171 CONV_2D(T#324, T#138, T#62) -> [T#325]\n",
      "  Op#172 CONCATENATION(T#320, T#325) -> [T#326]\n",
      "  Op#173 TRANSPOSE(T#326, T#9[0, 3, 1, 2]) -> [T#327]\n",
      "  Op#174 RESHAPE(T#327, T#2[96, 2, 121]) -> [T#328]\n",
      "  Op#175 TRANSPOSE(T#328, T#8[1, 0, 2]) -> [T#329]\n",
      "  Op#176 RESHAPE(T#329, T#1[2, 1, 96, 11, 11]) -> [T#330]\n",
      "  Op#177 GATHER(T#330, T#11[0]) -> [T#331]\n",
      "  Op#178 TRANSPOSE(T#331, T#7[0, 2, 3, 1]) -> [T#332]\n",
      "  Op#179 GATHER(T#330, T#10[1]) -> [T#333]\n",
      "  Op#180 TRANSPOSE(T#333, T#7[0, 2, 3, 1]) -> [T#334]\n",
      "  Op#181 CONV_2D(T#334, T#139, T#63) -> [T#335]\n",
      "  Op#182 DEPTHWISE_CONV_2D(T#335, T#16, T#94) -> [T#336]\n",
      "  Op#183 CONV_2D(T#336, T#140, T#64) -> [T#337]\n",
      "  Op#184 CONCATENATION(T#332, T#337) -> [T#338]\n",
      "  Op#185 RESIZE_NEAREST_NEIGHBOR(T#338, T#12[22, 22]) -> [T#339]\n",
      "  Op#186 CONCATENATION(T#204, T#294, T#339) -> [T#340]\n",
      "  Op#187 CONV_2D(T#340, T#141, T#65) -> [T#341]\n",
      "  Op#188 DEPTHWISE_CONV_2D(T#341, T#142, T#66) -> [T#342]\n",
      "  Op#189 DEPTHWISE_CONV_2D(T#341, T#143, T#67) -> [T#343]\n",
      "  Op#190 DEPTHWISE_CONV_2D(T#343, T#144, T#68) -> [T#344]\n",
      "  Op#191 DEPTHWISE_CONV_2D(T#341, T#145, T#69) -> [T#345]\n",
      "  Op#192 DEPTHWISE_CONV_2D(T#345, T#146, T#70) -> [T#346]\n",
      "  Op#193 DEPTHWISE_CONV_2D(T#346, T#147, T#71) -> [T#347]\n",
      "  Op#194 CONCATENATION(T#342, T#344, T#347) -> [T#348]\n",
      "  Op#195 CONV_2D(T#348, T#148, T#95) -> [T#349]\n",
      "  Op#196 ADD(T#341, T#349) -> [T#350]\n",
      "  Op#197 CONV_2D(T#350, T#149, T#72) -> [T#351]\n",
      "  Op#198 DEPTHWISE_CONV_2D(T#351, T#150, T#73) -> [T#352]\n",
      "  Op#199 DEPTHWISE_CONV_2D(T#351, T#151, T#74) -> [T#353]\n",
      "  Op#200 DEPTHWISE_CONV_2D(T#351, T#152, T#75) -> [T#354]\n",
      "  Op#201 CONV_2D(T#352, T#15, T#96) -> [T#355]\n",
      "  Op#202 LOGISTIC(T#355) -> [T#356]\n",
      "  Op#203 CONV_2D(T#353, T#14, T#97) -> [T#357]\n",
      "  Op#204 CONV_2D(T#354, T#153, T#98) -> [T#358]\n",
      "  Op#205 SOFTMAX(T#358) -> [T#359]\n",
      "  Op#206 CONCATENATION(T#356, T#357, T#359) -> [T#360]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_input.1:0) shape:[1, 352, 352, 3], type:FLOAT32\n",
      "  T#1(model_5/tf.reshape_52/Reshape/shape) shape:[5], type:INT32 RO 20 bytes, buffer: 2, data:[2, 1, 96, 11, 11]\n",
      "  T#2(model_5/tf.reshape_51/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 3, data:[96, 2, 121]\n",
      "  T#3(model_5/tf.reshape_38/Reshape/shape) shape:[5], type:INT32 RO 20 bytes, buffer: 4, data:[2, 1, 48, 22, 22]\n",
      "  T#4(model_5/tf.reshape_37/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 5, data:[48, 2, 484]\n",
      "  T#5(model_5/tf.reshape_32/Reshape/shape) shape:[5], type:INT32 RO 20 bytes, buffer: 6, data:[2, 1, 24, 44, 44]\n",
      "  T#6(model_5/tf.reshape_31/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 7, data:[24, 2, 1936]\n",
      "  T#7(model_5/tf.compat.v1.transpose_1235/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 8, data:[0, 2, 3, 1]\n",
      "  T#8(model_5/tf.compat.v1.transpose_1233/transpose/perm) shape:[3], type:INT32 RO 12 bytes, buffer: 9, data:[1, 0, 2]\n",
      "  T#9(model_5/tf.compat.v1.transpose_1232/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 10, data:[0, 3, 1, 2]\n",
      "  T#10(model_5/tf.compat.v1.gather_27/GatherV2/indices) shape:[], type:INT32 RO 4 bytes, buffer: 11, data:[1]\n",
      "  T#11(model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[], type:INT32 RO 4 bytes, buffer: 12, data:[0]\n",
      "  T#12(model_5/lambda_3/Resize_226/size) shape:[2], type:INT32 RO 8 bytes, buffer: 13, data:[22, 22]\n",
      "  T#13(Const_110) shape:[4, 2], type:INT32 RO 32 bytes, buffer: 14, data:[0, 0, 1, 1, 1, ...]\n",
      "  T#14(model_5/tf.nn.convolution_148/convolution) shape:[4, 1, 1, 96], type:FLOAT32 RO 1536 bytes, buffer: 15, data:[-0.346114, -0.0508209, 0.00167752, 0.0182714, -0.00903768, ...]\n",
      "  T#15(model_5/tf.nn.convolution_147/convolution) shape:[1, 1, 1, 96], type:FLOAT32 RO 384 bytes, buffer: 16, data:[-0.180282, 0.972872, 0.167803, -0.0412234, 0.138323, ...]\n",
      "  T#16(model_5/tf.compat.v1.nn.depthwise_conv2d_46/depthwise) shape:[1, 3, 3, 96], type:FLOAT32 RO 3456 bytes, buffer: 17, data:[0.00571084, -0.218398, 0.48948, -0.347104, -0.154934, ...]\n",
      "  T#17(model_5/tf.compat.v1.nn.depthwise_conv2d_45/depthwise) shape:[1, 3, 3, 96], type:FLOAT32 RO 3456 bytes, buffer: 18, data:[0.5677, -0.290866, 0.08106, 0.88798, 0.0295109, ...]\n",
      "  T#18(model_5/tf.compat.v1.nn.depthwise_conv2d_44/depthwise) shape:[1, 3, 3, 96], type:FLOAT32 RO 3456 bytes, buffer: 19, data:[0.840123, -0.757271, 0.437505, 0.498578, -0.41801, ...]\n",
      "  T#19(model_5/tf.compat.v1.nn.depthwise_conv2d_43/depthwise) shape:[1, 3, 3, 96], type:FLOAT32 RO 3456 bytes, buffer: 20, data:[-0.292337, -0.392259, 0.222919, -0.00044729, 0.384999, ...]\n",
      "  T#20(model_5/tf.compat.v1.nn.depthwise_conv2d_42/depthwise) shape:[1, 3, 3, 96], type:FLOAT32 RO 3456 bytes, buffer: 21, data:[0.213405, -0.12035, 0.043701, -0.044041, 0.173583, ...]\n",
      "  T#21(model_5/tf.compat.v1.nn.depthwise_conv2d_41/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 22, data:[-0.268697, -0.227478, -0.0534203, -0.12834, 0.376552, ...]\n",
      "  T#22(model_5/tf.compat.v1.nn.depthwise_conv2d_40/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 23, data:[0.545747, -0.0250537, 0.133094, 0.24043, -0.328595, ...]\n",
      "  T#23(model_5/tf.compat.v1.nn.depthwise_conv2d_39/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 24, data:[-0.263926, 0.225905, -1.36525, 0.192032, -0.190324, ...]\n",
      "  T#24(model_5/tf.compat.v1.nn.depthwise_conv2d_38/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 25, data:[-0.156812, -0.0483424, 0.25824, -0.53386, 0.0763341, ...]\n",
      "  T#25(model_5/tf.compat.v1.nn.depthwise_conv2d_37/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 26, data:[0.0664142, 0.0991065, -0.280962, -0.0196764, 0.000947048, ...]\n",
      "  T#26(model_5/tf.compat.v1.nn.depthwise_conv2d_36/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 27, data:[0.187133, 0.396188, -0.0224791, -0.121472, 0.363849, ...]\n",
      "  T#27(model_5/tf.compat.v1.nn.depthwise_conv2d_35/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 28, data:[-0.12716, 0.166943, -0.286503, -0.255908, -0.116604, ...]\n",
      "  T#28(model_5/tf.compat.v1.nn.depthwise_conv2d_34/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 29, data:[-0.437187, -0.17704, 0.288041, -0.326961, -0.272111, ...]\n",
      "  T#29(Const_144) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 30, data:[0.498611, 0.845525, 0.502995, 0.433243, 0.101576, ...]\n",
      "  T#30(Const_142) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 31, data:[-0.632407, -0.487176, 0.46909, -0.228312, 0.638565, ...]\n",
      "  T#31(Const_132) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 32, data:[0.138603, -0.103277, 0.152941, 0.394928, 0.123483, ...]\n",
      "  T#32(Const_133) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 33, data:[0.377911, 0.152157, 0.157201, -0.0978154, 0.531901, ...]\n",
      "  T#33(Const_130) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 34, data:[0.215222, 0.220831, 0.121159, 0.454536, 0.372335, ...]\n",
      "  T#34(Const_126) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 35, data:[0.0505838, 0.00967599, 0.190925, 0.0372933, 0.0248475, ...]\n",
      "  T#35(Const_124) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 36, data:[-0.137458, 0.308647, 0.150913, 0.370189, 0.224251, ...]\n",
      "  T#36(Const_120) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 37, data:[0.00633464, -0.0070531, 0.00621177, -0.0437164, 0.199047, ...]\n",
      "  T#37(Const_118) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 38, data:[0.371989, 0.269805, -0.0162116, 0.318339, -0.0463198, ...]\n",
      "  T#38(Const_114) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 39, data:[0.0121252, 0.00396547, 0.0446552, -0.0418448, 0.105915, ...]\n",
      "  T#39(Const_112) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 40, data:[-0.15927, 0.300288, 0.0118578, -0.123995, 0.310493, ...]\n",
      "  T#40(Const_102) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 41, data:[0.172879, -0.00399643, 0.0738369, 0.286183, 0.177352, ...]\n",
      "  T#41(Const_103) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 42, data:[0.215546, 0.00178619, 0.172907, 0.102654, 0.311038, ...]\n",
      "  T#42(Const_100) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 43, data:[0.0532654, 0.221701, 0.075001, -0.0612377, -0.094346, ...]\n",
      "  T#43(Const_96) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 44, data:[0.014894, -0.0225773, -0.0476035, -0.100795, 0.399442, ...]\n",
      "  T#44(Const_94) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 45, data:[0.0899949, 0.474271, -0.0791734, 0.091824, 0.087106, ...]\n",
      "  T#45(Const_90) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 46, data:[0.196463, 0.00843109, 0.132468, 0.00824066, 0.315954, ...]\n",
      "  T#46(Const_88) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 47, data:[0.12616, 0.151115, 0.245455, 0.000636682, -0.161543, ...]\n",
      "  T#47(Const_84) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 48, data:[0.255438, -0.0380368, 0.00581789, 0.314307, 0.282857, ...]\n",
      "  T#48(Const_82) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 49, data:[0.13153, -0.188157, 0.0888412, 0.145786, 0.246961, ...]\n",
      "  T#49(Const_78) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 50, data:[0.163319, -0.00714507, -0.157776, -0.067516, 0.14235, ...]\n",
      "  T#50(Const_76) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 51, data:[-0.357787, -0.214791, -0.16456, 0.348864, 0.0311218, ...]\n",
      "  T#51(Const_72) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 52, data:[0.194805, -0.0528647, 0.229031, -0.06689, 0.109894, ...]\n",
      "  T#52(Const_70) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 53, data:[0.24767, 0.193656, -0.00389619, -0.852597, -0.173606, ...]\n",
      "  T#53(Const_66) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 54, data:[0.21506, 0.220429, 0.148286, 0.0858684, 0.128245, ...]\n",
      "  T#54(Const_64) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 55, data:[0.1793, 0.533423, 0.111893, 0.156157, -0.175672, ...]\n",
      "  T#55(Const_60) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 56, data:[0.161383, -0.0643721, 0.116361, -0.0610915, 0.142982, ...]\n",
      "  T#56(Const_58) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 57, data:[0.268613, -0.0174522, 0.0415377, -0.00573172, -0.19669, ...]\n",
      "  T#57(Const_48) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 58, data:[0.106654, 0.164055, 0.185353, 0.208287, 0.0988114, ...]\n",
      "  T#58(Const_49) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 59, data:[0.0385486, -0.204464, -0.0361829, -0.0705515, 0.103522, ...]\n",
      "  T#59(Const_46) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 60, data:[0.165112, 0.0933195, 0.0384082, 0.0375655, 0.0500062, ...]\n",
      "  T#60(Const_42) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 61, data:[0.165663, 0.210069, -0.0573217, 0.208217, 0.0749661, ...]\n",
      "  T#61(Const_40) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 62, data:[-0.0609146, -0.139226, -0.0611582, 0.101616, 0.101354, ...]\n",
      "  T#62(Const_36) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 63, data:[0.0709577, -0.0657082, 0.0298865, 0.0632168, -0.29577, ...]\n",
      "  T#63(Const_34) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 64, data:[0.118627, 0.0380382, -0.0380735, 0.219475, -0.00767442, ...]\n",
      "  T#64(Const_30) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 65, data:[-0.0588356, 0.0044786, -0.0753183, -0.078428, -0.230815, ...]\n",
      "  T#65(Const_28) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 66, data:[0.246175, 0.0938794, -0.00494611, 0.067041, 0.132582, ...]\n",
      "  T#66(Const_16) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 67, data:[0.434184, 0.520512, -0.0423738, 0.794742, -0.406906, ...]\n",
      "  T#67(Const_22) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 68, data:[-0.249424, 0.445683, -0.0569355, -0.422226, 0.408646, ...]\n",
      "  T#68(Const_17) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 69, data:[-0.142437, -0.14331, -0.136561, -0.112118, -0.231939, ...]\n",
      "  T#69(Const_26) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 70, data:[-0.209787, -0.0783659, 0.0677139, -0.567379, 0.148837, ...]\n",
      "  T#70(Const_23) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 71, data:[-0.0633145, 0.248543, -0.0602396, -0.312988, -0.532315, ...]\n",
      "  T#71(Const_18) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 72, data:[-0.051946, -0.263165, -0.106424, 0.332849, -0.307167, ...]\n",
      "  T#72(Const_12) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 73, data:[0.193286, -0.0829772, -0.0689669, 0.00997497, -0.0833954, ...]\n",
      "  T#73(Const_6) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 74, data:[0.333647, 0.0100402, 0.207228, -0.00689665, -0.223818, ...]\n",
      "  T#74(Const_4) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 75, data:[0.322213, 0.153202, -0.00204362, 0.0031206, -0.00393793, ...]\n",
      "  T#75(Const_10) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 76, data:[0.460612, 0.361813, -0.0176406, -0.222525, -0.08205, ...]\n",
      "  T#76(Const_136) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 77, data:[0.489517, -0.287922, -0.747633, -0.755282, 0.0800997, ...]\n",
      "  T#77(Const_137) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 78, data:[0.046125, 0.360031, -0.218027, -0.221628, 0.0345793, ...]\n",
      "  T#78(Const_128) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 79, data:[0.63915, 0.0738122, -0.156009, 0.339055, 0.0721612, ...]\n",
      "  T#79(Const_122) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 80, data:[0.136486, 0.15227, -0.124072, -0.0255859, 0.0589108, ...]\n",
      "  T#80(Const_116) shape:[24], type:FLOAT32 RO 96 bytes, buffer: 81, data:[-0.319037, -0.092263, 0.0047944, -0.19052, -0.140935, ...]\n",
      "  T#81(Const_106) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 82, data:[0.549079, -0.197432, -1.51725, 0.995418, 0.159353, ...]\n",
      "  T#82(Const_107) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 83, data:[0.128451, 0.191962, -0.227711, 0.0690462, 0.26062, ...]\n",
      "  T#83(Const_98) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 84, data:[-0.0476997, 0.237215, -0.0132098, -0.228109, 0.000417363, ...]\n",
      "  T#84(Const_92) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 85, data:[0.491376, -0.067863, -0.13707, -0.00596786, 0.0142712, ...]\n",
      "  T#85(Const_86) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 86, data:[0.799214, -0.225137, 0.481207, 0.224963, 0.187367, ...]\n",
      "  T#86(Const_80) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 87, data:[-0.0674353, -0.210636, -0.294883, -0.16967, 0.129071, ...]\n",
      "  T#87(Const_74) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 88, data:[0.0421936, -0.0803013, 0.0394598, -0.284599, 0.311718, ...]\n",
      "  T#88(Const_68) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 89, data:[-0.290889, -0.149428, 0.328639, -0.147306, -0.0321897, ...]\n",
      "  T#89(Const_62) shape:[48], type:FLOAT32 RO 192 bytes, buffer: 90, data:[0.18442, 0.152673, 0.0118357, -0.112352, -0.212287, ...]\n",
      "  T#90(Const_52) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 91, data:[-0.292169, 0.607414, -0.207807, 0.492426, -0.778895, ...]\n",
      "  T#91(Const_53) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 92, data:[0.0805205, 0.0603086, -0.0876114, 2.6508e-08, -0.0686945, ...]\n",
      "  T#92(Const_44) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 93, data:[-0.153678, 0.108896, 0.0195819, -0.161156, 0.117481, ...]\n",
      "  T#93(Const_38) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 94, data:[-0.168105, -0.0994695, 0.0793947, -0.0154221, 0.144037, ...]\n",
      "  T#94(Const_32) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 95, data:[-0.0789523, 0.105219, -0.110292, 0.166113, 0.0396418, ...]\n",
      "  T#95(Const_14) shape:[96], type:FLOAT32 RO 384 bytes, buffer: 96, data:[0.147753, 0.2274, -0.022568, 0.033922, 0.261925, ...]\n",
      "  T#96(Const_1) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 97, data:[-2.55305]\n",
      "  T#97(Const) shape:[4], type:FLOAT32 RO 16 bytes, buffer: 98, data:[-0.188451, 0.336688, -0.739344, -0.644056]\n",
      "  T#98(Const_5) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 99, data:[-0.0586424, 0.377015, 0.688382, -0.780678, -2.66996, ...]\n",
      "  T#99(model_5/tf.nn.convolution_108/convolution) shape:[24, 3, 3, 3], type:FLOAT32 RO 2592 bytes, buffer: 100, data:[-0.0785462, -0.0836159, 0.156784, -0.0371055, -0.0663759, ...]\n",
      "  T#100(model_5/tf.compat.v1.nn.depthwise_conv2d_28/depthwise) shape:[1, 3, 3, 24], type:FLOAT32 RO 864 bytes, buffer: 101, data:[-0.0441813, 0.0723284, -0.00117313, 0.0652366, -0.0069578, ...]\n",
      "  T#101(model_5/tf.nn.convolution_109/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 102, data:[0.205052, 0.0200755, 0.222382, 0.229858, 0.0178085, ...]\n",
      "  T#102(model_5/tf.compat.v1.nn.depthwise_conv2d_29/depthwise) shape:[1, 3, 3, 24], type:FLOAT32 RO 864 bytes, buffer: 103, data:[-0.276918, -0.105227, 0.149807, 0.185461, -0.365254, ...]\n",
      "  T#103(model_5/tf.nn.convolution_110/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 104, data:[-0.0132025, 0.0679601, 0.0098892, 0.0146717, -0.0186309, ...]\n",
      "  T#104(model_5/tf.nn.convolution_111/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 105, data:[0.0224428, -0.0314921, -0.0052681, 0.0264061, -0.00204638, ...]\n",
      "  T#105(model_5/tf.nn.convolution_112/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 106, data:[0.0333502, 0.131226, 0.0518315, -0.0135208, -0.000694296, ...]\n",
      "  T#106(model_5/tf.compat.v1.nn.depthwise_conv2d_30/depthwise) shape:[1, 3, 3, 24], type:FLOAT32 RO 864 bytes, buffer: 107, data:[0.22256, 0.103769, -0.506495, 0.227005, 0.139669, ...]\n",
      "  T#107(model_5/tf.nn.convolution_113/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 108, data:[0.1447, 0.00483888, -0.299804, -0.0424973, 0.1055, ...]\n",
      "  T#108(model_5/tf.nn.convolution_114/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 109, data:[-0.038292, 0.253558, 0.467319, 0.286187, 0.0864674, ...]\n",
      "  T#109(model_5/tf.compat.v1.nn.depthwise_conv2d_31/depthwise) shape:[1, 3, 3, 24], type:FLOAT32 RO 864 bytes, buffer: 110, data:[0.024435, 0.078204, 0.00965505, -0.271704, -0.116009, ...]\n",
      "  T#110(model_5/tf.nn.convolution_115/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 111, data:[0.0441117, 0.0223686, 0.0143607, -0.0247123, -0.0724177, ...]\n",
      "  T#111(model_5/tf.nn.convolution_116/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 112, data:[0.0401845, -0.198869, 0.0331627, -0.128183, -0.0840933, ...]\n",
      "  T#112(model_5/tf.compat.v1.nn.depthwise_conv2d_32/depthwise) shape:[1, 3, 3, 24], type:FLOAT32 RO 864 bytes, buffer: 113, data:[0.547896, -0.21248, 0.0872807, -0.220631, -0.228929, ...]\n",
      "  T#113(model_5/tf.nn.convolution_117/convolution) shape:[24, 1, 1, 24], type:FLOAT32 RO 2304 bytes, buffer: 114, data:[0.0421335, -0.0714794, -0.00618478, -0.132509, -0.0797097, ...]\n",
      "  T#114(model_5/tf.compat.v1.nn.depthwise_conv2d_33/depthwise) shape:[1, 3, 3, 48], type:FLOAT32 RO 1728 bytes, buffer: 115, data:[-0.0888624, 0.108787, 0.0468929, -0.0121568, 0.0101385, ...]\n",
      "  T#115(model_5/tf.nn.convolution_118/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 116, data:[., ., ., ., ., ...]\n",
      "  T#116(model_5/tf.nn.convolution_119/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 117, data:[., ., ., T, $, ...]\n",
      "  T#117(model_5/tf.nn.convolution_120/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 118, data:[.,  , ., ., ., ...]\n",
      "  T#118(model_5/tf.nn.convolution_121/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 119, data:[., ., +, *, I, ...]\n",
      "  T#119(model_5/tf.nn.convolution_122/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 120, data:[., ., ., $, ., ...]\n",
      "  T#120(model_5/tf.nn.convolution_123/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 121, data:[2, 7, ., ., ., ...]\n",
      "  T#121(model_5/tf.nn.convolution_124/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 122, data:[., ., ., ., ., ...]\n",
      "  T#122(model_5/tf.nn.convolution_125/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 123, data:[., ., ., ., ., ...]\n",
      "  T#123(model_5/tf.nn.convolution_126/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 124, data:[&, ., .,  , ., ...]\n",
      "  T#124(model_5/tf.nn.convolution_127/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 125, data:[., >, ., ., ., ...]\n",
      "  T#125(model_5/tf.nn.convolution_128/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 126, data:[., ., ., ., ., ...]\n",
      "  T#126(model_5/tf.nn.convolution_129/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 127, data:[., M, ., ., ., ...]\n",
      "  T#127(model_5/tf.nn.convolution_130/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 128, data:[., ., ., ., !, ...]\n",
      "  T#128(model_5/tf.nn.convolution_131/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 129, data:[., ., ., ., ., ...]\n",
      "  T#129(model_5/tf.nn.convolution_132/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 130, data:[!, ., ,, ., ., ...]\n",
      "  T#130(model_5/tf.nn.convolution_133/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 131, data:[., ., ., ., ., ...]\n",
      "  T#131(model_5/tf.nn.convolution_134/convolution) shape:[48, 1, 1, 48], type:INT8 RO 2304 bytes, buffer: 132, data:[., ., U, ., ., ...]\n",
      "  T#132(model_5/tf.nn.convolution_135/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 133, data:[., ., ., ., ., ...]\n",
      "  T#133(model_5/tf.nn.convolution_136/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 134, data:[., E, ., ., ., ...]\n",
      "  T#134(model_5/tf.nn.convolution_137/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 135, data:[., ., ,, ., ., ...]\n",
      "  T#135(model_5/tf.nn.convolution_138/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 136, data:[,, ., ., ., ., ...]\n",
      "  T#136(model_5/tf.nn.convolution_139/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 137, data:[., ., ., ., ., ...]\n",
      "  T#137(model_5/tf.nn.convolution_140/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 138, data:[., >, i, ., ., ...]\n",
      "  T#138(model_5/tf.nn.convolution_141/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 139, data:[4, ., ., ., ., ...]\n",
      "  T#139(model_5/tf.nn.convolution_142/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 140, data:[., ., ., ., ., ...]\n",
      "  T#140(model_5/tf.nn.convolution_143/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 141, data:[., v, ., ., !, ...]\n",
      "  T#141(model_5/tf.nn.convolution_144/convolution) shape:[96, 1, 1, 336], type:INT8 RO 32256 bytes, buffer: 142, data:[., ., ., ., ., ...]\n",
      "  T#142(model_5/tf.compat.v1.nn.depthwise_conv2d_47/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 143, data:[., ., 3, ., >, ...]\n",
      "  T#143(model_5/tf.compat.v1.nn.depthwise_conv2d_48/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 144, data:[., ., ., ., ., ...]\n",
      "  T#144(model_5/tf.compat.v1.nn.depthwise_conv2d_50/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 145, data:[., ., ., ., O, ...]\n",
      "  T#145(model_5/tf.compat.v1.nn.depthwise_conv2d_49/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 146, data:[., w, ., b, ., ...]\n",
      "  T#146(model_5/tf.compat.v1.nn.depthwise_conv2d_51/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 147, data:[-, ., ., ., a, ...]\n",
      "  T#147(model_5/tf.compat.v1.nn.depthwise_conv2d_52/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 148, data:[., ., H, ., :, ...]\n",
      "  T#148(model_5/tf.nn.convolution_145/convolution) shape:[96, 1, 1, 288], type:INT8 RO 27648 bytes, buffer: 149, data:[., ., ., ., ., ...]\n",
      "  T#149(model_5/tf.nn.convolution_146/convolution) shape:[96, 1, 1, 96], type:INT8 RO 9216 bytes, buffer: 150, data:[., ., ., ., ., ...]\n",
      "  T#150(model_5/tf.compat.v1.nn.depthwise_conv2d_53/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 151, data:[., ., ., ., I, ...]\n",
      "  T#151(model_5/tf.compat.v1.nn.depthwise_conv2d_54/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 152, data:[., ., .,  , ., ...]\n",
      "  T#152(model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise) shape:[1, 5, 5, 96], type:INT8 RO 2400 bytes, buffer: 153, data:[., ., ., ., ., ...]\n",
      "  T#153(model_5/tf.nn.convolution_149/convolution) shape:[80, 1, 1, 96], type:INT8 RO 7680 bytes, buffer: 154, data:[., ., ., ., ., ...]\n",
      "  T#154(model_5/tf.compat.v1.pad_16/Pad) shape:[1, 354, 354, 3], type:FLOAT32\n",
      "  T#155(model_5/tf.nn.relu_48/Relu;model_5/tf.math.add_144/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_108/convolution;Const_144) shape:[1, 176, 176, 24], type:FLOAT32\n",
      "  T#156(model_5/tf.compat.v1.pad_17/Pad) shape:[1, 178, 178, 24], type:FLOAT32\n",
      "  T#157(model_5/tf.nn.max_pool2d_1/MaxPool2d) shape:[1, 88, 88, 24], type:FLOAT32\n",
      "  T#158(model_5/tf.compat.v1.pad_18/Pad) shape:[1, 90, 90, 24], type:FLOAT32\n",
      "  T#159(model_5/tf.math.add_145/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_28/depthwise;Const_136) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#160(model_5/tf.nn.relu_49/Relu;model_5/tf.math.add_146/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_109/convolution;Const_142) shape:[1, 88, 88, 24], type:FLOAT32\n",
      "  T#161(model_5/tf.compat.v1.pad_19/Pad) shape:[1, 90, 90, 24], type:FLOAT32\n",
      "  T#162(model_5/tf.math.add_148/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_29/depthwise;Const_137) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#163(model_5/tf.nn.relu_50/Relu;model_5/tf.math.add_147/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_110/convolution;Const_132) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#164(model_5/tf.nn.relu_51/Relu;model_5/tf.math.add_149/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_111/convolution;Const_133) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#165(model_5/tf.concat_615/concat) shape:[1, 44, 44, 48], type:FLOAT32\n",
      "  T#166(model_5/tf.compat.v1.transpose_1232/transpose) shape:[1, 48, 44, 44], type:FLOAT32\n",
      "  T#167(model_5/tf.reshape_31/Reshape) shape:[24, 2, 1936], type:FLOAT32\n",
      "  T#168(model_5/tf.compat.v1.transpose_1233/transpose) shape:[2, 24, 1936], type:FLOAT32\n",
      "  T#169(model_5/tf.reshape_32/Reshape) shape:[2, 1, 24, 44, 44], type:FLOAT32\n",
      "  T#170(model_5/tf.compat.v1.gather_26/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:FLOAT32\n",
      "  T#171(model_5/tf.compat.v1.transpose_1236/transpose) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#172(model_5/tf.compat.v1.gather_27/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:FLOAT32\n",
      "  T#173(model_5/tf.compat.v1.transpose_1235/transpose) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#174(model_5/tf.nn.relu_52/Relu;model_5/tf.math.add_150/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_112/convolution;Const_130) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#175(model_5/tf.math.add_151/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_30/depthwise;Const_128) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#176(model_5/tf.nn.relu_53/Relu;model_5/tf.math.add_152/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_113/convolution;Const_126) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#177(model_5/tf.concat_616/concat) shape:[1, 44, 44, 48], type:FLOAT32\n",
      "  T#178(model_5/tf.compat.v1.transpose_1237/transpose) shape:[1, 48, 44, 44], type:FLOAT32\n",
      "  T#179(model_5/tf.reshape_33/Reshape) shape:[24, 2, 1936], type:FLOAT32\n",
      "  T#180(model_5/tf.compat.v1.transpose_1238/transpose) shape:[2, 24, 1936], type:FLOAT32\n",
      "  T#181(model_5/tf.reshape_34/Reshape) shape:[2, 1, 24, 44, 44], type:FLOAT32\n",
      "  T#182(model_5/tf.compat.v1.gather_28/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:FLOAT32\n",
      "  T#183(model_5/tf.compat.v1.transpose_1241/transpose) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#184(model_5/tf.compat.v1.gather_29/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:FLOAT32\n",
      "  T#185(model_5/tf.compat.v1.transpose_1240/transpose) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#186(model_5/tf.nn.relu_54/Relu;model_5/tf.math.add_153/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_114/convolution;Const_124) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#187(model_5/tf.math.add_154/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_31/depthwise;Const_122) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#188(model_5/tf.nn.relu_55/Relu;model_5/tf.math.add_155/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_115/convolution;Const_120) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#189(model_5/tf.concat_617/concat) shape:[1, 44, 44, 48], type:FLOAT32\n",
      "  T#190(model_5/tf.compat.v1.transpose_1242/transpose) shape:[1, 48, 44, 44], type:FLOAT32\n",
      "  T#191(model_5/tf.reshape_35/Reshape) shape:[24, 2, 1936], type:FLOAT32\n",
      "  T#192(model_5/tf.compat.v1.transpose_1243/transpose) shape:[2, 24, 1936], type:FLOAT32\n",
      "  T#193(model_5/tf.reshape_36/Reshape) shape:[2, 1, 24, 44, 44], type:FLOAT32\n",
      "  T#194(model_5/tf.compat.v1.gather_30/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:FLOAT32\n",
      "  T#195(model_5/tf.compat.v1.transpose_1246/transpose) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#196(model_5/tf.compat.v1.gather_31/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 24, 44, 44], type:FLOAT32\n",
      "  T#197(model_5/tf.compat.v1.transpose_1245/transpose) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#198(model_5/tf.nn.relu_56/Relu;model_5/tf.math.add_156/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.nn.convolution_116/convolution;Const_118) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#199(model_5/tf.math.add_157/Add;model_5/tf.nn.convolution_117/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_32/depthwise;Const_116) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#200(model_5/tf.nn.relu_57/Relu;model_5/tf.math.add_158/Add;model_5/tf.nn.convolution_117/convolution;Const_114) shape:[1, 44, 44, 24], type:FLOAT32\n",
      "  T#201(model_5/tf.concat_618/concat) shape:[1, 44, 44, 48], type:FLOAT32\n",
      "  T#202(model_5/tf.compat.v1.pad_20/Pad) shape:[1, 46, 46, 48], type:FLOAT32\n",
      "  T#203(model_5/tf.math.add_159/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_33/depthwise;Const_106) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#204(model_5/tf.compat.v1.nn.avg_pool_1/AvgPool) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#205(model_5/tf.nn.relu_58/Relu;model_5/tf.math.add_160/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_118/convolution;Const_112) shape:[1, 44, 44, 48], type:FLOAT32\n",
      "  T#206(model_5/tf.compat.v1.pad_22/Pad) shape:[1, 46, 46, 48], type:FLOAT32\n",
      "  T#207(model_5/tf.math.add_162/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_34/depthwise;Const_107) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#208(model_5/tf.nn.relu_59/Relu;model_5/tf.math.add_161/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_119/convolution;Const_102) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#209(model_5/tf.nn.relu_60/Relu;model_5/tf.math.add_163/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_120/convolution;Const_103) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#210(model_5/tf.concat_619/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#211(model_5/tf.compat.v1.transpose_1247/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#212(model_5/tf.reshape_37/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#213(model_5/tf.compat.v1.transpose_1248/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#214(model_5/tf.reshape_38/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#215(model_5/tf.compat.v1.gather_32/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#216(model_5/tf.compat.v1.transpose_1251/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#217(model_5/tf.compat.v1.gather_33/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#218(model_5/tf.compat.v1.transpose_1250/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#219(model_5/tf.nn.relu_61/Relu;model_5/tf.math.add_164/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_121/convolution;Const_100) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#220(model_5/tf.math.add_165/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_35/depthwise;Const_98) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#221(model_5/tf.nn.relu_62/Relu;model_5/tf.math.add_166/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_122/convolution;Const_96) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#222(model_5/tf.concat_620/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#223(model_5/tf.compat.v1.transpose_1252/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#224(model_5/tf.reshape_39/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#225(model_5/tf.compat.v1.transpose_1253/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#226(model_5/tf.reshape_40/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#227(model_5/tf.compat.v1.gather_34/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#228(model_5/tf.compat.v1.transpose_1256/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#229(model_5/tf.compat.v1.gather_35/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#230(model_5/tf.compat.v1.transpose_1255/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#231(model_5/tf.nn.relu_63/Relu;model_5/tf.math.add_167/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_123/convolution;Const_94) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#232(model_5/tf.math.add_168/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_36/depthwise;Const_92) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#233(model_5/tf.nn.relu_64/Relu;model_5/tf.math.add_169/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_124/convolution;Const_90) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#234(model_5/tf.concat_621/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#235(model_5/tf.compat.v1.transpose_1257/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#236(model_5/tf.reshape_41/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#237(model_5/tf.compat.v1.transpose_1258/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#238(model_5/tf.reshape_42/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#239(model_5/tf.compat.v1.gather_36/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#240(model_5/tf.compat.v1.transpose_1261/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#241(model_5/tf.compat.v1.gather_37/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#242(model_5/tf.compat.v1.transpose_1260/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#243(model_5/tf.nn.relu_65/Relu;model_5/tf.math.add_170/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_125/convolution;Const_88) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#244(model_5/tf.math.add_171/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_37/depthwise;Const_86) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#245(model_5/tf.nn.relu_66/Relu;model_5/tf.math.add_172/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_126/convolution;Const_84) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#246(model_5/tf.concat_622/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#247(model_5/tf.compat.v1.transpose_1262/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#248(model_5/tf.reshape_43/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#249(model_5/tf.compat.v1.transpose_1263/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#250(model_5/tf.reshape_44/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#251(model_5/tf.compat.v1.gather_38/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#252(model_5/tf.compat.v1.transpose_1266/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#253(model_5/tf.compat.v1.gather_39/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#254(model_5/tf.compat.v1.transpose_1265/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#255(model_5/tf.nn.relu_67/Relu;model_5/tf.math.add_173/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_127/convolution;Const_82) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#256(model_5/tf.math.add_174/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_38/depthwise;Const_80) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#257(model_5/tf.nn.relu_68/Relu;model_5/tf.math.add_175/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_128/convolution;Const_78) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#258(model_5/tf.concat_623/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#259(model_5/tf.compat.v1.transpose_1267/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#260(model_5/tf.reshape_45/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#261(model_5/tf.compat.v1.transpose_1268/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#262(model_5/tf.reshape_46/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#263(model_5/tf.compat.v1.gather_40/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#264(model_5/tf.compat.v1.transpose_1271/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#265(model_5/tf.compat.v1.gather_41/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#266(model_5/tf.compat.v1.transpose_1270/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#267(model_5/tf.nn.relu_69/Relu;model_5/tf.math.add_176/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_129/convolution;Const_76) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#268(model_5/tf.math.add_177/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_39/depthwise;Const_74) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#269(model_5/tf.nn.relu_70/Relu;model_5/tf.math.add_178/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_130/convolution;Const_72) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#270(model_5/tf.concat_624/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#271(model_5/tf.compat.v1.transpose_1272/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#272(model_5/tf.reshape_47/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#273(model_5/tf.compat.v1.transpose_1273/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#274(model_5/tf.reshape_48/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#275(model_5/tf.compat.v1.gather_42/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#276(model_5/tf.compat.v1.transpose_1276/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#277(model_5/tf.compat.v1.gather_43/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#278(model_5/tf.compat.v1.transpose_1275/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#279(model_5/tf.nn.relu_71/Relu;model_5/tf.math.add_179/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_131/convolution;Const_70) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#280(model_5/tf.math.add_180/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_40/depthwise;Const_68) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#281(model_5/tf.nn.relu_72/Relu;model_5/tf.math.add_181/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_132/convolution;Const_66) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#282(model_5/tf.concat_625/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#283(model_5/tf.compat.v1.transpose_1277/transpose) shape:[1, 96, 22, 22], type:FLOAT32\n",
      "  T#284(model_5/tf.reshape_49/Reshape) shape:[48, 2, 484], type:FLOAT32\n",
      "  T#285(model_5/tf.compat.v1.transpose_1278/transpose) shape:[2, 48, 484], type:FLOAT32\n",
      "  T#286(model_5/tf.reshape_50/Reshape) shape:[2, 1, 48, 22, 22], type:FLOAT32\n",
      "  T#287(model_5/tf.compat.v1.gather_44/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#288(model_5/tf.compat.v1.transpose_1281/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#289(model_5/tf.compat.v1.gather_45/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 48, 22, 22], type:FLOAT32\n",
      "  T#290(model_5/tf.compat.v1.transpose_1280/transpose) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#291(model_5/tf.nn.relu_73/Relu;model_5/tf.math.add_182/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.nn.convolution_133/convolution;Const_64) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#292(model_5/tf.math.add_183/Add;model_5/tf.nn.convolution_134/convolution;model_5/tf.compat.v1.nn.depthwise_conv2d_41/depthwise;Const_62) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#293(model_5/tf.nn.relu_74/Relu;model_5/tf.math.add_184/Add;model_5/tf.nn.convolution_134/convolution;Const_60) shape:[1, 22, 22, 48], type:FLOAT32\n",
      "  T#294(model_5/tf.concat_626/concat) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#295(model_5/tf.compat.v1.pad_23/Pad) shape:[1, 24, 24, 96], type:FLOAT32\n",
      "  T#296(model_5/tf.math.add_185/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_42/depthwise;Const_52) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#297(model_5/tf.nn.relu_75/Relu;model_5/tf.math.add_186/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_135/convolution;Const_58) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#298(model_5/tf.compat.v1.pad_24/Pad) shape:[1, 24, 24, 96], type:FLOAT32\n",
      "  T#299(model_5/tf.math.add_188/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_43/depthwise;Const_53) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#300(model_5/tf.nn.relu_76/Relu;model_5/tf.math.add_187/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_136/convolution;Const_48) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#301(model_5/tf.nn.relu_77/Relu;model_5/tf.math.add_189/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_137/convolution;Const_49) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#302(model_5/tf.concat_627/concat) shape:[1, 11, 11, 192], type:FLOAT32\n",
      "  T#303(model_5/tf.compat.v1.transpose_1282/transpose) shape:[1, 192, 11, 11], type:FLOAT32\n",
      "  T#304(model_5/tf.reshape_51/Reshape) shape:[96, 2, 121], type:FLOAT32\n",
      "  T#305(model_5/tf.compat.v1.transpose_1283/transpose) shape:[2, 96, 121], type:FLOAT32\n",
      "  T#306(model_5/tf.reshape_52/Reshape) shape:[2, 1, 96, 11, 11], type:FLOAT32\n",
      "  T#307(model_5/tf.compat.v1.gather_46/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:FLOAT32\n",
      "  T#308(model_5/tf.compat.v1.transpose_1286/transpose) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#309(model_5/tf.compat.v1.gather_47/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:FLOAT32\n",
      "  T#310(model_5/tf.compat.v1.transpose_1285/transpose) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#311(model_5/tf.nn.relu_78/Relu;model_5/tf.math.add_190/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_138/convolution;Const_46) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#312(model_5/tf.math.add_191/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_44/depthwise;Const_44) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#313(model_5/tf.nn.relu_79/Relu;model_5/tf.math.add_192/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_139/convolution;Const_42) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#314(model_5/tf.concat_628/concat) shape:[1, 11, 11, 192], type:FLOAT32\n",
      "  T#315(model_5/tf.compat.v1.transpose_1287/transpose) shape:[1, 192, 11, 11], type:FLOAT32\n",
      "  T#316(model_5/tf.reshape_53/Reshape) shape:[96, 2, 121], type:FLOAT32\n",
      "  T#317(model_5/tf.compat.v1.transpose_1288/transpose) shape:[2, 96, 121], type:FLOAT32\n",
      "  T#318(model_5/tf.reshape_54/Reshape) shape:[2, 1, 96, 11, 11], type:FLOAT32\n",
      "  T#319(model_5/tf.compat.v1.gather_48/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:FLOAT32\n",
      "  T#320(model_5/tf.compat.v1.transpose_1291/transpose) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#321(model_5/tf.compat.v1.gather_49/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:FLOAT32\n",
      "  T#322(model_5/tf.compat.v1.transpose_1290/transpose) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#323(model_5/tf.nn.relu_80/Relu;model_5/tf.math.add_193/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_140/convolution;Const_40) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#324(model_5/tf.math.add_194/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_45/depthwise;Const_38) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#325(model_5/tf.nn.relu_81/Relu;model_5/tf.math.add_195/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_141/convolution;Const_36) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#326(model_5/tf.concat_629/concat) shape:[1, 11, 11, 192], type:FLOAT32\n",
      "  T#327(model_5/tf.compat.v1.transpose_1292/transpose) shape:[1, 192, 11, 11], type:FLOAT32\n",
      "  T#328(model_5/tf.reshape_55/Reshape) shape:[96, 2, 121], type:FLOAT32\n",
      "  T#329(model_5/tf.compat.v1.transpose_1293/transpose) shape:[2, 96, 121], type:FLOAT32\n",
      "  T#330(model_5/tf.reshape_56/Reshape) shape:[2, 1, 96, 11, 11], type:FLOAT32\n",
      "  T#331(model_5/tf.compat.v1.gather_50/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:FLOAT32\n",
      "  T#332(model_5/tf.compat.v1.transpose_1296/transpose) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#333(model_5/tf.compat.v1.gather_51/GatherV2;model_5/tf.compat.v1.gather_26/GatherV2/axis) shape:[1, 96, 11, 11], type:FLOAT32\n",
      "  T#334(model_5/tf.compat.v1.transpose_1295/transpose) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#335(model_5/tf.nn.relu_82/Relu;model_5/tf.math.add_196/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_142/convolution;Const_34) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#336(model_5/tf.math.add_197/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_46/depthwise;Const_32) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#337(model_5/tf.nn.relu_83/Relu;model_5/tf.math.add_198/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_143/convolution;Const_30) shape:[1, 11, 11, 96], type:FLOAT32\n",
      "  T#338(model_5/tf.concat_630/concat) shape:[1, 11, 11, 192], type:FLOAT32\n",
      "  T#339(model_5/lambda_3/Resize_226) shape:[1, 22, 22, 192], type:FLOAT32\n",
      "  T#340(model_5/tf.concat_631/concat) shape:[1, 22, 22, 336], type:FLOAT32\n",
      "  T#341(model_5/tf.nn.relu_84/Relu;model_5/tf.math.add_199/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_144/convolution;Const_28) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#342(model_5/tf.nn.relu_85/Relu;model_5/tf.math.add_200/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_47/depthwise;Const_16) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#343(model_5/tf.nn.relu_86/Relu;model_5/tf.math.add_201/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_48/depthwise;Const_22) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#344(model_5/tf.nn.relu_88/Relu;model_5/tf.math.add_203/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_50/depthwise;Const_17) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#345(model_5/tf.nn.relu_87/Relu;model_5/tf.math.add_202/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_49/depthwise;Const_26) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#346(model_5/tf.nn.relu_89/Relu;model_5/tf.math.add_204/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_51/depthwise;Const_23) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#347(model_5/tf.nn.relu_90/Relu;model_5/tf.math.add_205/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_52/depthwise;Const_18) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#348(model_5/tf.concat_632/concat) shape:[1, 22, 22, 288], type:FLOAT32\n",
      "  T#349(model_5/tf.math.add_206/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_145/convolution;Const_14) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#350(model_5/tf.nn.relu_91/Relu;model_5/tf.math.add_207/Add) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#351(model_5/tf.nn.relu_92/Relu;model_5/tf.math.add_208/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.nn.convolution_146/convolution;Const_12) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#352(model_5/tf.nn.relu_93/Relu;model_5/tf.math.add_209/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_53/depthwise;Const_6) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#353(model_5/tf.nn.relu_94/Relu;model_5/tf.math.add_210/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;model_5/tf.compat.v1.nn.depthwise_conv2d_54/depthwise;Const_4) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#354(model_5/tf.nn.relu_95/Relu;model_5/tf.math.add_211/Add;model_5/tf.compat.v1.nn.depthwise_conv2d_55/depthwise;Const_10) shape:[1, 22, 22, 96], type:FLOAT32\n",
      "  T#355(model_5/tf.math.add_212/Add;model_5/tf.nn.convolution_147/convolution;Const_1) shape:[1, 22, 22, 1], type:FLOAT32\n",
      "  T#356(model_5/tf.math.sigmoid_59/Sigmoid) shape:[1, 22, 22, 1], type:FLOAT32\n",
      "  T#357(model_5/tf.math.add_213/Add;model_5/tf.nn.convolution_148/convolution;Const) shape:[1, 22, 22, 4], type:FLOAT32\n",
      "  T#358(model_5/tf.math.add_214/Add;model_5/tf.nn.convolution_149/convolution;Const_5) shape:[1, 22, 22, 80], type:FLOAT32\n",
      "  T#359(model_5/tf.nn.softmax_2/Softmax_262) shape:[1, 22, 22, 80], type:FLOAT32\n",
      "  T#360(PartitionedCall:0) shape:[1, 22, 22, 85], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'input.1' : T#0\n",
      "- Outputs: \n",
      "    '758' : T#360\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:     392864 bytes\n",
      "    Non-data buffer size:      92896 bytes (23.65 %)\n",
      "  Total data buffer size:     299968 bytes (76.35 %)\n",
      "    (Zero value buffers):          4 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FASTEST_DET = f\"{saved_model_fastest_det}/FastestDet_dynamic_range_quant.tflite\"\n",
    "\n",
    "tf.lite.experimental.Analyzer.analyze(FASTEST_DET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392864\n",
      "392864\n",
      "1964404\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"models/fastest_det_rom_dyn_range.h\"\n",
    "HEADER = \"models/fastest_det_dyn.h\"\n",
    "\n",
    "print(get_file_size(FASTEST_DET))\n",
    "\n",
    "model_size = c_style_hexdump(FASTEST_DET, MODEL, \"model_data\")\n",
    "\n",
    "print(model_size)\n",
    "\n",
    "print(get_file_size(MODEL))\n",
    "# build_header(HEADER, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421784\n",
      "421784\n",
      "2109004\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/43749\n",
    "\n",
    "ODEL = \"models/fastest_det_rom_full_int.h\"\n",
    "HEADER = \"models/fastest_det_full.h\"\n",
    "\n",
    "print(get_file_size(fastest_det_quant_file))\n",
    "\n",
    "model_size = c_style_hexdump(fastest_det_quant_file, MODEL, \"model_data\")\n",
    "\n",
    "print(model_size)\n",
    "\n",
    "print(get_file_size(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from `saved_model` to `.tflite`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 640, 640, 3)\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 3.34 Megabytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 20:49:38.787659: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-05-11 20:49:38.787707: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-05-11 20:49:38.787850: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: saved_model\n",
      "2024-05-11 20:49:38.792667: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-05-11 20:49:38.792695: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: saved_model\n",
      "2024-05-11 20:49:38.802549: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-05-11 20:49:38.829788: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: saved_model\n",
      "2024-05-11 20:49:38.854778: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 66927 microseconds.\n",
      "2024-05-11 20:49:39.226956: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 9.744 G  ops, equivalently 4.872 G  MACs\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model\")\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# converter.representative_dataset = representative_dataset\n",
    "\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.uint8\n",
    "# converter.inference_output_type = tf.uint8\n",
    "\n",
    "file = converter.convert()\n",
    "\n",
    "_, baseline_quantized = tempfile.mkstemp(\".tflite\")\n",
    "\n",
    "with open(baseline_quantized, \"wb\") as f:\n",
    "    f.write(file)\n",
    "\n",
    "convert_bytes(get_file_size(baseline_quantized), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /tmp/tmp315mnjlf.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the PAD op takes\n",
      "tensor #0 and tensor #13 as input and produces tensor #157 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#409]\n",
      "  Op#0 PAD(T#0, T#13[0, 0, 1, 1, 1, ...]) -> [T#157]\n",
      "  Op#1 CONV_2D(T#157, T#94, T#18) -> [T#158]\n",
      "  Op#2 LOGISTIC(T#158) -> [T#159]\n",
      "  Op#3 MUL(T#158, T#159) -> [T#160]\n",
      "  Op#4 PAD(T#160, T#13[0, 0, 1, 1, 1, ...]) -> [T#161]\n",
      "  Op#5 CONV_2D(T#161, T#95, T#19) -> [T#162]\n",
      "  Op#6 LOGISTIC(T#162) -> [T#163]\n",
      "  Op#7 MUL(T#162, T#163) -> [T#164]\n",
      "  Op#8 CONV_2D(T#164, T#96, T#20) -> [T#165]\n",
      "  Op#9 LOGISTIC(T#165) -> [T#166]\n",
      "  Op#10 MUL(T#165, T#166) -> [T#167]\n",
      "  Op#11 STRIDED_SLICE(T#167, T#93[0, 0, 0, 0], T#92[0, 0, 0, 16], T#91[1, 1, 1, 1]) -> [T#168]\n",
      "  Op#12 STRIDED_SLICE(T#167, T#92[0, 0, 0, 16], T#90[0, 0, 0, 32], T#91[1, 1, 1, 1]) -> [T#169]\n",
      "  Op#13 CONV_2D(T#169, T#97, T#21) -> [T#170]\n",
      "  Op#14 LOGISTIC(T#170) -> [T#171]\n",
      "  Op#15 MUL(T#170, T#171) -> [T#172]\n",
      "  Op#16 CONV_2D(T#172, T#98, T#22) -> [T#173]\n",
      "  Op#17 LOGISTIC(T#173) -> [T#174]\n",
      "  Op#18 MUL(T#173, T#174) -> [T#175]\n",
      "  Op#19 ADD(T#169, T#175) -> [T#176]\n",
      "  Op#20 CONCATENATION(T#168, T#169, T#176) -> [T#177]\n",
      "  Op#21 CONV_2D(T#177, T#99, T#23) -> [T#178]\n",
      "  Op#22 LOGISTIC(T#178) -> [T#179]\n",
      "  Op#23 MUL(T#178, T#179) -> [T#180]\n",
      "  Op#24 PAD(T#180, T#13[0, 0, 1, 1, 1, ...]) -> [T#181]\n",
      "  Op#25 CONV_2D(T#181, T#100, T#24) -> [T#182]\n",
      "  Op#26 LOGISTIC(T#182) -> [T#183]\n",
      "  Op#27 MUL(T#182, T#183) -> [T#184]\n",
      "  Op#28 CONV_2D(T#184, T#101, T#25) -> [T#185]\n",
      "  Op#29 LOGISTIC(T#185) -> [T#186]\n",
      "  Op#30 MUL(T#185, T#186) -> [T#187]\n",
      "  Op#31 STRIDED_SLICE(T#187, T#93[0, 0, 0, 0], T#90[0, 0, 0, 32], T#91[1, 1, 1, 1]) -> [T#188]\n",
      "  Op#32 STRIDED_SLICE(T#187, T#90[0, 0, 0, 32], T#89[0, 0, 0, 64], T#91[1, 1, 1, 1]) -> [T#189]\n",
      "  Op#33 CONV_2D(T#189, T#102, T#26) -> [T#190]\n",
      "  Op#34 LOGISTIC(T#190) -> [T#191]\n",
      "  Op#35 MUL(T#190, T#191) -> [T#192]\n",
      "  Op#36 CONV_2D(T#192, T#103, T#27) -> [T#193]\n",
      "  Op#37 LOGISTIC(T#193) -> [T#194]\n",
      "  Op#38 MUL(T#193, T#194) -> [T#195]\n",
      "  Op#39 ADD(T#189, T#195) -> [T#196]\n",
      "  Op#40 CONV_2D(T#196, T#104, T#28) -> [T#197]\n",
      "  Op#41 LOGISTIC(T#197) -> [T#198]\n",
      "  Op#42 MUL(T#197, T#198) -> [T#199]\n",
      "  Op#43 CONV_2D(T#199, T#105, T#29) -> [T#200]\n",
      "  Op#44 LOGISTIC(T#200) -> [T#201]\n",
      "  Op#45 MUL(T#200, T#201) -> [T#202]\n",
      "  Op#46 ADD(T#196, T#202) -> [T#203]\n",
      "  Op#47 CONCATENATION(T#188, T#189, T#196, T#203) -> [T#204]\n",
      "  Op#48 CONV_2D(T#204, T#106, T#30) -> [T#205]\n",
      "  Op#49 LOGISTIC(T#205) -> [T#206]\n",
      "  Op#50 MUL(T#205, T#206) -> [T#207]\n",
      "  Op#51 PAD(T#207, T#13[0, 0, 1, 1, 1, ...]) -> [T#208]\n",
      "  Op#52 CONV_2D(T#208, T#107, T#31) -> [T#209]\n",
      "  Op#53 LOGISTIC(T#209) -> [T#210]\n",
      "  Op#54 MUL(T#209, T#210) -> [T#211]\n",
      "  Op#55 CONV_2D(T#211, T#108, T#32) -> [T#212]\n",
      "  Op#56 LOGISTIC(T#212) -> [T#213]\n",
      "  Op#57 MUL(T#212, T#213) -> [T#214]\n",
      "  Op#58 STRIDED_SLICE(T#214, T#93[0, 0, 0, 0], T#89[0, 0, 0, 64], T#91[1, 1, 1, 1]) -> [T#215]\n",
      "  Op#59 STRIDED_SLICE(T#214, T#89[0, 0, 0, 64], T#88[0, 0, 0, 128], T#91[1, 1, 1, 1]) -> [T#216]\n",
      "  Op#60 CONV_2D(T#216, T#109, T#33) -> [T#217]\n",
      "  Op#61 LOGISTIC(T#217) -> [T#218]\n",
      "  Op#62 MUL(T#217, T#218) -> [T#219]\n",
      "  Op#63 CONV_2D(T#219, T#110, T#34) -> [T#220]\n",
      "  Op#64 LOGISTIC(T#220) -> [T#221]\n",
      "  Op#65 MUL(T#220, T#221) -> [T#222]\n",
      "  Op#66 ADD(T#216, T#222) -> [T#223]\n",
      "  Op#67 CONV_2D(T#223, T#111, T#35) -> [T#224]\n",
      "  Op#68 LOGISTIC(T#224) -> [T#225]\n",
      "  Op#69 MUL(T#224, T#225) -> [T#226]\n",
      "  Op#70 CONV_2D(T#226, T#112, T#36) -> [T#227]\n",
      "  Op#71 LOGISTIC(T#227) -> [T#228]\n",
      "  Op#72 MUL(T#227, T#228) -> [T#229]\n",
      "  Op#73 ADD(T#223, T#229) -> [T#230]\n",
      "  Op#74 CONCATENATION(T#215, T#216, T#223, T#230) -> [T#231]\n",
      "  Op#75 CONV_2D(T#231, T#113, T#37) -> [T#232]\n",
      "  Op#76 LOGISTIC(T#232) -> [T#233]\n",
      "  Op#77 MUL(T#232, T#233) -> [T#234]\n",
      "  Op#78 PAD(T#234, T#13[0, 0, 1, 1, 1, ...]) -> [T#235]\n",
      "  Op#79 CONV_2D(T#235, T#114, T#38) -> [T#236]\n",
      "  Op#80 LOGISTIC(T#236) -> [T#237]\n",
      "  Op#81 MUL(T#236, T#237) -> [T#238]\n",
      "  Op#82 CONV_2D(T#238, T#115, T#39) -> [T#239]\n",
      "  Op#83 LOGISTIC(T#239) -> [T#240]\n",
      "  Op#84 MUL(T#239, T#240) -> [T#241]\n",
      "  Op#85 STRIDED_SLICE(T#241, T#93[0, 0, 0, 0], T#88[0, 0, 0, 128], T#91[1, 1, 1, 1]) -> [T#242]\n",
      "  Op#86 STRIDED_SLICE(T#241, T#88[0, 0, 0, 128], T#87[0, 0, 0, 256], T#91[1, 1, 1, 1]) -> [T#243]\n",
      "  Op#87 CONV_2D(T#243, T#116, T#40) -> [T#244]\n",
      "  Op#88 LOGISTIC(T#244) -> [T#245]\n",
      "  Op#89 MUL(T#244, T#245) -> [T#246]\n",
      "  Op#90 CONV_2D(T#246, T#117, T#41) -> [T#247]\n",
      "  Op#91 LOGISTIC(T#247) -> [T#248]\n",
      "  Op#92 MUL(T#247, T#248) -> [T#249]\n",
      "  Op#93 ADD(T#243, T#249) -> [T#250]\n",
      "  Op#94 CONCATENATION(T#242, T#243, T#250) -> [T#251]\n",
      "  Op#95 CONV_2D(T#251, T#118, T#42) -> [T#252]\n",
      "  Op#96 LOGISTIC(T#252) -> [T#253]\n",
      "  Op#97 MUL(T#252, T#253) -> [T#254]\n",
      "  Op#98 CONV_2D(T#254, T#119, T#43) -> [T#255]\n",
      "  Op#99 LOGISTIC(T#255) -> [T#256]\n",
      "  Op#100 MUL(T#255, T#256) -> [T#257]\n",
      "  Op#101 MAX_POOL_2D(T#257) -> [T#258]\n",
      "  Op#102 MAX_POOL_2D(T#258) -> [T#259]\n",
      "  Op#103 MAX_POOL_2D(T#259) -> [T#260]\n",
      "  Op#104 CONCATENATION(T#257, T#258, T#259, T#260) -> [T#261]\n",
      "  Op#105 CONV_2D(T#261, T#120, T#44) -> [T#262]\n",
      "  Op#106 LOGISTIC(T#262) -> [T#263]\n",
      "  Op#107 MUL(T#262, T#263) -> [T#264]\n",
      "  Op#108 RESIZE_NEAREST_NEIGHBOR(T#264, T#11[40, 40]) -> [T#265]\n",
      "  Op#109 CONCATENATION(T#265, T#234) -> [T#266]\n",
      "  Op#110 CONV_2D(T#266, T#121, T#45) -> [T#267]\n",
      "  Op#111 LOGISTIC(T#267) -> [T#268]\n",
      "  Op#112 MUL(T#267, T#268) -> [T#269]\n",
      "  Op#113 STRIDED_SLICE(T#269, T#93[0, 0, 0, 0], T#89[0, 0, 0, 64], T#91[1, 1, 1, 1]) -> [T#270]\n",
      "  Op#114 STRIDED_SLICE(T#269, T#89[0, 0, 0, 64], T#88[0, 0, 0, 128], T#91[1, 1, 1, 1]) -> [T#271]\n",
      "  Op#115 CONV_2D(T#271, T#122, T#46) -> [T#272]\n",
      "  Op#116 LOGISTIC(T#272) -> [T#273]\n",
      "  Op#117 MUL(T#272, T#273) -> [T#274]\n",
      "  Op#118 CONV_2D(T#274, T#123, T#47) -> [T#275]\n",
      "  Op#119 LOGISTIC(T#275) -> [T#276]\n",
      "  Op#120 MUL(T#275, T#276) -> [T#277]\n",
      "  Op#121 CONCATENATION(T#270, T#271, T#277) -> [T#278]\n",
      "  Op#122 CONV_2D(T#278, T#124, T#48) -> [T#279]\n",
      "  Op#123 LOGISTIC(T#279) -> [T#280]\n",
      "  Op#124 MUL(T#279, T#280) -> [T#281]\n",
      "  Op#125 RESIZE_NEAREST_NEIGHBOR(T#281, T#10[80, 80]) -> [T#282]\n",
      "  Op#126 CONCATENATION(T#282, T#207) -> [T#283]\n",
      "  Op#127 CONV_2D(T#283, T#125, T#49) -> [T#284]\n",
      "  Op#128 LOGISTIC(T#284) -> [T#285]\n",
      "  Op#129 MUL(T#284, T#285) -> [T#286]\n",
      "  Op#130 STRIDED_SLICE(T#286, T#93[0, 0, 0, 0], T#90[0, 0, 0, 32], T#91[1, 1, 1, 1]) -> [T#287]\n",
      "  Op#131 STRIDED_SLICE(T#286, T#90[0, 0, 0, 32], T#89[0, 0, 0, 64], T#91[1, 1, 1, 1]) -> [T#288]\n",
      "  Op#132 CONV_2D(T#288, T#126, T#50) -> [T#289]\n",
      "  Op#133 LOGISTIC(T#289) -> [T#290]\n",
      "  Op#134 MUL(T#289, T#290) -> [T#291]\n",
      "  Op#135 CONV_2D(T#291, T#127, T#51) -> [T#292]\n",
      "  Op#136 LOGISTIC(T#292) -> [T#293]\n",
      "  Op#137 MUL(T#292, T#293) -> [T#294]\n",
      "  Op#138 CONCATENATION(T#287, T#288, T#294) -> [T#295]\n",
      "  Op#139 CONV_2D(T#295, T#128, T#52) -> [T#296]\n",
      "  Op#140 LOGISTIC(T#296) -> [T#297]\n",
      "  Op#141 MUL(T#296, T#297) -> [T#298]\n",
      "  Op#142 PAD(T#298, T#13[0, 0, 1, 1, 1, ...]) -> [T#299]\n",
      "  Op#143 CONV_2D(T#299, T#129, T#53) -> [T#300]\n",
      "  Op#144 LOGISTIC(T#300) -> [T#301]\n",
      "  Op#145 MUL(T#300, T#301) -> [T#302]\n",
      "  Op#146 CONCATENATION(T#302, T#281) -> [T#303]\n",
      "  Op#147 CONV_2D(T#303, T#130, T#54) -> [T#304]\n",
      "  Op#148 LOGISTIC(T#304) -> [T#305]\n",
      "  Op#149 MUL(T#304, T#305) -> [T#306]\n",
      "  Op#150 CONV_2D(T#298, T#131, T#55) -> [T#307]\n",
      "  Op#151 LOGISTIC(T#307) -> [T#308]\n",
      "  Op#152 MUL(T#307, T#308) -> [T#309]\n",
      "  Op#153 CONV_2D(T#309, T#132, T#56) -> [T#310]\n",
      "  Op#154 LOGISTIC(T#310) -> [T#311]\n",
      "  Op#155 MUL(T#310, T#311) -> [T#312]\n",
      "  Op#156 CONV_2D(T#312, T#133, T#57) -> [T#313]\n",
      "  Op#157 CONV_2D(T#298, T#134, T#58) -> [T#314]\n",
      "  Op#158 LOGISTIC(T#314) -> [T#315]\n",
      "  Op#159 MUL(T#314, T#315) -> [T#316]\n",
      "  Op#160 CONV_2D(T#316, T#135, T#59) -> [T#317]\n",
      "  Op#161 LOGISTIC(T#317) -> [T#318]\n",
      "  Op#162 MUL(T#317, T#318) -> [T#319]\n",
      "  Op#163 CONV_2D(T#319, T#136, T#60) -> [T#320]\n",
      "  Op#164 CONCATENATION(T#313, T#320) -> [T#321]\n",
      "  Op#165 TRANSPOSE(T#321, T#9[0, 3, 1, 2]) -> [T#322]\n",
      "  Op#166 RESHAPE(T#322, T#5[1, 144, 6400]) -> [T#323]\n",
      "  Op#167 STRIDED_SLICE(T#306, T#93[0, 0, 0, 0], T#89[0, 0, 0, 64], T#91[1, 1, 1, 1]) -> [T#324]\n",
      "  Op#168 STRIDED_SLICE(T#306, T#89[0, 0, 0, 64], T#88[0, 0, 0, 128], T#91[1, 1, 1, 1]) -> [T#325]\n",
      "  Op#169 CONV_2D(T#325, T#137, T#61) -> [T#326]\n",
      "  Op#170 LOGISTIC(T#326) -> [T#327]\n",
      "  Op#171 MUL(T#326, T#327) -> [T#328]\n",
      "  Op#172 CONV_2D(T#328, T#138, T#62) -> [T#329]\n",
      "  Op#173 LOGISTIC(T#329) -> [T#330]\n",
      "  Op#174 MUL(T#329, T#330) -> [T#331]\n",
      "  Op#175 CONCATENATION(T#324, T#325, T#331) -> [T#332]\n",
      "  Op#176 CONV_2D(T#332, T#139, T#63) -> [T#333]\n",
      "  Op#177 LOGISTIC(T#333) -> [T#334]\n",
      "  Op#178 MUL(T#333, T#334) -> [T#335]\n",
      "  Op#179 PAD(T#335, T#13[0, 0, 1, 1, 1, ...]) -> [T#336]\n",
      "  Op#180 CONV_2D(T#336, T#140, T#64) -> [T#337]\n",
      "  Op#181 LOGISTIC(T#337) -> [T#338]\n",
      "  Op#182 MUL(T#337, T#338) -> [T#339]\n",
      "  Op#183 CONCATENATION(T#339, T#264) -> [T#340]\n",
      "  Op#184 CONV_2D(T#340, T#141, T#65) -> [T#341]\n",
      "  Op#185 LOGISTIC(T#341) -> [T#342]\n",
      "  Op#186 MUL(T#341, T#342) -> [T#343]\n",
      "  Op#187 CONV_2D(T#335, T#142, T#66) -> [T#344]\n",
      "  Op#188 LOGISTIC(T#344) -> [T#345]\n",
      "  Op#189 MUL(T#344, T#345) -> [T#346]\n",
      "  Op#190 CONV_2D(T#346, T#143, T#67) -> [T#347]\n",
      "  Op#191 LOGISTIC(T#347) -> [T#348]\n",
      "  Op#192 MUL(T#347, T#348) -> [T#349]\n",
      "  Op#193 CONV_2D(T#349, T#144, T#68) -> [T#350]\n",
      "  Op#194 CONV_2D(T#335, T#145, T#69) -> [T#351]\n",
      "  Op#195 LOGISTIC(T#351) -> [T#352]\n",
      "  Op#196 MUL(T#351, T#352) -> [T#353]\n",
      "  Op#197 CONV_2D(T#353, T#146, T#70) -> [T#354]\n",
      "  Op#198 LOGISTIC(T#354) -> [T#355]\n",
      "  Op#199 MUL(T#354, T#355) -> [T#356]\n",
      "  Op#200 CONV_2D(T#356, T#147, T#71) -> [T#357]\n",
      "  Op#201 CONCATENATION(T#350, T#357) -> [T#358]\n",
      "  Op#202 TRANSPOSE(T#358, T#9[0, 3, 1, 2]) -> [T#359]\n",
      "  Op#203 RESHAPE(T#359, T#4[1, 144, 1600]) -> [T#360]\n",
      "  Op#204 STRIDED_SLICE(T#343, T#93[0, 0, 0, 0], T#88[0, 0, 0, 128], T#91[1, 1, 1, 1]) -> [T#361]\n",
      "  Op#205 STRIDED_SLICE(T#343, T#88[0, 0, 0, 128], T#87[0, 0, 0, 256], T#91[1, 1, 1, 1]) -> [T#362]\n",
      "  Op#206 CONV_2D(T#362, T#148, T#72) -> [T#363]\n",
      "  Op#207 LOGISTIC(T#363) -> [T#364]\n",
      "  Op#208 MUL(T#363, T#364) -> [T#365]\n",
      "  Op#209 CONV_2D(T#365, T#149, T#73) -> [T#366]\n",
      "  Op#210 LOGISTIC(T#366) -> [T#367]\n",
      "  Op#211 MUL(T#366, T#367) -> [T#368]\n",
      "  Op#212 CONCATENATION(T#361, T#362, T#368) -> [T#369]\n",
      "  Op#213 CONV_2D(T#369, T#150, T#74) -> [T#370]\n",
      "  Op#214 LOGISTIC(T#370) -> [T#371]\n",
      "  Op#215 MUL(T#370, T#371) -> [T#372]\n",
      "  Op#216 CONV_2D(T#372, T#151, T#75) -> [T#373]\n",
      "  Op#217 LOGISTIC(T#373) -> [T#374]\n",
      "  Op#218 MUL(T#373, T#374) -> [T#375]\n",
      "  Op#219 CONV_2D(T#375, T#152, T#76) -> [T#376]\n",
      "  Op#220 LOGISTIC(T#376) -> [T#377]\n",
      "  Op#221 MUL(T#376, T#377) -> [T#378]\n",
      "  Op#222 CONV_2D(T#378, T#153, T#77) -> [T#379]\n",
      "  Op#223 CONV_2D(T#372, T#154, T#78) -> [T#380]\n",
      "  Op#224 LOGISTIC(T#380) -> [T#381]\n",
      "  Op#225 MUL(T#380, T#381) -> [T#382]\n",
      "  Op#226 CONV_2D(T#382, T#155, T#79) -> [T#383]\n",
      "  Op#227 LOGISTIC(T#383) -> [T#384]\n",
      "  Op#228 MUL(T#383, T#384) -> [T#385]\n",
      "  Op#229 CONV_2D(T#385, T#156, T#80) -> [T#386]\n",
      "  Op#230 CONCATENATION(T#379, T#386) -> [T#387]\n",
      "  Op#231 TRANSPOSE(T#387, T#9[0, 3, 1, 2]) -> [T#388]\n",
      "  Op#232 RESHAPE(T#388, T#3[1, 144, 400]) -> [T#389]\n",
      "  Op#233 CONCATENATION(T#323, T#360, T#389) -> [T#390]\n",
      "  Op#234 STRIDED_SLICE(T#390, T#86[0, 0, 0], T#85[0, 64, 0], T#84[1, 1, 1]) -> [T#391]\n",
      "  Op#235 RESHAPE(T#391, T#2[1, 4, 16, 8400]) -> [T#392]\n",
      "  Op#236 TRANSPOSE(T#392, T#8[0, 2, 1, 3]) -> [T#393]\n",
      "  Op#237 TRANSPOSE(T#393, T#7[0, 2, 3, 1]) -> [T#394]\n",
      "  Op#238 SOFTMAX(T#394) -> [T#395]\n",
      "  Op#239 CONV_2D(T#395, T#15, T#16) -> [T#396]\n",
      "  Op#240 RESHAPE(T#396, T#17[1, 1, 4, 8400]) -> [T#397]\n",
      "  Op#241 MUL(T#397, T#6) -> [T#398]\n",
      "  Op#242 RESHAPE(T#398, T#1[1, 4, 8400]) -> [T#399]\n",
      "  Op#243 STRIDED_SLICE(T#390, T#85[0, 64, 0], T#83[0, 144, 0], T#84[1, 1, 1]) -> [T#400]\n",
      "  Op#244 LOGISTIC(T#400) -> [T#401]\n",
      "  Op#245 STRIDED_SLICE(T#399, T#86[0, 0, 0], T#82[0, 2, 0], T#84[1, 1, 1]) -> [T#402]\n",
      "  Op#246 SUB(T#12, T#402) -> [T#403]\n",
      "  Op#247 STRIDED_SLICE(T#399, T#82[0, 2, 0], T#81[0, 4, 0], T#84[1, 1, 1]) -> [T#404]\n",
      "  Op#248 ADD(T#404, T#12) -> [T#405]\n",
      "  Op#249 ADD(T#403, T#405) -> [T#406]\n",
      "  Op#250 MUL(T#406, T#14) -> [T#407]\n",
      "  Op#251 SUB(T#405, T#403) -> [T#408]\n",
      "  Op#252 CONCATENATION(T#407, T#408, T#401) -> [T#409]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_images:0) shape:[1, 640, 640, 3], type:FLOAT32\n",
      "  T#1(model_7/tf.reshape_9/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 2, data:[1, 4, 8400]\n",
      "  T#2(model_7/tf.reshape_8/Reshape/shape) shape:[4], type:INT32 RO 16 bytes, buffer: 3, data:[1, 4, 16, 8400]\n",
      "  T#3(model_7/tf.reshape_7/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 4, data:[1, 144, 400]\n",
      "  T#4(model_7/tf.reshape_6/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 5, data:[1, 144, 1600]\n",
      "  T#5(model_7/tf.reshape_5/Reshape/shape) shape:[3], type:INT32 RO 12 bytes, buffer: 6, data:[1, 144, 6400]\n",
      "  T#6(model_7/tf.math.multiply_382/Mul/y) shape:[1, 4, 8400], type:FLOAT32 RO 134400 bytes, buffer: 7, data:[0.0125, 0.0125, 0.0125, 0.0125, 0.0125, ...]\n",
      "  T#7(model_7/tf.compat.v1.transpose_2326/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 8, data:[0, 2, 3, 1]\n",
      "  T#8(model_7/tf.compat.v1.transpose_2325/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 9, data:[0, 2, 1, 3]\n",
      "  T#9(model_7/tf.compat.v1.transpose_2321/transpose/perm) shape:[4], type:INT32 RO 16 bytes, buffer: 10, data:[0, 3, 1, 2]\n",
      "  T#10(model_7/lambda_3/wa/model.13/Resize/size) shape:[2], type:INT32 RO 8 bytes, buffer: 11, data:[80, 80]\n",
      "  T#11(model_7/lambda_2/wa/model.10/Resize/size) shape:[2], type:INT32 RO 8 bytes, buffer: 12, data:[40, 40]\n",
      "  T#12(Const_3) shape:[1, 2, 8400], type:FLOAT32 RO 67200 bytes, buffer: 13, data:[0.00625, 0.01875, 0.03125, 0.04375, 0.05625, ...]\n",
      "  T#13(Const_120) shape:[4, 2], type:INT32 RO 32 bytes, buffer: 14, data:[0, 0, 1, 1, 1, ...]\n",
      "  T#14(model_7/tf.math.divide_1/truediv;Const) shape:[1, 1, 1], type:FLOAT32 RO 4 bytes, buffer: 15, data:[0.5]\n",
      "  T#15(model_7/tf.nn.convolution_131/convolution) shape:[1, 1, 1, 16], type:FLOAT32 RO 64 bytes, buffer: 16, data:[0, 1, 2, 3, 4, ...]\n",
      "  T#16(model_7/tf.nn.convolution_131/convolution1) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 17, data:[0]\n",
      "  T#17(model_7/tf.compat.v1.transpose_2329/transpose) shape:[4], type:INT32 RO 16 bytes, buffer: 18, data:[1, 1, 4, 8400]\n",
      "  T#18(Const_174) shape:[16], type:FLOAT32 RO 64 bytes, buffer: 19, data:[1.36072, 2.87563, 1.59502, 1.52119, 6.71341, ...]\n",
      "  T#19(Const_171) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 20, data:[0.834823, 0.135042, 4.2437, 0.131573, -0.581737, ...]\n",
      "  T#20(Const_169) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 21, data:[2.87758, 1.61199, 1.39985, 2.91378, 1.58388, ...]\n",
      "  T#21(Const_165) shape:[16], type:FLOAT32 RO 64 bytes, buffer: 22, data:[1.82751, 3.94976, 2.03271, 3.11424, 3.29356, ...]\n",
      "  T#22(Const_163) shape:[16], type:FLOAT32 RO 64 bytes, buffer: 23, data:[1.59743, 1.59654, 3.53328, -1.47893, 1.7329, ...]\n",
      "  T#23(Const_159) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 24, data:[1.01228, 2.52251, 3.39363, 0.363974, 3.58518, ...]\n",
      "  T#24(Const_156) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 25, data:[0.70063, 0.690369, 3.44191, 1.24739, -0.925155, ...]\n",
      "  T#25(Const_154) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 26, data:[0.649491, 1.13025, 3.0369, -0.355595, 2.45356, ...]\n",
      "  T#26(Const_150) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 27, data:[1.11284, -0.771865, 0.816024, -0.140802, -0.188204, ...]\n",
      "  T#27(Const_148) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 28, data:[-0.016261, -0.184019, 0.385608, -0.786309, -0.0806919, ...]\n",
      "  T#28(Const_146) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 29, data:[1.27787, 0.771917, -0.417795, -1.46802, -0.150831, ...]\n",
      "  T#29(Const_144) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 30, data:[-0.860723, 0.740438, -0.177764, 0.335262, -0.723959, ...]\n",
      "  T#30(Const_140) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 31, data:[0.00282443, 1.87584, 0.174678, -3.04769, 0.301321, ...]\n",
      "  T#31(Const_137) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 32, data:[-0.673072, -0.94557, -0.086089, -0.583352, 0.974652, ...]\n",
      "  T#32(Const_135) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 33, data:[1.09111, 1.06198, -1.24117, -0.597439, -2.51229, ...]\n",
      "  T#33(Const_131) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 34, data:[-1.00169, -1.61851, 0.421669, -0.846553, -0.273657, ...]\n",
      "  T#34(Const_129) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 35, data:[0.0333642, -0.885829, -0.446184, 0.335801, 0.47181, ...]\n",
      "  T#35(Const_127) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 36, data:[0.507463, 0.387176, -0.446434, 1.03909, 0.976839, ...]\n",
      "  T#36(Const_125) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 37, data:[-0.0531414, -0.829983, -0.8391, -0.829715, 1.11645, ...]\n",
      "  T#37(Const_121) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 38, data:[0.527533, 0.959538, 1.62561, 0.467298, 0.988243, ...]\n",
      "  T#38(Const_118) shape:[256], type:FLOAT32 RO 1024 bytes, buffer: 39, data:[0.0489843, -0.711045, -0.0727264, -1.25254, -0.497684, ...]\n",
      "  T#39(Const_116) shape:[256], type:FLOAT32 RO 1024 bytes, buffer: 40, data:[-1.62909, -0.843385, -1.15103, -0.258287, -0.293877, ...]\n",
      "  T#40(Const_112) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 41, data:[-1.04664, 0.039275, -0.648322, -0.360782, -1.03193, ...]\n",
      "  T#41(Const_110) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 42, data:[-0.149423, 2.57403, -0.372426, -0.22432, 0.550813, ...]\n",
      "  T#42(Const_106) shape:[256], type:FLOAT32 RO 1024 bytes, buffer: 43, data:[0.201997, -1.1351, -0.451686, 0.291155, 0.308112, ...]\n",
      "  T#43(Const_104) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 44, data:[1.48748, 0.864057, 2.08728, 2.09607, 2.38151, ...]\n",
      "  T#44(Const_102) shape:[256], type:FLOAT32 RO 1024 bytes, buffer: 45, data:[-1.42042, -1.36401, -0.0993438, -0.655365, -5.33505, ...]\n",
      "  T#45(Const_100) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 46, data:[-2.39447, -0.0183613, -0.916081, -3.48727, -1.3392, ...]\n",
      "  T#46(Const_96) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 47, data:[1.8247, -0.0259651, 0.0492792, 0.239147, -0.225671, ...]\n",
      "  T#47(Const_94) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 48, data:[-0.348454, -0.998298, -0.871081, -0.653346, 0.296764, ...]\n",
      "  T#48(Const_90) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 49, data:[-0.429278, -1.26263, 0.144764, -0.103962, 0.531942, ...]\n",
      "  T#49(Const_88) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 50, data:[1.24621, 1.347, 0.234037, 0.105675, -4.25772, ...]\n",
      "  T#50(Const_84) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 51, data:[-0.341176, 2.21229, -0.241639, -1.00373, -1.51024, ...]\n",
      "  T#51(Const_82) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 52, data:[-0.77493, 0.780948, -0.431487, -0.217551, -1.0263, ...]\n",
      "  T#52(Const_78) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 53, data:[-0.00233907, 0.167908, 0.754358, 0.954243, 2.06993, ...]\n",
      "  T#53(Const_75) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 54, data:[-3.1667, 1.26725, -0.8768, 0.941903, -1.17256, ...]\n",
      "  T#54(Const_73) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 55, data:[0.79044, -0.198552, -1.65131, -2.10819, -0.494972, ...]\n",
      "  T#55(Const_40) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 56, data:[-0.399455, 0.208415, -0.529004, 0.0277173, -2.04878, ...]\n",
      "  T#56(Const_28) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 57, data:[0.476676, -0.610192, 1.12176, 1.46996, 1.11831, ...]\n",
      "  T#57(Const_16) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 58, data:[2.31445, 2.40625, 2.30469, 1.94531, 2.63672, ...]\n",
      "  T#58(Const_46) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 59, data:[-1.97324, -0.931558, -1.68106, -1.93075, -0.802156, ...]\n",
      "  T#59(Const_34) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 60, data:[-0.392438, 5.77389, 6.95173, 4.34218, 2.00869, ...]\n",
      "  T#60(Const_17) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 61, data:[-6.38281, -11.4922, -9.63281, -11.9688, -12.1641, ...]\n",
      "  T#61(Const_69) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 62, data:[-0.729921, -0.441305, 0.000124156, -0.769954, -1.88098, ...]\n",
      "  T#62(Const_67) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 63, data:[0.111351, 0.32296, -1.66783, -3.02703, 2.08479, ...]\n",
      "  T#63(Const_63) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 64, data:[-0.531182, -0.126487, 0.345724, 0.126987, -0.990895, ...]\n",
      "  T#64(Const_60) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 65, data:[-0.981238, -0.0767639, -1.07168, -0.485074, 0.296315, ...]\n",
      "  T#65(Const_58) shape:[256], type:FLOAT32 RO 1024 bytes, buffer: 66, data:[-1.40371, -0.217599, -0.721618, -1.90172, -1.66724, ...]\n",
      "  T#66(Const_36) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 67, data:[1.5443, -0.465354, -0.0354099, 0.0810277, -0.0680133, ...]\n",
      "  T#67(Const_24) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 68, data:[1.06027, 1.08141, 1.72963, 1.51712, 1.51836, ...]\n",
      "  T#68(Const_13) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 69, data:[2.8125, 2.65234, 2.61719, 2.25586, 2.0332, ...]\n",
      "  T#69(Const_37) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 70, data:[-0.682432, -1.24226, 1.21091, 0.492044, 1.20086, ...]\n",
      "  T#70(Const_25) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 71, data:[-0.245881, 5.66335, -0.210819, 8.16803, 9.11745, ...]\n",
      "  T#71(Const_12) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 72, data:[-5.66797, -10.9609, -8.94531, -10.5781, -10.6953, ...]\n",
      "  T#72(Const_54) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 73, data:[-0.645405, -2.64791, -0.0375574, 0.00196531, -0.676532, ...]\n",
      "  T#73(Const_52) shape:[128], type:FLOAT32 RO 512 bytes, buffer: 74, data:[-1.02823, 0.53062, 0.0404796, -0.705384, -1.36715, ...]\n",
      "  T#74(Const_48) shape:[256], type:FLOAT32 RO 1024 bytes, buffer: 75, data:[-0.763399, -0.886909, -0.774657, -0.579617, -0.883503, ...]\n",
      "  T#75(Const_38) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 76, data:[-0.742871, -0.189768, -1.23154, -0.393392, -0.116633, ...]\n",
      "  T#76(Const_26) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 77, data:[2.19215, 1.5203, 0.108451, 2.37309, 1.40851, ...]\n",
      "  T#77(Const_15) shape:[64], type:FLOAT32 RO 256 bytes, buffer: 78, data:[2.27539, 2.34961, 2.22656, 2.0918, 1.94824, ...]\n",
      "  T#78(Const_39) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 79, data:[-0.458916, -1.59135, -0.895996, 0.458669, -0.665035, ...]\n",
      "  T#79(Const_27) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 80, data:[3.80754, 1.64455, 9.55976, 4.29135, 0.545861, ...]\n",
      "  T#80(Const_14) shape:[80], type:FLOAT32 RO 320 bytes, buffer: 81, data:[-4.77734, -9.70312, -8.63281, -9.25, -9.32812, ...]\n",
      "  T#81(model_7/tf.strided_slice_39/StridedSlice) shape:[3], type:INT32 RO 12 bytes, buffer: 82, data:[0, 4, 0]\n",
      "  T#82(model_7/tf.strided_slice_38/StridedSlice) shape:[3], type:INT32 RO 12 bytes, buffer: 83, data:[0, 2, 0]\n",
      "  T#83(model_7/tf.strided_slice_37/StridedSlice) shape:[3], type:INT32 RO 12 bytes, buffer: 84, data:[0, 144, 0]\n",
      "  T#84(model_7/tf.strided_slice_36/StridedSlice) shape:[3], type:INT32 RO 12 bytes, buffer: 85, data:[1, 1, 1]\n",
      "  T#85(model_7/tf.strided_slice_36/StridedSlice1) shape:[3], type:INT32 RO 12 bytes, buffer: 86, data:[0, 64, 0]\n",
      "  T#86(model_7/tf.strided_slice_36/StridedSlice2) shape:[3], type:INT32 RO 12 bytes, buffer: 87, data:[0, 0, 0]\n",
      "  T#87(model_7/tf.strided_slice_27/StridedSlice) shape:[4], type:INT32 RO 16 bytes, buffer: 88, data:[0, 0, 0, 256]\n",
      "  T#88(model_7/tf.strided_slice_25/StridedSlice) shape:[4], type:INT32 RO 16 bytes, buffer: 89, data:[0, 0, 0, 128]\n",
      "  T#89(model_7/tf.strided_slice_23/StridedSlice) shape:[4], type:INT32 RO 16 bytes, buffer: 90, data:[0, 0, 0, 64]\n",
      "  T#90(model_7/tf.strided_slice_21/StridedSlice) shape:[4], type:INT32 RO 16 bytes, buffer: 91, data:[0, 0, 0, 32]\n",
      "  T#91(model_7/tf.strided_slice_20/StridedSlice) shape:[4], type:INT32 RO 16 bytes, buffer: 92, data:[1, 1, 1, 1]\n",
      "  T#92(model_7/tf.strided_slice_20/StridedSlice1) shape:[4], type:INT32 RO 16 bytes, buffer: 93, data:[0, 0, 0, 16]\n",
      "  T#93(model_7/tf.strided_slice_20/StridedSlice2) shape:[4], type:INT32 RO 16 bytes, buffer: 94, data:[0, 0, 0, 0]\n",
      "  T#94(model_7/tf.nn.convolution_66/convolution) shape:[16, 3, 3, 3], type:FLOAT32 RO 1728 bytes, buffer: 95, data:[-2.05435, -2.53747, -0.888985, -0.188651, 0.174098, ...]\n",
      "  T#95(model_7/tf.nn.convolution_67/convolution) shape:[32, 3, 3, 16], type:INT8 RO 4608 bytes, buffer: 96, data:[., ., ., ., ., ...]\n",
      "  T#96(model_7/tf.nn.convolution_68/convolution) shape:[32, 1, 1, 32], type:INT8 RO 1024 bytes, buffer: 97, data:[., ., ., ., ., ...]\n",
      "  T#97(model_7/tf.nn.convolution_69/convolution) shape:[16, 3, 3, 16], type:INT8 RO 2304 bytes, buffer: 98, data:[., ., ., ., ., ...]\n",
      "  T#98(model_7/tf.nn.convolution_70/convolution) shape:[16, 3, 3, 16], type:INT8 RO 2304 bytes, buffer: 99, data:[., ., ., ., ., ...]\n",
      "  T#99(model_7/tf.nn.convolution_71/convolution) shape:[32, 1, 1, 48], type:INT8 RO 1536 bytes, buffer: 100, data:[., ., ., ., ., ...]\n",
      "  T#100(model_7/tf.nn.convolution_72/convolution) shape:[64, 3, 3, 32], type:INT8 RO 18432 bytes, buffer: 101, data:[., ., ., ., ., ...]\n",
      "  T#101(model_7/tf.nn.convolution_73/convolution) shape:[64, 1, 1, 64], type:INT8 RO 4096 bytes, buffer: 102, data:[., ., ., ., ., ...]\n",
      "  T#102(model_7/tf.nn.convolution_74/convolution) shape:[32, 3, 3, 32], type:INT8 RO 9216 bytes, buffer: 103, data:[., ., ., ., ., ...]\n",
      "  T#103(model_7/tf.nn.convolution_75/convolution) shape:[32, 3, 3, 32], type:INT8 RO 9216 bytes, buffer: 104, data:[., ., ., ., \n",
      ", ...]\n",
      "  T#104(model_7/tf.nn.convolution_76/convolution) shape:[32, 3, 3, 32], type:INT8 RO 9216 bytes, buffer: 105, data:[., ., ., ., ., ...]\n",
      "  T#105(model_7/tf.nn.convolution_77/convolution) shape:[32, 3, 3, 32], type:INT8 RO 9216 bytes, buffer: 106, data:[., ., ., ., ., ...]\n",
      "  T#106(model_7/tf.nn.convolution_78/convolution) shape:[64, 1, 1, 128], type:INT8 RO 8192 bytes, buffer: 107, data:[ , ., ., ., ., ...]\n",
      "  T#107(model_7/tf.nn.convolution_79/convolution) shape:[128, 3, 3, 64], type:INT8 RO 73728 bytes, buffer: 108, data:[., ., $, ., ., ...]\n",
      "  T#108(model_7/tf.nn.convolution_80/convolution) shape:[128, 1, 1, 128], type:INT8 RO 16384 bytes, buffer: 109, data:[., M, H, ., ., ...]\n",
      "  T#109(model_7/tf.nn.convolution_81/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 110, data:[., ., \n",
      ", ., ., ...]\n",
      "  T#110(model_7/tf.nn.convolution_82/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 111, data:[., ., ., \n",
      ", \n",
      ", ...]\n",
      "  T#111(model_7/tf.nn.convolution_83/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 112, data:[., ., .,  , ., ...]\n",
      "  T#112(model_7/tf.nn.convolution_84/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 113, data:[., ., ., \n",
      ", ., ...]\n",
      "  T#113(model_7/tf.nn.convolution_85/convolution) shape:[128, 1, 1, 256], type:INT8 RO 32768 bytes, buffer: 114, data:[%, ., ., ., !, ...]\n",
      "  T#114(model_7/tf.nn.convolution_86/convolution) shape:[256, 3, 3, 128], type:INT8 RO 294912 bytes, buffer: 115, data:[., ., ., ., ., ...]\n",
      "  T#115(model_7/tf.nn.convolution_87/convolution) shape:[256, 1, 1, 256], type:INT8 RO 65536 bytes, buffer: 116, data:[., ., ., ., >, ...]\n",
      "  T#116(model_7/tf.nn.convolution_88/convolution) shape:[128, 3, 3, 128], type:INT8 RO 147456 bytes, buffer: 117, data:[., ., \n",
      ", R, M, ...]\n",
      "  T#117(model_7/tf.nn.convolution_89/convolution) shape:[128, 3, 3, 128], type:INT8 RO 147456 bytes, buffer: 118, data:[., ?, ., ., ., ...]\n",
      "  T#118(model_7/tf.nn.convolution_90/convolution) shape:[256, 1, 1, 384], type:INT8 RO 98304 bytes, buffer: 119, data:[., :, ., -, ., ...]\n",
      "  T#119(model_7/tf.nn.convolution_91/convolution) shape:[128, 1, 1, 256], type:INT8 RO 32768 bytes, buffer: 120, data:[., ., ., ), ., ...]\n",
      "  T#120(model_7/tf.nn.convolution_92/convolution) shape:[256, 1, 1, 512], type:INT8 RO 131072 bytes, buffer: 121, data:[', ., ., ., S, ...]\n",
      "  T#121(model_7/tf.nn.convolution_93/convolution) shape:[128, 1, 1, 384], type:INT8 RO 49152 bytes, buffer: 122, data:[0, ., ., ., ., ...]\n",
      "  T#122(model_7/tf.nn.convolution_94/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 123, data:[., ., ., ., ., ...]\n",
      "  T#123(model_7/tf.nn.convolution_95/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 124, data:[., ., ., ., ., ...]\n",
      "  T#124(model_7/tf.nn.convolution_96/convolution) shape:[128, 1, 1, 192], type:INT8 RO 24576 bytes, buffer: 125, data:[., ., ., ., ., ...]\n",
      "  T#125(model_7/tf.nn.convolution_97/convolution) shape:[64, 1, 1, 192], type:INT8 RO 12288 bytes, buffer: 126, data:[., ., ., ., ., ...]\n",
      "  T#126(model_7/tf.nn.convolution_98/convolution) shape:[32, 3, 3, 32], type:INT8 RO 9216 bytes, buffer: 127, data:[=, ., 1, ., ., ...]\n",
      "  T#127(model_7/tf.nn.convolution_99/convolution) shape:[32, 3, 3, 32], type:INT8 RO 9216 bytes, buffer: 128, data:[., ., ., ., ., ...]\n",
      "  T#128(model_7/tf.nn.convolution_100/convolution) shape:[64, 1, 1, 96], type:INT8 RO 6144 bytes, buffer: 129, data:[., ., ., ., K, ...]\n",
      "  T#129(model_7/tf.nn.convolution_101/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 130, data:[., ., ., ., ., ...]\n",
      "  T#130(model_7/tf.nn.convolution_107/convolution) shape:[128, 1, 1, 192], type:INT8 RO 24576 bytes, buffer: 131, data:[., ., ., ., ., ...]\n",
      "  T#131(model_7/tf.nn.convolution_102/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 132, data:[., ., ., ., ., ...]\n",
      "  T#132(model_7/tf.nn.convolution_104/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 133, data:[., ., ., ., ., ...]\n",
      "  T#133(model_7/tf.nn.convolution_108/convolution) shape:[64, 1, 1, 64], type:INT8 RO 4096 bytes, buffer: 134, data:[., ., ., ., \n",
      ", ...]\n",
      "  T#134(model_7/tf.nn.convolution_103/convolution) shape:[80, 3, 3, 64], type:INT8 RO 46080 bytes, buffer: 135, data:[., ., ., ., ., ...]\n",
      "  T#135(model_7/tf.nn.convolution_106/convolution) shape:[80, 3, 3, 80], type:INT8 RO 57600 bytes, buffer: 136, data:[., &, ., ., ., ...]\n",
      "  T#136(model_7/tf.nn.convolution_110/convolution) shape:[80, 1, 1, 80], type:INT8 RO 6400 bytes, buffer: 137, data:[., ., ., ., ., ...]\n",
      "  T#137(model_7/tf.nn.convolution_111/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 138, data:[%, ., ., ., ., ...]\n",
      "  T#138(model_7/tf.nn.convolution_112/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 139, data:[., ., ., ., ., ...]\n",
      "  T#139(model_7/tf.nn.convolution_113/convolution) shape:[128, 1, 1, 192], type:INT8 RO 24576 bytes, buffer: 140, data:[., ., ., ., ., ...]\n",
      "  T#140(model_7/tf.nn.convolution_114/convolution) shape:[128, 3, 3, 128], type:INT8 RO 147456 bytes, buffer: 141, data:[., ., ., K, ,, ...]\n",
      "  T#141(model_7/tf.nn.convolution_119/convolution) shape:[256, 1, 1, 384], type:INT8 RO 98304 bytes, buffer: 142, data:[., ., *, ., ., ...]\n",
      "  T#142(model_7/tf.nn.convolution_115/convolution) shape:[64, 3, 3, 128], type:INT8 RO 73728 bytes, buffer: 143, data:[., ., ., ., ., ...]\n",
      "  T#143(model_7/tf.nn.convolution_117/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 144, data:[., ., ., ., ., ...]\n",
      "  T#144(model_7/tf.nn.convolution_120/convolution) shape:[64, 1, 1, 64], type:INT8 RO 4096 bytes, buffer: 145, data:[., ., .,  , ., ...]\n",
      "  T#145(model_7/tf.nn.convolution_116/convolution) shape:[80, 3, 3, 128], type:INT8 RO 92160 bytes, buffer: 146, data:[., ., ., ., ., ...]\n",
      "  T#146(model_7/tf.nn.convolution_118/convolution) shape:[80, 3, 3, 80], type:INT8 RO 57600 bytes, buffer: 147, data:[., ., ., ., ., ...]\n",
      "  T#147(model_7/tf.nn.convolution_121/convolution) shape:[80, 1, 1, 80], type:INT8 RO 6400 bytes, buffer: 148, data:[., ., ., ., ., ...]\n",
      "  T#148(model_7/tf.nn.convolution_122/convolution) shape:[128, 3, 3, 128], type:INT8 RO 147456 bytes, buffer: 149, data:[., ., ., ., ., ...]\n",
      "  T#149(model_7/tf.nn.convolution_123/convolution) shape:[128, 3, 3, 128], type:INT8 RO 147456 bytes, buffer: 150, data:[., ., ., ., ., ...]\n",
      "  T#150(model_7/tf.nn.convolution_124/convolution) shape:[256, 1, 1, 384], type:INT8 RO 98304 bytes, buffer: 151, data:[., ., ., ., ., ...]\n",
      "  T#151(model_7/tf.nn.convolution_125/convolution) shape:[64, 3, 3, 256], type:INT8 RO 147456 bytes, buffer: 152, data:[., ., ., ., ., ...]\n",
      "  T#152(model_7/tf.nn.convolution_127/convolution) shape:[64, 3, 3, 64], type:INT8 RO 36864 bytes, buffer: 153, data:[., ., ., ., ., ...]\n",
      "  T#153(model_7/tf.nn.convolution_129/convolution) shape:[64, 1, 1, 64], type:INT8 RO 4096 bytes, buffer: 154, data:[., ., ., ., ., ...]\n",
      "  T#154(model_7/tf.nn.convolution_126/convolution) shape:[80, 3, 3, 256], type:INT8 RO 184320 bytes, buffer: 155, data:[., ., ., ., ., ...]\n",
      "  T#155(model_7/tf.nn.convolution_128/convolution) shape:[80, 3, 3, 80], type:INT8 RO 57600 bytes, buffer: 156, data:[., ., ., ., ., ...]\n",
      "  T#156(model_7/tf.nn.convolution_130/convolution) shape:[80, 1, 1, 80], type:INT8 RO 6400 bytes, buffer: 157, data:[., ., ., ., ., ...]\n",
      "  T#157(model_7/tf.compat.v1.pad_7/Pad) shape:[1, 642, 642, 3], type:FLOAT32\n",
      "  T#158(model_7/tf.math.add_73/Add;model_7/tf.nn.convolution_70/convolution;model_7/tf.nn.convolution_66/convolution;Const_174) shape:[1, 320, 320, 16], type:FLOAT32\n",
      "  T#159(model_7/tf.math.sigmoid_58/Sigmoid) shape:[1, 320, 320, 16], type:FLOAT32\n",
      "  T#160(model_7/tf.math.multiply_199/Mul) shape:[1, 320, 320, 16], type:FLOAT32\n",
      "  T#161(model_7/tf.compat.v1.pad_8/Pad) shape:[1, 322, 322, 16], type:FLOAT32\n",
      "  T#162(model_7/tf.math.add_74/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_67/convolution;Const_171) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#163(model_7/tf.math.sigmoid_59/Sigmoid) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#164(model_7/tf.math.multiply_202/Mul) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#165(model_7/tf.math.add_75/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_68/convolution;Const_169) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#166(model_7/tf.math.sigmoid_60/Sigmoid) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#167(model_7/tf.math.multiply_205/Mul) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#168(model_7/tf.strided_slice_20/StridedSlice3) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#169(model_7/tf.strided_slice_21/StridedSlice1) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#170(model_7/tf.math.add_76/Add;model_7/tf.nn.convolution_70/convolution;model_7/tf.nn.convolution_69/convolution;Const_165) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#171(model_7/tf.math.sigmoid_61/Sigmoid) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#172(model_7/tf.math.multiply_208/Mul) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#173(model_7/tf.math.add_77/Add;model_7/tf.nn.convolution_70/convolution;Const_163) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#174(model_7/tf.math.sigmoid_62/Sigmoid) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#175(model_7/tf.math.multiply_211/Mul) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#176(model_7/tf.math.add_78/Add) shape:[1, 160, 160, 16], type:FLOAT32\n",
      "  T#177(model_7/tf.concat_595/concat) shape:[1, 160, 160, 48], type:FLOAT32\n",
      "  T#178(model_7/tf.math.add_79/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_71/convolution;Const_159) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#179(model_7/tf.math.sigmoid_63/Sigmoid) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#180(model_7/tf.math.multiply_216/Mul) shape:[1, 160, 160, 32], type:FLOAT32\n",
      "  T#181(model_7/tf.compat.v1.pad_9/Pad) shape:[1, 162, 162, 32], type:FLOAT32\n",
      "  T#182(model_7/tf.math.add_80/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_72/convolution;Const_156) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#183(model_7/tf.math.sigmoid_64/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#184(model_7/tf.math.multiply_219/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#185(model_7/tf.math.add_81/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_73/convolution;Const_154) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#186(model_7/tf.math.sigmoid_65/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#187(model_7/tf.math.multiply_222/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#188(model_7/tf.strided_slice_22/StridedSlice) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#189(model_7/tf.strided_slice_23/StridedSlice1) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#190(model_7/tf.math.add_82/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_74/convolution;Const_150) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#191(model_7/tf.math.sigmoid_66/Sigmoid) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#192(model_7/tf.math.multiply_225/Mul) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#193(model_7/tf.math.add_83/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_75/convolution;Const_148) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#194(model_7/tf.math.sigmoid_67/Sigmoid) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#195(model_7/tf.math.multiply_228/Mul) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#196(model_7/tf.math.add_84/Add) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#197(model_7/tf.math.add_85/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_76/convolution;Const_146) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#198(model_7/tf.math.sigmoid_68/Sigmoid) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#199(model_7/tf.math.multiply_233/Mul) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#200(model_7/tf.math.add_86/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_77/convolution;Const_144) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#201(model_7/tf.math.sigmoid_69/Sigmoid) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#202(model_7/tf.math.multiply_236/Mul) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#203(model_7/tf.math.add_87/Add) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#204(model_7/tf.concat_596/concat) shape:[1, 80, 80, 128], type:FLOAT32\n",
      "  T#205(model_7/tf.math.add_88/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_78/convolution;Const_140) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#206(model_7/tf.math.sigmoid_70/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#207(model_7/tf.math.multiply_241/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#208(model_7/tf.compat.v1.pad_10/Pad) shape:[1, 82, 82, 64], type:FLOAT32\n",
      "  T#209(model_7/tf.math.add_89/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_79/convolution;Const_137) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#210(model_7/tf.math.sigmoid_71/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#211(model_7/tf.math.multiply_244/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#212(model_7/tf.math.add_90/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_80/convolution;Const_135) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#213(model_7/tf.math.sigmoid_72/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#214(model_7/tf.math.multiply_247/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#215(model_7/tf.strided_slice_24/StridedSlice) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#216(model_7/tf.strided_slice_25/StridedSlice1) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#217(model_7/tf.math.add_91/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_81/convolution;Const_131) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#218(model_7/tf.math.sigmoid_73/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#219(model_7/tf.math.multiply_250/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#220(model_7/tf.math.add_92/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_82/convolution;Const_129) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#221(model_7/tf.math.sigmoid_74/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#222(model_7/tf.math.multiply_253/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#223(model_7/tf.math.add_93/Add) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#224(model_7/tf.math.add_94/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_83/convolution;Const_127) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#225(model_7/tf.math.sigmoid_75/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#226(model_7/tf.math.multiply_258/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#227(model_7/tf.math.add_95/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_84/convolution;Const_125) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#228(model_7/tf.math.sigmoid_76/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#229(model_7/tf.math.multiply_261/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#230(model_7/tf.math.add_96/Add) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#231(model_7/tf.concat_597/concat) shape:[1, 40, 40, 256], type:FLOAT32\n",
      "  T#232(model_7/tf.math.add_97/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_85/convolution;Const_121) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#233(model_7/tf.math.sigmoid_77/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#234(model_7/tf.math.multiply_266/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#235(model_7/tf.compat.v1.pad_11/Pad) shape:[1, 42, 42, 128], type:FLOAT32\n",
      "  T#236(model_7/tf.math.add_98/Add;model_7/tf.nn.convolution_124/convolution;model_7/tf.nn.convolution_86/convolution;Const_118) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#237(model_7/tf.math.sigmoid_78/Sigmoid) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#238(model_7/tf.math.multiply_269/Mul) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#239(model_7/tf.math.add_99/Add;model_7/tf.nn.convolution_124/convolution;model_7/tf.nn.convolution_87/convolution;Const_116) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#240(model_7/tf.math.sigmoid_79/Sigmoid) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#241(model_7/tf.math.multiply_272/Mul) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#242(model_7/tf.strided_slice_26/StridedSlice) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#243(model_7/tf.strided_slice_27/StridedSlice1) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#244(model_7/tf.math.add_100/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_88/convolution;Const_112) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#245(model_7/tf.math.sigmoid_80/Sigmoid) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#246(model_7/tf.math.multiply_275/Mul) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#247(model_7/tf.math.add_101/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_89/convolution;Const_110) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#248(model_7/tf.math.sigmoid_81/Sigmoid) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#249(model_7/tf.math.multiply_278/Mul) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#250(model_7/tf.math.add_102/Add) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#251(model_7/tf.concat_598/concat) shape:[1, 20, 20, 384], type:FLOAT32\n",
      "  T#252(model_7/tf.math.add_103/Add;model_7/tf.nn.convolution_124/convolution;model_7/tf.nn.convolution_90/convolution;Const_106) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#253(model_7/tf.math.sigmoid_82/Sigmoid) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#254(model_7/tf.math.multiply_283/Mul) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#255(model_7/tf.math.add_104/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_91/convolution;Const_104) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#256(model_7/tf.math.sigmoid_83/Sigmoid) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#257(model_7/tf.math.multiply_286/Mul) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#258(model_7/tf.compat.v1.nn.pool_3/max_pool) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#259(model_7/tf.compat.v1.nn.pool_4/max_pool) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#260(model_7/tf.compat.v1.nn.pool_5/max_pool) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#261(model_7/tf.concat_599/concat) shape:[1, 20, 20, 512], type:FLOAT32\n",
      "  T#262(model_7/tf.math.add_105/Add;model_7/tf.nn.convolution_124/convolution;model_7/tf.nn.convolution_92/convolution;Const_102) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#263(model_7/tf.math.sigmoid_84/Sigmoid) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#264(model_7/tf.math.multiply_289/Mul) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#265(model_7/lambda_2/wa/model.10/Resize) shape:[1, 40, 40, 256], type:FLOAT32\n",
      "  T#266(model_7/tf.concat_600/concat) shape:[1, 40, 40, 384], type:FLOAT32\n",
      "  T#267(model_7/tf.math.add_106/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_93/convolution;Const_100) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#268(model_7/tf.math.sigmoid_85/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#269(model_7/tf.math.multiply_292/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#270(model_7/tf.strided_slice_28/StridedSlice) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#271(model_7/tf.strided_slice_29/StridedSlice) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#272(model_7/tf.math.add_107/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_94/convolution;Const_96) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#273(model_7/tf.math.sigmoid_86/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#274(model_7/tf.math.multiply_295/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#275(model_7/tf.math.add_108/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_95/convolution;Const_94) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#276(model_7/tf.math.sigmoid_87/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#277(model_7/tf.math.multiply_298/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#278(model_7/tf.concat_601/concat) shape:[1, 40, 40, 192], type:FLOAT32\n",
      "  T#279(model_7/tf.math.add_109/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_96/convolution;Const_90) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#280(model_7/tf.math.sigmoid_88/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#281(model_7/tf.math.multiply_301/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#282(model_7/lambda_3/wa/model.13/Resize) shape:[1, 80, 80, 128], type:FLOAT32\n",
      "  T#283(model_7/tf.concat_602/concat) shape:[1, 80, 80, 192], type:FLOAT32\n",
      "  T#284(model_7/tf.math.add_110/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_97/convolution;Const_88) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#285(model_7/tf.math.sigmoid_89/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#286(model_7/tf.math.multiply_304/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#287(model_7/tf.strided_slice_30/StridedSlice) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#288(model_7/tf.strided_slice_31/StridedSlice) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#289(model_7/tf.math.add_111/Add;model_7/tf.nn.convolution_99/convolution;model_7/tf.nn.convolution_98/convolution;Const_84) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#290(model_7/tf.math.sigmoid_90/Sigmoid) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#291(model_7/tf.math.multiply_307/Mul) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#292(model_7/tf.math.add_112/Add;model_7/tf.nn.convolution_99/convolution;Const_82) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#293(model_7/tf.math.sigmoid_91/Sigmoid) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#294(model_7/tf.math.multiply_310/Mul) shape:[1, 80, 80, 32], type:FLOAT32\n",
      "  T#295(model_7/tf.concat_603/concat) shape:[1, 80, 80, 96], type:FLOAT32\n",
      "  T#296(model_7/tf.math.add_113/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_100/convolution;Const_78) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#297(model_7/tf.math.sigmoid_92/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#298(model_7/tf.math.multiply_313/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#299(model_7/tf.compat.v1.pad_12/Pad) shape:[1, 82, 82, 64], type:FLOAT32\n",
      "  T#300(model_7/tf.math.add_114/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_101/convolution;Const_75) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#301(model_7/tf.math.sigmoid_93/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#302(model_7/tf.math.multiply_316/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#303(model_7/tf.concat_604/concat) shape:[1, 40, 40, 192], type:FLOAT32\n",
      "  T#304(model_7/tf.math.add_120/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_107/convolution;Const_73) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#305(model_7/tf.math.sigmoid_98/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#306(model_7/tf.math.multiply_331/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#307(model_7/tf.math.add_115/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_102/convolution;Const_40) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#308(model_7/tf.math.sigmoid_94/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#309(model_7/tf.math.multiply_319/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#310(model_7/tf.math.add_117/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_104/convolution;Const_28) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#311(model_7/tf.math.sigmoid_96/Sigmoid) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#312(model_7/tf.math.multiply_325/Mul) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#313(model_7/tf.math.add_121/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_108/convolution;Const_16) shape:[1, 80, 80, 64], type:FLOAT32\n",
      "  T#314(model_7/tf.math.add_116/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_103/convolution;Const_46) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#315(model_7/tf.math.sigmoid_95/Sigmoid) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#316(model_7/tf.math.multiply_322/Mul) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#317(model_7/tf.math.add_119/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_106/convolution;Const_34) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#318(model_7/tf.math.sigmoid_97/Sigmoid) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#319(model_7/tf.math.multiply_328/Mul) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#320(model_7/tf.math.add_123/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_110/convolution;Const_17) shape:[1, 80, 80, 80], type:FLOAT32\n",
      "  T#321(model_7/tf.concat_1182/concat) shape:[1, 80, 80, 144], type:FLOAT32\n",
      "  T#322(model_7/tf.compat.v1.transpose_2321/transpose) shape:[1, 144, 80, 80], type:FLOAT32\n",
      "  T#323(model_7/tf.reshape_5/Reshape) shape:[1, 144, 6400], type:FLOAT32\n",
      "  T#324(model_7/tf.strided_slice_32/StridedSlice) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#325(model_7/tf.strided_slice_33/StridedSlice) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#326(model_7/tf.math.add_124/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_111/convolution;Const_69) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#327(model_7/tf.math.sigmoid_99/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#328(model_7/tf.math.multiply_334/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#329(model_7/tf.math.add_125/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_112/convolution;Const_67) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#330(model_7/tf.math.sigmoid_100/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#331(model_7/tf.math.multiply_337/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#332(model_7/tf.concat_1183/concat) shape:[1, 40, 40, 192], type:FLOAT32\n",
      "  T#333(model_7/tf.math.add_126/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_113/convolution;Const_63) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#334(model_7/tf.math.sigmoid_101/Sigmoid) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#335(model_7/tf.math.multiply_340/Mul) shape:[1, 40, 40, 128], type:FLOAT32\n",
      "  T#336(model_7/tf.compat.v1.pad_13/Pad) shape:[1, 42, 42, 128], type:FLOAT32\n",
      "  T#337(model_7/tf.math.add_127/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_114/convolution;Const_60) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#338(model_7/tf.math.sigmoid_102/Sigmoid) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#339(model_7/tf.math.multiply_343/Mul) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#340(model_7/tf.concat_1184/concat) shape:[1, 20, 20, 384], type:FLOAT32\n",
      "  T#341(model_7/tf.math.add_132/Add;model_7/tf.nn.convolution_124/convolution;model_7/tf.nn.convolution_119/convolution;Const_58) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#342(model_7/tf.math.sigmoid_107/Sigmoid) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#343(model_7/tf.math.multiply_358/Mul) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#344(model_7/tf.math.add_128/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_115/convolution;Const_36) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#345(model_7/tf.math.sigmoid_103/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#346(model_7/tf.math.multiply_346/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#347(model_7/tf.math.add_130/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_117/convolution;Const_24) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#348(model_7/tf.math.sigmoid_105/Sigmoid) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#349(model_7/tf.math.multiply_352/Mul) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#350(model_7/tf.math.add_133/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_120/convolution;Const_13) shape:[1, 40, 40, 64], type:FLOAT32\n",
      "  T#351(model_7/tf.math.add_129/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_116/convolution;Const_37) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#352(model_7/tf.math.sigmoid_104/Sigmoid) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#353(model_7/tf.math.multiply_349/Mul) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#354(model_7/tf.math.add_131/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_118/convolution;Const_25) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#355(model_7/tf.math.sigmoid_106/Sigmoid) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#356(model_7/tf.math.multiply_355/Mul) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#357(model_7/tf.math.add_134/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_121/convolution;Const_12) shape:[1, 40, 40, 80], type:FLOAT32\n",
      "  T#358(model_7/tf.concat_1185/concat) shape:[1, 40, 40, 144], type:FLOAT32\n",
      "  T#359(model_7/tf.compat.v1.transpose_2322/transpose) shape:[1, 144, 40, 40], type:FLOAT32\n",
      "  T#360(model_7/tf.reshape_6/Reshape) shape:[1, 144, 1600], type:FLOAT32\n",
      "  T#361(model_7/tf.strided_slice_34/StridedSlice) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#362(model_7/tf.strided_slice_35/StridedSlice) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#363(model_7/tf.math.add_135/Add;model_7/tf.nn.convolution_123/convolution;model_7/tf.nn.convolution_122/convolution;Const_54) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#364(model_7/tf.math.sigmoid_108/Sigmoid) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#365(model_7/tf.math.multiply_361/Mul) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#366(model_7/tf.math.add_136/Add;model_7/tf.nn.convolution_123/convolution;Const_52) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#367(model_7/tf.math.sigmoid_109/Sigmoid) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#368(model_7/tf.math.multiply_364/Mul) shape:[1, 20, 20, 128], type:FLOAT32\n",
      "  T#369(model_7/tf.concat_1186/concat) shape:[1, 20, 20, 384], type:FLOAT32\n",
      "  T#370(model_7/tf.math.add_137/Add;model_7/tf.nn.convolution_124/convolution;Const_48) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#371(model_7/tf.math.sigmoid_110/Sigmoid) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#372(model_7/tf.math.multiply_367/Mul) shape:[1, 20, 20, 256], type:FLOAT32\n",
      "  T#373(model_7/tf.math.add_138/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_125/convolution;Const_38) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#374(model_7/tf.math.sigmoid_111/Sigmoid) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#375(model_7/tf.math.multiply_370/Mul) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#376(model_7/tf.math.add_140/Add;model_7/tf.nn.convolution_129/convolution;model_7/tf.nn.convolution_127/convolution;Const_26) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#377(model_7/tf.math.sigmoid_113/Sigmoid) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#378(model_7/tf.math.multiply_376/Mul) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#379(model_7/tf.math.add_142/Add;model_7/tf.nn.convolution_129/convolution;Const_15) shape:[1, 20, 20, 64], type:FLOAT32\n",
      "  T#380(model_7/tf.math.add_139/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_126/convolution;Const_39) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#381(model_7/tf.math.sigmoid_112/Sigmoid) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#382(model_7/tf.math.multiply_373/Mul) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#383(model_7/tf.math.add_141/Add;model_7/tf.nn.convolution_130/convolution;model_7/tf.nn.convolution_128/convolution;Const_27) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#384(model_7/tf.math.sigmoid_114/Sigmoid) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#385(model_7/tf.math.multiply_379/Mul) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#386(model_7/tf.math.add_143/Add;model_7/tf.nn.convolution_130/convolution;Const_14) shape:[1, 20, 20, 80], type:FLOAT32\n",
      "  T#387(model_7/tf.concat_1187/concat) shape:[1, 20, 20, 144], type:FLOAT32\n",
      "  T#388(model_7/tf.compat.v1.transpose_2323/transpose) shape:[1, 144, 20, 20], type:FLOAT32\n",
      "  T#389(model_7/tf.reshape_7/Reshape) shape:[1, 144, 400], type:FLOAT32\n",
      "  T#390(model_7/tf.concat_1188/concat) shape:[1, 144, 8400], type:FLOAT32\n",
      "  T#391(model_7/tf.strided_slice_36/StridedSlice3) shape:[1, 64, 8400], type:FLOAT32\n",
      "  T#392(model_7/tf.reshape_8/Reshape) shape:[1, 4, 16, 8400], type:FLOAT32\n",
      "  T#393(model_7/tf.compat.v1.transpose_2325/transpose) shape:[1, 16, 4, 8400], type:FLOAT32\n",
      "  T#394(model_7/tf.compat.v1.transpose_2326/transpose) shape:[1, 4, 8400, 16], type:FLOAT32\n",
      "  T#395(model_7/tf.nn.softmax_1/wa/model.22/dfl/Softmax) shape:[1, 4, 8400, 16], type:FLOAT32\n",
      "  T#396(model_7/tf.nn.convolution_131/convolution2) shape:[1, 4, 8400, 1], type:FLOAT32\n",
      "  T#397(model_7/tf.compat.v1.transpose_2329/transpose1) shape:[1, 1, 4, 8400], type:FLOAT32\n",
      "  T#398(model_7/tf.math.multiply_382/Mul;model_7/tf.reshape_9/Reshape/shape;model_7/tf.reshape_9/Reshape;model_7/tf.math.multiply_382/Mul/y) shape:[1, 1, 4, 8400], type:FLOAT32\n",
      "  T#399(model_7/tf.math.multiply_382/Mul;model_7/tf.reshape_9/Reshape/shape;model_7/tf.reshape_9/Reshape;model_7/tf.math.multiply_382/Mul/y1) shape:[1, 4, 8400], type:FLOAT32\n",
      "  T#400(model_7/tf.strided_slice_37/StridedSlice1) shape:[1, 80, 8400], type:FLOAT32\n",
      "  T#401(model_7/tf.math.sigmoid_115/Sigmoid) shape:[1, 80, 8400], type:FLOAT32\n",
      "  T#402(model_7/tf.strided_slice_38/StridedSlice1) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#403(model_7/tf.math.subtract_2/Sub) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#404(model_7/tf.strided_slice_39/StridedSlice1) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#405(model_7/tf.math.add_144/Add) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#406(model_7/tf.math.add_145/Add) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#407(model_7/tf.math.divide_1/truediv;Const1) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#408(model_7/tf.math.subtract_3/Sub) shape:[1, 2, 8400], type:FLOAT32\n",
      "  T#409(PartitionedCall:0) shape:[1, 84, 8400], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'images' : T#0\n",
      "- Outputs: \n",
      "    'output0' : T#409\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:    3502448 bytes\n",
      "    Non-data buffer size:     129944 bytes (03.71 %)\n",
      "  Total data buffer size:    3372504 bytes (96.29 %)\n",
      "    (Zero value buffers):         32 bytes (00.00 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(baseline_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics YOLOv8.2.12 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "Loading /tmp/tmp5l314eq0/yolov8n_float32.tflite for TensorFlow Lite inference...\n",
      "WARNING ⚠️ Metadata not found for 'model=/tmp/tmp5l314eq0/yolov8n_float32.tflite'\n",
      "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:16<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 123.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/val57\u001b[0m\n",
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics YOLOv8.2.12 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "Loading /tmp/tmp315mnjlf.tflite for TensorFlow Lite inference...\n",
      "WARNING ⚠️ Metadata not found for 'model=/tmp/tmp315mnjlf.tflite'\n",
      "Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:13<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.669      0.536      0.609      0.454\n",
      "                person        128        254       0.81      0.661      0.757      0.541\n",
      "               bicycle        128          6      0.655      0.322      0.334      0.239\n",
      "                   car        128         46       0.77      0.196      0.271      0.184\n",
      "            motorcycle        128          5       0.63        0.8      0.866      0.709\n",
      "              airplane        128          6      0.747      0.667      0.823      0.623\n",
      "                   bus        128          7      0.552      0.714      0.722      0.637\n",
      "                 train        128          3      0.547      0.667      0.863      0.784\n",
      "                 truck        128         12      0.783      0.306      0.435      0.258\n",
      "                  boat        128          6      0.198      0.167      0.342      0.145\n",
      "         traffic light        128         14          1      0.182       0.22      0.141\n",
      "             stop sign        128          2      0.633        0.5      0.828      0.547\n",
      "                 bench        128          9       0.84      0.586      0.621      0.358\n",
      "                  bird        128         16      0.847      0.688      0.858      0.502\n",
      "                   cat        128          4      0.937          1      0.995       0.92\n",
      "                   dog        128          9      0.593      0.778       0.82      0.615\n",
      "                 horse        128          2      0.718          1      0.995      0.746\n",
      "              elephant        128         17      0.858      0.824      0.888      0.639\n",
      "                  bear        128          1      0.605          1      0.995      0.995\n",
      "                 zebra        128          4      0.852          1      0.995      0.971\n",
      "               giraffe        128          9      0.816      0.989      0.941      0.695\n",
      "              backpack        128          6      0.686      0.373      0.433      0.233\n",
      "              umbrella        128         18      0.736        0.5      0.665      0.422\n",
      "               handbag        128         19       0.32     0.0526      0.142     0.0835\n",
      "                   tie        128          7      0.852      0.714      0.719      0.478\n",
      "              suitcase        128          4      0.615          1      0.945      0.625\n",
      "               frisbee        128          5      0.702        0.8      0.759      0.688\n",
      "                  skis        128          1      0.693          1      0.995        0.5\n",
      "             snowboard        128          7      0.794      0.714      0.744      0.528\n",
      "           sports ball        128          6      0.545      0.212      0.469      0.276\n",
      "                  kite        128         10      0.821      0.463      0.567      0.195\n",
      "          baseball bat        128          4      0.659        0.5      0.414      0.232\n",
      "        baseball glove        128          7      0.715      0.429       0.43      0.274\n",
      "            skateboard        128          5      0.781        0.6      0.615      0.428\n",
      "         tennis racket        128          7      0.656       0.55      0.537      0.324\n",
      "                bottle        128         18      0.441      0.333      0.359      0.239\n",
      "            wine glass        128         16      0.609      0.375      0.502      0.335\n",
      "                   cup        128         36      0.697       0.25      0.401      0.286\n",
      "                  fork        128          6      0.572      0.167      0.255      0.203\n",
      "                 knife        128         16      0.708      0.456      0.631      0.396\n",
      "                 spoon        128         22      0.623      0.226      0.304      0.171\n",
      "                  bowl        128         28      0.739      0.607        0.6       0.47\n",
      "                banana        128          1          0          0      0.124     0.0541\n",
      "              sandwich        128          2      0.573          1      0.663      0.663\n",
      "                orange        128          4          1          0      0.995       0.66\n",
      "              broccoli        128         11       0.35      0.198      0.248      0.211\n",
      "                carrot        128         24      0.712      0.413      0.603      0.386\n",
      "               hot dog        128          2      0.467        0.9      0.745      0.721\n",
      "                 pizza        128          5      0.835          1      0.995      0.833\n",
      "                 donut        128         14      0.647          1       0.96      0.858\n",
      "                  cake        128          4        0.6          1      0.912      0.821\n",
      "                 chair        128         35      0.511      0.486      0.415      0.231\n",
      "                 couch        128          6      0.647      0.617      0.693      0.538\n",
      "          potted plant        128         14      0.688      0.643      0.704      0.457\n",
      "                   bed        128          3      0.885      0.667       0.83       0.61\n",
      "          dining table        128         13      0.467      0.538      0.493      0.428\n",
      "                toilet        128          2        0.6        0.5      0.662      0.646\n",
      "                    tv        128          2      0.401      0.702      0.745      0.696\n",
      "                laptop        128          3          1          0      0.263      0.218\n",
      "                 mouse        128          2          1          0     0.0625     0.0125\n",
      "                remote        128          8      0.833        0.5      0.582      0.471\n",
      "            cell phone        128          8          1          0      0.117     0.0657\n",
      "             microwave        128          3      0.307      0.667      0.789      0.691\n",
      "                  oven        128          5      0.314        0.4      0.374      0.291\n",
      "                  sink        128          6       0.32      0.167      0.164      0.109\n",
      "          refrigerator        128          5      0.677        0.4      0.578      0.419\n",
      "                  book        128         29      0.662      0.103      0.317      0.162\n",
      "                 clock        128          9      0.728      0.778      0.835      0.687\n",
      "                  vase        128          2       0.34          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0498\n",
      "            teddy bear        128         21      0.673      0.392       0.58      0.375\n",
      "            toothbrush        128          5      0.933        0.6      0.706      0.442\n",
      "Speed: 0.7ms preprocess, 96.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/val58\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# validate on COCO dataset FP32\n",
    "results_converted = YOLO(f\"{saved_model}/yolov8n_float32.tflite\").val(\n",
    "    data=\"coco128.yaml\"\n",
    ")\n",
    "\n",
    "# validate on COCO dataset INT8\n",
    "results_quant = YOLO(baseline_quantized).val(data=\"coco128.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/precision(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6401136562982888</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/recall(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5371329744029286</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6049606058248067</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50-95(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4455822678794395</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fitness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4615201016739762</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/precision\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.6401136562982888\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/recall\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.5371329744029286\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.6049606058248067\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50-95\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.4455822678794395\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'fitness'\u001b[0m: \u001b[1;36m0.4615201016739762\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'FP32'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'FP32'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/precision(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/recall(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50-95(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fitness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/precision\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/recall\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50-95\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'fitness'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'INT8'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'INT8'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/precision(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6693744628674021</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/recall(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5357106358126033</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6089456673483312</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50-95(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4540750785376153</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fitness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4695621374186869</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/precision\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.6693744628674021\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/recall\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.5357106358126033\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.6089456673483312\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50-95\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.4540750785376153\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'fitness'\u001b[0m: \u001b[1;36m0.4695621374186869\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Original\")\n",
    "pprint(results.results_dict)\n",
    "\n",
    "pprint(\"FP32\")\n",
    "pprint(results_converted.results_dict)\n",
    "\n",
    "pprint(\"INT8\")\n",
    "pprint(results_quant.results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity and cluster preserving quantization aware training (PCQAT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune and fine-tune the model to 50% sparsity\n",
    "\n",
    "I am using this approach and code https://github.com/VainF/Torch-Pruning after having tried, with little success (fast reduction in mAP when increasing the pruning amount) the ultralytics method https://docs.ultralytics.com/yolov5/tutorials/model_pruning_and_sparsity/#test-normally https://github.com/ultralytics/ultralytics/issues/3507\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'yolov8n.pt'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'cfg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'default.yaml'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'iterative_steps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_prune_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_map_drop'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'coco128.yaml'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'yolov8n.pt'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'epoch'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'cfg'\u001b[0m: \u001b[32m'default.yaml'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'iterative_steps'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'target_prune_rate'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'max_map_drop'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'data'\u001b[0m: \u001b[32m'coco128.yaml'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"model\": \"yolov8n.pt\",\n",
    "    \"epoch\": 10,\n",
    "    \"cfg\": \"default.yaml\",\n",
    "    \"iterative_steps\": 16,\n",
    "    \"target_prune_rate\": 0.1,\n",
    "    \"max_map_drop\": 0.2,\n",
    "    \"data\": \"coco128.yaml\",\n",
    "}\n",
    "\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "\n",
    "args = AttrDict(config)\n",
    "pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.12 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "YOLOv8n summary (fused): 185 layers, 3151904 parameters, 31936 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:03<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.651      0.533      0.606      0.452\n",
      "                person        128        254      0.805      0.667      0.764      0.543\n",
      "               bicycle        128          6      0.661      0.328      0.329      0.232\n",
      "                   car        128         46      0.819      0.196      0.269      0.181\n",
      "            motorcycle        128          5      0.603        0.8       0.88      0.672\n",
      "              airplane        128          6      0.755      0.667      0.845      0.619\n",
      "                   bus        128          7      0.539      0.714      0.698      0.625\n",
      "                 train        128          3      0.525      0.667       0.83      0.764\n",
      "                 truck        128         12       0.69       0.25       0.42      0.239\n",
      "                  boat        128          6      0.197      0.167      0.327      0.144\n",
      "         traffic light        128         14      0.684      0.158      0.202      0.139\n",
      "             stop sign        128          2      0.612        0.5      0.828      0.547\n",
      "                 bench        128          9      0.835      0.564      0.621      0.319\n",
      "                  bird        128         16      0.856      0.743      0.868      0.521\n",
      "                   cat        128          4      0.838          1      0.995      0.902\n",
      "                   dog        128          9      0.726      0.889      0.829        0.6\n",
      "                 horse        128          2        0.7          1      0.995      0.746\n",
      "              elephant        128         17      0.907      0.824      0.893      0.661\n",
      "                  bear        128          1       0.62          1      0.995      0.995\n",
      "                 zebra        128          4       0.85          1      0.995      0.971\n",
      "               giraffe        128          9      0.765          1      0.928      0.705\n",
      "              backpack        128          6       0.69       0.38      0.433      0.253\n",
      "              umbrella        128         18      0.649      0.444      0.641      0.405\n",
      "               handbag        128         19      0.408     0.0526      0.157     0.0878\n",
      "                   tie        128          7      0.849      0.714      0.719      0.478\n",
      "              suitcase        128          4      0.615          1      0.912      0.624\n",
      "               frisbee        128          5      0.691        0.8      0.759      0.688\n",
      "                  skis        128          1      0.664          1      0.995      0.497\n",
      "             snowboard        128          7      0.675      0.714      0.716      0.567\n",
      "           sports ball        128          6      0.536      0.167      0.469      0.282\n",
      "                  kite        128         10      0.631      0.347      0.444      0.178\n",
      "          baseball bat        128          4      0.651        0.5      0.502      0.274\n",
      "        baseball glove        128          7      0.638      0.429      0.429      0.309\n",
      "            skateboard        128          5      0.667        0.6      0.599      0.413\n",
      "         tennis racket        128          7      0.666      0.571      0.522      0.321\n",
      "                bottle        128         18      0.636      0.388      0.419       0.25\n",
      "            wine glass        128         16      0.534      0.375      0.493      0.329\n",
      "                   cup        128         36      0.698       0.25      0.416      0.283\n",
      "                  fork        128          6       0.57      0.167      0.254      0.188\n",
      "                 knife        128         16      0.642      0.438      0.604      0.382\n",
      "                 spoon        128         22      0.574      0.184      0.324      0.174\n",
      "                  bowl        128         28      0.722      0.607      0.627      0.475\n",
      "                banana        128          1          0          0      0.124     0.0465\n",
      "              sandwich        128          2      0.529          1      0.663      0.663\n",
      "                orange        128          4          1          0      0.995      0.666\n",
      "              broccoli        128         11      0.346      0.182      0.251      0.212\n",
      "                carrot        128         24      0.671      0.426      0.621      0.396\n",
      "               hot dog        128          2      0.473      0.919      0.745      0.721\n",
      "                 pizza        128          5      0.787          1      0.995      0.838\n",
      "                 donut        128         14      0.649          1      0.946      0.851\n",
      "                  cake        128          4      0.602          1      0.912      0.797\n",
      "                 chair        128         35      0.469      0.486      0.417      0.234\n",
      "                 couch        128          6      0.509        0.5      0.649      0.461\n",
      "          potted plant        128         14      0.589      0.643      0.686      0.455\n",
      "                   bed        128          3      0.933      0.667      0.736      0.576\n",
      "          dining table        128         13      0.423      0.538      0.507      0.425\n",
      "                toilet        128          2      0.605        0.5       0.62      0.596\n",
      "                    tv        128          2      0.398      0.695      0.745      0.696\n",
      "                laptop        128          3          1          0      0.244      0.194\n",
      "                 mouse        128          2          1          0     0.0694     0.0139\n",
      "                remote        128          8      0.816        0.5      0.608        0.5\n",
      "            cell phone        128          8          1          0      0.128     0.0745\n",
      "             microwave        128          3       0.34       0.69      0.806      0.702\n",
      "                  oven        128          5      0.378        0.4      0.363      0.284\n",
      "                  sink        128          6      0.328      0.167      0.156      0.103\n",
      "          refrigerator        128          5      0.711        0.4      0.603       0.42\n",
      "                  book        128         29       0.66      0.103      0.298      0.153\n",
      "                 clock        128          9      0.726      0.778      0.861      0.727\n",
      "                  vase        128          2      0.345          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0564\n",
      "            teddy bear        128         21       0.65      0.355      0.585      0.389\n",
      "            toothbrush        128          5      0.894        0.6      0.705      0.432\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/baseline_val26\u001b[0m\n",
      "Before Pruning: MACs= 4.40236 G, #Params= 3.15720 M, mAP= 0.45150\n",
      "Ultralytics YOLOv8.2.12 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "YOLOv8n summary (fused): 185 layers, 3099495 parameters, 31936 gradients, 8.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:03<00:00, 33.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929       0.52    0.00201    0.00282    0.00152\n",
      "                person        128        254          0          0     0.0255    0.00965\n",
      "               bicycle        128          6          1          0          0          0\n",
      "                   car        128         46          1          0    0.00346    0.00234\n",
      "            motorcycle        128          5          0          0          0          0\n",
      "              airplane        128          6          1          0          0          0\n",
      "                   bus        128          7      0.887      0.143      0.151     0.0888\n",
      "                 train        128          3          0          0    0.00104   0.000311\n",
      "                 truck        128         12          1          0    0.00332   0.000996\n",
      "                  boat        128          6          1          0          0          0\n",
      "         traffic light        128         14          0          0          0          0\n",
      "             stop sign        128          2          0          0          0          0\n",
      "                 bench        128          9          1          0          0          0\n",
      "                  bird        128         16          0          0          0          0\n",
      "                   cat        128          4          0          0          0          0\n",
      "                   dog        128          9          0          0          0          0\n",
      "                 horse        128          2          0          0          0          0\n",
      "              elephant        128         17          1          0          0          0\n",
      "                  bear        128          1          0          0          0          0\n",
      "                 zebra        128          4          1          0          0          0\n",
      "               giraffe        128          9          1          0          0          0\n",
      "              backpack        128          6          1          0          0          0\n",
      "              umbrella        128         18          0          0          0          0\n",
      "               handbag        128         19          1          0          0          0\n",
      "                   tie        128          7          1          0          0          0\n",
      "              suitcase        128          4          1          0          0          0\n",
      "               frisbee        128          5          0          0          0          0\n",
      "                  skis        128          1          1          0          0          0\n",
      "             snowboard        128          7          1          0          0          0\n",
      "           sports ball        128          6          1          0          0          0\n",
      "                  kite        128         10          0          0          0          0\n",
      "          baseball bat        128          4          0          0          0          0\n",
      "        baseball glove        128          7          0          0          0          0\n",
      "            skateboard        128          5          0          0          0          0\n",
      "         tennis racket        128          7          0          0          0          0\n",
      "                bottle        128         18          0          0    0.00409    0.00215\n",
      "            wine glass        128         16          1          0          0          0\n",
      "                   cup        128         36          0          0          0          0\n",
      "                  fork        128          6          1          0          0          0\n",
      "                 knife        128         16          1          0          0          0\n",
      "                 spoon        128         22          1          0          0          0\n",
      "                  bowl        128         28          1          0          0          0\n",
      "                banana        128          1          0          0          0          0\n",
      "              sandwich        128          2          0          0          0          0\n",
      "                orange        128          4          0          0          0          0\n",
      "              broccoli        128         11          0          0          0          0\n",
      "                carrot        128         24          0          0          0          0\n",
      "               hot dog        128          2          0          0          0          0\n",
      "                 pizza        128          5          0          0          0          0\n",
      "                 donut        128         14          0          0          0          0\n",
      "                  cake        128          4          0          0          0          0\n",
      "                 chair        128         35          1          0    0.00818    0.00164\n",
      "                 couch        128          6          1          0          0          0\n",
      "          potted plant        128         14          1          0          0          0\n",
      "                   bed        128          3          0          0    0.00331    0.00198\n",
      "          dining table        128         13          1          0          0          0\n",
      "                toilet        128          2          0          0          0          0\n",
      "                    tv        128          2          1          0          0          0\n",
      "                laptop        128          3          1          0          0          0\n",
      "                 mouse        128          2          1          0          0          0\n",
      "                remote        128          8          1          0          0          0\n",
      "            cell phone        128          8          1          0          0          0\n",
      "             microwave        128          3          1          0          0          0\n",
      "                  oven        128          5          1          0          0          0\n",
      "                  sink        128          6          0          0          0          0\n",
      "          refrigerator        128          5          1          0          0          0\n",
      "                  book        128         29          1          0          0          0\n",
      "                 clock        128          9          0          0          0          0\n",
      "                  vase        128          2          1          0          0          0\n",
      "              scissors        128          1          1          0          0          0\n",
      "            teddy bear        128         21          0          0          0          0\n",
      "            toothbrush        128          5          0          0          0          0\n",
      "Speed: 1.8ms preprocess, 18.9ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/step_0_pre_val22\u001b[0m\n",
      "After pruning iter 1: MACs=4.284912 G, #Params=3.104734 M, mAP=0.0015186372445515255, speed up=1.0274100378257476\n",
      "Ultralytics YOLOv8.2.12 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/train17\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 124/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/train17', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/train17/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/train17\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.31G      3.865      6.577      3.282        217        640: 100%|██████████| 8/8 [00:01<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'DetectionTrainer' has no attribute 'last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 380\u001b[0m, in \u001b[0;36mprune\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    378\u001b[0m pruning_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_finetune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m pruning_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_size  \u001b[38;5;66;03m# restore batch size\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpruning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# post fine-tuning validation\u001b[39;00m\n\u001b[1;32m    383\u001b[0m pruning_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_post_val\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[18], line 281\u001b[0m, in \u001b[0;36mtrain_v2\u001b[0;34m(self, pruning, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# self.trainer.train()\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco128.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:673\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:199\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:427\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mor\u001b[39;00m final_epoch:\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_model_save\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Scheduler\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 182\u001b[0m, in \u001b[0;36msave_model_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# FIXME: self.epoch,\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# \"best_fitness\": self.best_fitness, FIXME: why all these params are not working?\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: __version__,\n\u001b[1;32m    179\u001b[0m }\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Save last, best and delete\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(ckpt, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness:\n\u001b[1;32m    184\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(ckpt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'DetectionTrainer' has no attribute 'last'"
     ]
    }
   ],
   "source": [
    "prune(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNING_AMOUNT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        prune.l1_unstructured(m, name=\"weight\", amount=PRUNING_AMOUNT)  # prune\n",
    "        prune.remove(m, \"weight\")  # make permanent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pruned to 0.0998 global sparsity\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model pruned to {sparsity(model.model):.3} global sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {\n",
    "    \"model\": model.model,\n",
    "    \"train_args\": {},  # save as dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.11 🚀 Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/eduard/Github/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.483      0.429      0.462      0.317\n",
      "                person        128        254      0.337      0.531      0.407      0.242\n",
      "               bicycle        128          6      0.625      0.333      0.301      0.221\n",
      "                   car        128         46      0.213      0.152      0.109     0.0482\n",
      "            motorcycle        128          5       0.52        0.8      0.832      0.651\n",
      "              airplane        128          6      0.518      0.667      0.683       0.41\n",
      "                   bus        128          7      0.487      0.714       0.68      0.498\n",
      "                 train        128          3      0.364      0.667      0.684      0.504\n",
      "                 truck        128         12      0.773      0.288      0.376       0.16\n",
      "                  boat        128          6      0.546      0.167      0.238      0.101\n",
      "         traffic light        128         14      0.128     0.0714     0.0808     0.0223\n",
      "             stop sign        128          2      0.462      0.886      0.745      0.476\n",
      "                 bench        128          9      0.663       0.22      0.472      0.244\n",
      "                  bird        128         16      0.289      0.562      0.426      0.214\n",
      "                   cat        128          4      0.974          1      0.995       0.76\n",
      "                   dog        128          9      0.512      0.778      0.639      0.375\n",
      "                 horse        128          2      0.386          1      0.995      0.597\n",
      "              elephant        128         17       0.43      0.824      0.595      0.326\n",
      "                  bear        128          1      0.591          1      0.995      0.995\n",
      "                 zebra        128          4      0.714          1      0.995      0.893\n",
      "               giraffe        128          9      0.803      0.889      0.949      0.703\n",
      "              backpack        128          6      0.622      0.333       0.29      0.181\n",
      "              umbrella        128         18      0.587      0.444      0.525      0.295\n",
      "               handbag        128         19     0.0514    0.00541     0.0634     0.0284\n",
      "                   tie        128          7      0.311      0.429       0.51      0.268\n",
      "              suitcase        128          4      0.407      0.519      0.551      0.324\n",
      "               frisbee        128          5      0.285        0.6      0.403       0.33\n",
      "                  skis        128          1          0          0      0.249      0.174\n",
      "             snowboard        128          7      0.315      0.429      0.464      0.349\n",
      "           sports ball        128          6      0.298      0.167      0.168      0.134\n",
      "                  kite        128         10     0.0655        0.1     0.0379     0.0139\n",
      "          baseball bat        128          4          1          0     0.0427     0.0171\n",
      "        baseball glove        128          7       0.17      0.286      0.251      0.184\n",
      "            skateboard        128          5      0.168        0.2      0.234      0.129\n",
      "         tennis racket        128          7      0.194      0.286       0.25      0.102\n",
      "                bottle        128         18      0.161      0.167      0.104     0.0453\n",
      "            wine glass        128         16      0.365      0.312      0.237      0.109\n",
      "                   cup        128         36      0.359      0.222      0.245      0.166\n",
      "                  fork        128          6      0.615      0.167      0.178      0.173\n",
      "                 knife        128         16      0.158       0.25      0.163     0.0717\n",
      "                 spoon        128         22      0.629      0.156      0.252      0.114\n",
      "                  bowl        128         28      0.392      0.571      0.425      0.292\n",
      "                banana        128          1          0          0     0.0765      0.021\n",
      "              sandwich        128          2          0          0      0.332      0.315\n",
      "                orange        128          4          1          0      0.912      0.497\n",
      "              broccoli        128         11      0.419      0.182      0.228      0.189\n",
      "                carrot        128         24      0.593      0.292      0.436      0.248\n",
      "               hot dog        128          2      0.631          1      0.828      0.828\n",
      "                 pizza        128          5        0.7          1      0.962      0.694\n",
      "                 donut        128         14      0.597          1      0.759      0.631\n",
      "                  cake        128          4      0.561          1      0.912      0.718\n",
      "                 chair        128         35      0.225      0.366      0.248      0.123\n",
      "                 couch        128          6      0.614        0.5      0.631      0.461\n",
      "          potted plant        128         14       0.44        0.5       0.49      0.248\n",
      "                   bed        128          3      0.919      0.667      0.764       0.61\n",
      "          dining table        128         13      0.527      0.515      0.456      0.343\n",
      "                toilet        128          2      0.666        0.5      0.828      0.745\n",
      "                    tv        128          2      0.308        0.5      0.662      0.535\n",
      "                laptop        128          3          1          0      0.163      0.116\n",
      "                 mouse        128          2          1          0          0          0\n",
      "                remote        128          8      0.954        0.5      0.528      0.413\n",
      "            cell phone        128          8          1          0     0.0367     0.0116\n",
      "             microwave        128          3      0.335      0.333      0.624      0.433\n",
      "                  oven        128          5      0.243        0.4      0.337      0.244\n",
      "                  sink        128          6      0.238      0.167      0.135     0.0851\n",
      "          refrigerator        128          5      0.415        0.4      0.529      0.339\n",
      "                  book        128         29      0.155     0.0345      0.104     0.0409\n",
      "                 clock        128          9      0.254      0.667      0.554      0.319\n",
      "                  vase        128          2       0.36          1      0.828      0.612\n",
      "              scissors        128          1          1          0      0.497      0.149\n",
      "            teddy bear        128         21          1      0.332      0.594      0.359\n",
      "            toothbrush        128          5      0.627        0.4      0.524      0.238\n",
      "Speed: 0.8ms preprocess, 4.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/eduard/Github/x-heep-femu-tflite-sdk/runs/detect/val42\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'PRUNED'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'PRUNED'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/precision(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.48268779643490495</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/recall(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.42881404068150936</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.462184408704583</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics/mAP50-95(B)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3170316451700596</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fitness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.33154692152351195</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/precision\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.48268779643490495\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/recall\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.42881404068150936\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.462184408704583\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'metrics/mAP50-95\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.3170316451700596\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'fitness'\u001b[0m: \u001b[1;36m0.33154692152351195\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, pruned_model = tempfile.mkstemp(\".pt\")\n",
    "\n",
    "torch.save(ckpt, pruned_model)\n",
    "\n",
    "pruned_model = YOLO(pruned_model)\n",
    "\n",
    "results_pruned = pruned_model.val(data=\"coco128.yaml\")\n",
    "\n",
    "\n",
    "pprint(\"PRUNED\")\n",
    "pprint(results_pruned.results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = keras.saving.load_model(f\"{saved_model}/yolov8n_float32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please initialize `Prune` with a supported layer. Layers should either be supported by the PruneRegistry (built-in keras layers) or should be a `PrunableLayer` instance, or should has a customer defined `get_prunable_weights` method. You passed: <class 'keras.src.layers.core.tf_op_layer.TFOpLambda'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m pruning_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruning_schedule\u001b[39m\u001b[38;5;124m\"\u001b[39m: tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mConstantSparsity(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m0.5\u001b[39m, begin_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mUpdatePruningStep()]\n\u001b[0;32m---> 11\u001b[0m pruned_model \u001b[38;5;241m=\u001b[39m \u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use smaller learning rate for fine-tuning\u001b[39;00m\n\u001b[1;32m     14\u001b[0m opt \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:211\u001b[0m, in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pruning_policy:\n\u001b[1;32m    210\u001b[0m     pruning_policy\u001b[38;5;241m.\u001b[39mensure_model_supports_pruning(to_prune)\n\u001b[0;32m--> 211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_add_pruning_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_prune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_keras_layer:\n\u001b[1;32m    213\u001b[0m   params\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:182\u001b[0m, in \u001b[0;36mprune_low_magnitude.<locals>._add_pruning_wrapper\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    179\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential)):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubclassed models are not supported currently.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_add_pruning_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, pruning_wrapper\u001b[38;5;241m.\u001b[39mPruneLowMagnitude):\n\u001b[1;32m    185\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m layer\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/keras/src/models/cloning.py:539\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, functional\u001b[38;5;241m.\u001b[39mFunctional):\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m# If the get_config() method is the same as a regular Functional\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m# model, we're safe to use _clone_functional_model (which relies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# or input_tensors are passed, we attempt it anyway\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;66;03m# in order to preserve backwards compatibility.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mis_default(model\u001b[38;5;241m.\u001b[39mget_config) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    537\u001b[0m         clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors\n\u001b[1;32m    538\u001b[0m     ):\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_functional_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_function\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# Case of a custom model class\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors:\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/keras/src/models/cloning.py:222\u001b[0m, in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    218\u001b[0m         model_configs, created_layers \u001b[38;5;241m=\u001b[39m _clone_layers_and_model_config(\n\u001b[1;32m    219\u001b[0m             model, new_input_layers, layer_fn\n\u001b[1;32m    220\u001b[0m         )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     model_configs, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_clone_layers_and_model_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_input_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Reconstruct model from the config, using the cloned layers.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m (\n\u001b[1;32m    227\u001b[0m     input_tensors,\n\u001b[1;32m    228\u001b[0m     output_tensors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m     model_configs, created_layers\u001b[38;5;241m=\u001b[39mcreated_layers\n\u001b[1;32m    232\u001b[0m )\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/keras/src/models/cloning.py:298\u001b[0m, in \u001b[0;36m_clone_layers_and_model_config\u001b[0;34m(model, input_layers, layer_fn)\u001b[0m\n\u001b[1;32m    295\u001b[0m         created_layers[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m layer_fn(layer)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m--> 298\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_network_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialize_layer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_copy_layer\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config, created_layers\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/keras/src/engine/functional.py:1590\u001b[0m, in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn, config)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Functional) \u001b[38;5;129;01mand\u001b[39;00m set_layers_legacy:\n\u001b[1;32m   1589\u001b[0m     layer\u001b[38;5;241m.\u001b[39muse_legacy_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1590\u001b[0m layer_config \u001b[38;5;241m=\u001b[39m \u001b[43mserialize_layer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1591\u001b[0m layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1592\u001b[0m layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minbound_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_inbound_nodes\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/keras/src/models/cloning.py:295\u001b[0m, in \u001b[0;36m_clone_layers_and_model_config.<locals>._copy_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    293\u001b[0m     created_layers[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m InputLayer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlayer\u001b[38;5;241m.\u001b[39mget_config())\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     created_layers[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:189\u001b[0m, in \u001b[0;36mprune_low_magnitude.<locals>._add_pruning_wrapper\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpruning_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPruneLowMagnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/x-heep-femu-tflite-sdk/.venv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:191\u001b[0m, in \u001b[0;36mPruneLowMagnitude.__init__\u001b[0;34m(self, layer, pruning_schedule, block_size, block_pooling_type, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[38;5;28msuper\u001b[39m(PruneLowMagnitude, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    189\u001b[0m       prune_registry\u001b[38;5;241m.\u001b[39mPruneRegistry\u001b[38;5;241m.\u001b[39mmake_prunable(layer), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    192\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease initialize `Prune` with a supported layer. Layers should \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    193\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meither be supported by the PruneRegistry (built-in keras layers) or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    194\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould be a `PrunableLayer` instance, or should has a customer \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    195\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefined `get_prunable_weights` method. You passed: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    196\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlayer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m))\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_trackable(layer, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# TODO(yunluli): Work-around to handle the first layer of Sequential model\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# properly. Can remove this when it is implemented in the Wrapper base\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# class.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# built. Being not built is confusing since the end-user has passed an\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# input shape.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please initialize `Prune` with a supported layer. Layers should either be supported by the PruneRegistry (built-in keras layers) or should be a `PrunableLayer` instance, or should has a customer defined `get_prunable_weights` method. You passed: <class 'keras.src.layers.core.tf_op_layer.TFOpLambda'>"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "pruning_params = {\n",
    "    \"pruning_schedule\": tfmot.sparsity.keras.ConstantSparsity(\n",
    "        0.5, begin_step=0, frequency=100\n",
    "    )\n",
    "}\n",
    "\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "\n",
    "pruned_model = prune_low_magnitude(tf_model, **pruning_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "pruned_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a YOLOv8 model with keras directly\n",
    "\n",
    "https://keras.io/examples/vision/yolov8/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"car\",\n",
    "    \"pedestrian\",\n",
    "    \"trafficLight\",\n",
    "    \"biker\",\n",
    "    \"truck\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "I start from pre-trained coco weigths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/yolov8/keras/yolo_v8_xs_backbone_coco/2/download/model.weights.h5...\n",
      "100%|██████████| 5.11M/5.11M [00:01<00:00, 5.35MB/s]\n"
     ]
    }
   ],
   "source": [
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xs_backbone_coco\")\n",
    "# https://github.com/keras-team/keras-cv/issues/1886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model\n",
    "\n",
    "- **Classification loss**: Each thing is either an identified class or not so it's a bianary classification problem\n",
    "- **Box loss**: Complete IoU metric not only measures the overlap between predicted and ground truth bounding boxes but also considers the difference in aspect ratio, center distance, and box size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    global_clipnorm=GLOBAL_CLIPNORM,\n",
    ")\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer,\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Metric Callback\n",
    "\n",
    "Used to calculate the mAP (Mean Average Precision) score, Recall and Precision and to save the model when the mAP score improves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, data, save_path):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "            bounding_box_format=\"xyxy\",\n",
    "            evaluate_freq=1e9,\n",
    "        )\n",
    "\n",
    "        self.save_path = save_path\n",
    "        self.best_map = -1.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metrics.reset_state()\n",
    "        for batch in self.data:\n",
    "            images, y_true = batch[0], batch[1]\n",
    "            y_pred = self.model.predict(images, verbose=0)\n",
    "            self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        metrics = self.metrics.result(force=True)\n",
    "        logs.update(metrics)\n",
    "\n",
    "        current_map = metrics[\"MaP\"]\n",
    "        if current_map > self.best_map:\n",
    "            self.best_map = current_map\n",
    "            self.model.save(self.save_path)  # Save the model when mAP improves\n",
    "\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,\n",
    "    callbacks=[EvaluateCOCOMetricsCallback(val_ds, \"model.h5\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(model, dataset, bounding_box_format):\n",
    "    images, y_true = next(iter(dataset.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    y_pred = bounding_box.to_ragged(y_pred)\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        show=True,\n",
    "        font_scale=0.7,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "\n",
    "visualize_detections(yolo, dataset=val_ds, bounding_box_format=\"xyxy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
